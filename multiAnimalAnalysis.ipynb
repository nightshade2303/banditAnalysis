{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49e97f47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# To load data from NAS - python sessdfGenerator.py in conda env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344e4e3c-b916-4d18-b599-303f6e9cc548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.opconNosepokeFunctions import *\n",
    "from utils.supplementaryFunctions import *\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import ttest_rel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import plotSettings\n",
    "\n",
    "# import pickle \n",
    "# with open('L:/4portProb_processed/cleandf.pkl', 'rb') as f:\n",
    "#     df = pickle.load(f)\n",
    "\n",
    "sessdf = pd.read_csv('S:/fileTransferFromWindows/sessdf.csv')\n",
    "\n",
    "window = 5\n",
    "# sessdf = df\n",
    "sessdf['rr'] = sessdf.groupby(['animal', 'session'], as_index = False).reward.rolling(window, center=True).mean().reward\n",
    "bin_size = 50\n",
    "sessdf['sess_bin'] = sessdf.groupby(['animal', 'task'])['session'].transform(lambda x: pd.cut(x, bins=range(0, x.max() + bin_size, bin_size), labels=False, right=False)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b0086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_dict = {\n",
    "    'unstr'  : ['test05022023', 'Blissey', 'Chikorita', 'Darkrai', 'Eevee', \n",
    "                'Goldeen', 'Hoppip', 'Inkay', 'Jirachi', 'Kirlia', 'Mesprit',\n",
    "                'Nidorina', 'Oddish', 'Phione', 'Quilava', 'Raltz', 'Shinx',\n",
    "                'Togepi', 'Umbreon', 'Vulpix', 'Xatu', 'Yanma', 'Zacian',\n",
    "                'Alakazam', 'Bayleef', 'Cresselia', 'Emolga', 'Giratina',\n",
    "                'Haxorus', 'Ivysaur', 'Jigglypuff', 'Lugia', 'Ninetales', 'Onix',\n",
    "                'Pichu', 'Quaxly', 'Sableye', 'Torchic', 'Uxie', 'Vanillish',\n",
    "                'Whismur', 'Xerneas', 'Yamper', 'Zorua'],\n",
    "    'dls'    : ['Blissey', 'Darkrai', 'Inkay' , 'Mesprit', 'Raltz', 'Zacian', 'Alakazam', 'Quilava', 'Torchic', 'Uxie', 'Vanillish', 'Yamper', 'Zorua'],\n",
    "    'dms'    : ['Hoppip', 'Kirlia', 'Nidorina', 'Togepi', 'Xatu', 'Yanma', 'Giratina', 'Ivysaur', 'Lugia', 'Whismur', 'Quaxly', 'Sableye'],\n",
    "    'sham'   : ['test05022023', 'Jirachi', 'Goldeen', 'Phione', 'Umbreon', 'Vulpix', 'Emolga', 'Haxorus', 'Jigglypuff'],\n",
    "    'ds'     : ['Chikorita', 'Eevee'],\n",
    "    'str'    : ['test05022023', 'Blissey', 'Chikorita', 'Darkrai', 'Eevee'],\n",
    "    'oe_drive' : ['Shinx', 'Dratini', 'Bayleef', 'Onix', 'Pichu', 'Xerneas']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f3a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove sessions (per animal) that have any duplicated trials (rows)\n",
    "# Assumes 'animal' and 'session' columns exist in sessdf\n",
    "\n",
    "def remove_sessions_with_duplicate_trials(df, animal_col='animal', session_col='session'):\n",
    "    # Find sessions (per animal) with any duplicated trials based on 'trialstart' and 'eptime'\n",
    "    trial_cols = ['trialstart', 'eptime']\n",
    "    to_remove = set()\n",
    "    for (animal, session), group in df.groupby([animal_col, session_col]):\n",
    "        # If any duplicated trial in this group, mark for removal\n",
    "        if group.duplicated(subset=trial_cols, keep=False).any():\n",
    "            # print(f\"Session {animal}, {session} has duplicated trials based on {trial_cols}\")\n",
    "            to_remove.add((animal, session))\n",
    "    # Build mask for rows to keep\n",
    "    mask = ~(df[[animal_col, session_col]].apply(tuple, axis=1).isin(to_remove))\n",
    "    return df[mask].copy()\n",
    "\n",
    "# Apply to sessdf\n",
    "sessdf = remove_sessions_with_duplicate_trials(sessdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73678796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sessdf.drop(columns = 'Unnamed: 0', inplace = True)\n",
    "exclude = ['[ 20  20  20 100]', '[0 0 0 0]', '[0]', '[0 0]',\n",
    "    '[1000   80]', '[30]', '[40]', '[70]']\n",
    "sessdf = sessdf[~sessdf.rewprobfull.isin(exclude)]\n",
    "sessdf = sessdf[~(sessdf.animal == 'Raikou')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5684e269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'trial', 'trialstart', 'port', 'reward', 'trialend',\n",
       "       'session', 'rewprob', 'eptime', 'task', 'rewprobfull', 'animal',\n",
       "       'datetime', 'rr', 'sess_bin', 'sess_block', 'block_group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.dfLoading import add_block_groups\n",
    "sessdf = add_block_groups(sessdf)\n",
    "sessdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c81962d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all data as .mat files for every animal\n",
    "# first folder - all data\n",
    "# from utils.dfLoading import add_block_groups\n",
    "# blocked_df = add_block_groups(sessdf)\n",
    "# blocked_df = blocked_df.rename(columns = {'session':'block', 'sess_block': 'session'})#.drop(columns = \"Unnamed: 0\")\n",
    "# blocked_df['datetime'] = pd.to_datetime(blocked_df['datetime'])\n",
    "\n",
    "# ## week relative to each animal-task first date\n",
    "# blocked_df['week_task'] = blocked_df.groupby(['animal', 'task'])['datetime'].transform(\n",
    "#     lambda x: ((x - x.min()).dt.days // 7) + 1\n",
    "# )\n",
    "\n",
    "# select week 1 rows per animal-task   #(blocked_df['week_task'] == 8)& \n",
    "week1_per_animal_task = blocked_df[(blocked_df.task == 'sham')]\n",
    "# from scipy.io import savemat\n",
    "# savemat(\"week1_data_RS_20251118_arr.mat\", week1_per_animal_task[['animal', 'session','block','block_group', 'port', 'reward', 'week_task']].to_numpy(), appendmat=False)\n",
    "\n",
    "# group or iterate as needed:\n",
    "# for (animal, task), group in week1_per_animal_task.groupby(['animal', 'task']):\n",
    "#     print(animal, task, group.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9feeaf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dlab\\rishika_sim\\utils\\dfLoading.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sess_block'] = 0\n",
      "c:\\Users\\dlab\\rishika_sim\\utils\\dfLoading.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sess_block'] = df.groupby(['animal', 'task']).sess_block.cumsum()\n",
      "c:\\Users\\dlab\\rishika_sim\\utils\\dfLoading.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['block_group'] = df.groupby(['animal', 'task', 'session']).ngroup()\n",
      "c:\\Users\\dlab\\rishika_sim\\utils\\dfLoading.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['block_group'] = (\n"
     ]
    }
   ],
   "source": [
    "ratdf = sessdf[sessdf.animal == 'Jirachi']\n",
    "from utils.dfLoading import add_block_groups\n",
    "\n",
    "ratdf = add_block_groups(ratdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd89e145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emolga\n",
      "Haxorus\n",
      "Jigglypuff\n",
      "Jirachi\n",
      "Phione\n",
      "Umbreon\n",
      "Vulpix\n",
      "test05022023\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "week1_choices = {}\n",
    "week1_rewards = {}\n",
    "week1_block_num = {}\n",
    "week1_rewprob = {}\n",
    "week1 = []\n",
    "for (animal, group) in week1_per_animal_task[['animal', 'session', 'port', 'reward', 'week_task', 'block_group', 'rewprobfull']].groupby('animal'):\n",
    "    l.append([group.session.nunique(), group.session.value_counts().max()])\n",
    "    choices = np.ones(shape = l[-1])*np.nan\n",
    "    rewards = np.ones(shape = l[-1])*np.nan\n",
    "    block_num = np.ones(shape = l[-1])*np.nan\n",
    "    rewprob = np.ones(shape = (group.session.nunique(), group.session.value_counts().max(), 4))*np.nan\n",
    "\n",
    "    for idx, (sess, sess_group) in enumerate(group.groupby('session')):\n",
    "        if (animal == 'Umbreon') & (sess != 362):\n",
    "            l_sess = sess_group.port.to_numpy().shape[0]\n",
    "            choices[idx, :l_sess] = sess_group.port.to_numpy()\n",
    "            rewards[idx, :l_sess] = sess_group.reward.to_numpy()\n",
    "            block_num[idx, :l_sess] = sess_group.block_group.to_numpy()\n",
    "            rewprob[idx, :l_sess, :] = np.array([i.strip('[]').split(' ') for i in sess_group['rewprobfull']], dtype = int)\n",
    "    week1_choices[animal] = choices\n",
    "    week1_rewards[animal] = rewards\n",
    "    week1_block_num[animal] = block_num\n",
    "    week1_rewprob[animal] = rewprob\n",
    "    print(animal)\n",
    "\n",
    "    week1.append({'choices':week1_choices[animal], 'rewards':week1_rewards[animal], 'block_num':week1_block_num[animal], 'rewprob':week1_rewprob[animal], 'animal':animal})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53fc0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "savemat(\"data/sham_data_20251118_RS.mat\", {'sham':week1}, appendmat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2006222f-0090-4ba3-918c-4b1625ac4122",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Initial bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "985bd2af-d2ee-453d-aefb-b4a73298a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_num = 100\n",
    "cond = 'dls'\n",
    "nth_port = (sessdf[(sessdf.task == 'unstr') & (sessdf.block_group == 1) & (sessdf.sess_bin>=4)]\n",
    "                               .groupby(['animal', 'session'])\n",
    "                               .filter(lambda x: x.reward.size >= 100)\n",
    "                               .groupby(['animal', 'session'])\n",
    "                               .nth(row_num))\n",
    "# sns.displot(data = first_10_ports, x = 'port', col = 'animal', discrete = True,\n",
    "#             common_norm = False, col_wrap = 7, stat = 'probability', color = 'xkcd:cornflower')\n",
    "init_port_prop = nth_port.groupby('animal').port.value_counts(normalize = True, sort = True).reset_index()\n",
    "init_port_prop['highness'] = init_port_prop.groupby('animal').cumcount()+1\n",
    "init_port_prop = init_port_prop.drop(columns = 'port')\n",
    "pref_mat = init_port_prop.set_index(['animal', 'highness']).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d7ff38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.subplot(121)\n",
    "ax.bar(np.arange(1,5),nth_port.port.value_counts(normalize=True), color = 'xkcd:cornflower')\n",
    "ax.set_xticks(np.arange(1,5), np.arange(1,5), color = 'grey', fontsize = 'large')\n",
    "ax.set_xlabel('Average choice', fontsize = 'x-large')\n",
    "# ax.set_yticks(color = 'grey', fontsize = 'large')\n",
    "ax.set_ylabel(f'Probability on trial {row_num}', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "ax = plt.subplot(122)\n",
    "ax.bar(np.arange(1,5),np.mean(pref_mat, axis = 0), color = 'xkcd:cornflower')\n",
    "ax.set_xticks(np.arange(1,5), ['High', '', '', 'Low'],color = 'grey', fontsize = 'large')\n",
    "ax.set_xlabel('Preferred choice', fontsize = 'x-large')\n",
    "# ax.set_yticks(color = 'grey', fontsize = 'large')\n",
    "ax.set_ylabel(f'Probability on trial {row_num}', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef621c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison pairs\n",
    "cond_l = [\"dls\", \"dms\", 'sham']\n",
    "for cond in cond_l:\n",
    "    # calc_nth port\n",
    "    print(cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b560f10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# number of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bcae53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby cond and animal\n",
    "from utils.plotSettings import *\n",
    "countdf = sessdf.groupby(['animal', 'task'],\n",
    "                         as_index = False)['sess_block'].value_counts().rename(columns = {'count':'sesscount'})\n",
    "\n",
    "cond = 'sham'\n",
    "an_list = sessdf[sessdf.task == cond].animal.sort_values().unique()\n",
    "\n",
    "he = countdf[countdf.task.isin([cond, 'unstr'])& \n",
    "             (countdf.animal.isin(an_list))].groupby(['animal', 'task'], as_index = False).sesscount.median()\n",
    "\n",
    "y = np.vstack([he[he.task == 'unstr'].sesscount.values, he[he.task == cond].sesscount.values]).T\n",
    "\n",
    "# plot now!\n",
    "fig = plt.figure(figsize = (3.5, 4.5))\n",
    "ax = plt.subplot(111)\n",
    "ax.bar([0, 1], [np.mean(y[:, 0]), np.mean(y[:, 1])], width = 0.4, color = ['xkcd:cornflower', 'xkcd:slate grey'], alpha = 0.5)\n",
    "ax.plot([0]*len(y[:, 0]), y[:, 0], 'o', color = 'xkcd:cornflower', alpha = 0.7)\n",
    "ax.plot([1]*len(y[:, 1]), y[:, 1], 'o', color = 'xkcd:slate grey', alpha = 0.7)\n",
    "\n",
    "# for lines between points\n",
    "for i in range(y.shape[0]):\n",
    "    ax.plot(y[i, :], color = 'xkcd:slate grey', linewidth = 0.7, alpha = 0.3)\n",
    "\n",
    "# sns.pointplot(data = countdf[countdf.task.isin([cond, 'unstr'])& (countdf.animal.isin(an_list))],\n",
    "#                 order = ['unstr', cond], hue_order =['unstr', cond], \n",
    "#               y = 'sesscount', x = 'task', hue = 'task', errorbar = None, estimator = 'mean', \n",
    "#             palette = ['xkcd:cornflower', 'xkcd:slate grey'], dodge = False, ax = ax)\n",
    "\n",
    "\n",
    "# formatting\n",
    "ax.set_xticks([0, 1], [\"Pre-lesion\",\"Post-lesion\"], fontsize = 'large', color = 'grey')\n",
    "ax.tick_params(axis='both', colors='grey')\n",
    "# ax.set_ylabel()\n",
    "# ax.legend(False)\n",
    "ax.set_ylabel('Number of trials in session', fontsize = 'x-large')\n",
    "ax.set_xlabel('Condition', fontsize = 'x-large')\n",
    "ax.set_xlim(-0.3, 1.3)\n",
    "\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "ttest_rel(y[:, 0], y[:, 1])\n",
    "\n",
    "annot = True\n",
    "if annot == True:\n",
    "  # Perform t-tests\n",
    "  t_stat1, p_val1 = ttest_rel(y[:, 0], y[:, 1])\n",
    "  # Add annotations\n",
    "  max_y = max(np.concatenate([y[:, 0], y[:, 1]]))+20\n",
    "\n",
    "  if p_val1:\n",
    "      plt.plot([0, 1], [max_y + 0.02, max_y + 0.02], color='black', linewidth=1)\n",
    "      plt.text(0.5, max_y + 20, f'p={p_val1:.3f}', ha='center', fontsize=10)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b79c4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Transition matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96afc4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dlab\\rishika_sim\\utils\\dfLoading.py:80: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['shift_t0'] = (df['choice_t1']==df['port']).replace({True: 0, False: 1})\n",
      "c:\\Users\\dlab\\rishika_sim\\utils\\dfLoading.py:81: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['shift_t1'] = (df['choice_t2']==df['port']).replace({True: 0, False: 1})\n"
     ]
    }
   ],
   "source": [
    "from utils.dfLoading import add_shift_info\n",
    "sessdf = add_shift_info(sessdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "583a09e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# full tm - all trials \n",
    "%matplotlib qt\n",
    "ind = 1\n",
    "trialsinsess = 100\n",
    "\n",
    "cond = 'unstr'\n",
    "an_list = an_dict[cond]\n",
    "from utils.plotSettings import *\n",
    "parula = get_parula_cmap()\n",
    "cmap = parula\n",
    "mat = np.ones((len(an_list), 4, 4))*np.nan\n",
    "fig = plt.figure(figsize = (15, 10))\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "mask = (tempdf.task==cond) & tempdf.animal.isin(an_list) & (tempdf.sess_bin>=4)\n",
    "for animal, group in tempdf[mask].groupby('animal'):\n",
    "\n",
    "    ax = plt.subplot(6, 8, ind)\n",
    "    sns.heatmap(pd.crosstab(group['port'],\n",
    "                            group['choice_t1'],\n",
    "                            normalize = 'index'),\n",
    "                            # dropna = False),\n",
    "                ax = ax, cmap = cmap,\n",
    "                annot = True, fmt = '.2f',square = True, vmax = 0.17,\n",
    "                xticklabels = np.arange(1,5), yticklabels = np.arange(1,5),\n",
    "                # mask = np.eye(4, dtype = bool),\n",
    "                vmin = 0)\n",
    "    ax.set_title(animal)\n",
    "    \n",
    "    if (animal == 'Yamper') & (group.task.unique()[0] == 'dls'):\n",
    "        mat_y = np.vstack([pd.crosstab(group['port'],\n",
    "                            group['choice_t1'],\n",
    "                            normalize = 'index').to_numpy(), np.zeros((1, 3))*np.nan])\n",
    "        mat_y = np.hstack([mat_y, np.zeros((4, 1))*np.nan])\n",
    "        mat[ind-1] = mat_y\n",
    "    else:\n",
    "        mat[ind-1] = pd.crosstab(group['port'],\n",
    "                            group['choice_t1'],\n",
    "                            normalize = 'index')\n",
    "    \n",
    "    ind+=1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "sns.heatmap(np.nanmedian(mat, axis = 0), annot = False, fmt = '.2f', cmap = parula, xticklabels = np.arange(1,5), square = True,\n",
    "            yticklabels = np.arange(1,5), vmin = 0, vmax = 0.17, cbar_kws={'label': 'Transition probability'},\n",
    "            # mask = np.eye(4),\n",
    "            ax = ax)\n",
    "# ax.patch.set_facecolor('white')\n",
    "ax.set_xlabel('Choice at trial t+1', fontsize = 'x-large')\n",
    "ax.set_ylabel('Choice at trial t', fontsize = 'x-large')\n",
    "ax.tick_params(axis = u'both', which = u'both', length = 0, labelsize = 'large', color = 'grey')\n",
    "plt.title(f'Choice at switches - Animal data, n = {mat.shape[0]}')\n",
    "\n",
    "# plt.suptitle('Animal data', fontsize = 16)    \n",
    "plt.tight_layout()\n",
    "# plt.savefig('C:/Users/dlab/rishika_sim/plots/20231210/tm_all_noswitch.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc831e06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501c678-2157-4f02-8689-f29d44d71eef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sliding window entropy for different conditions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9affc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### moving entropy ######################################\n",
    "%matplotlib qt\n",
    "\n",
    "trialsinsess = 100\n",
    "\n",
    "from utils.dfLoading import subset_trials, add_shift_info, add_block_groups\n",
    "subset_df = add_block_groups(sessdf)\n",
    "# subset_df = add_shift_info(subset_df)\n",
    "subset_df = subset_trials(subset_df, trialsinsess=trialsinsess, head_trials = trialsinsess)\n",
    "\n",
    "from utils.supplementaryFunctions import calc_prob\n",
    "window = 5\n",
    "# subset_df['entropy'] = (subset_df.groupby(['animal', 'session'], as_index = False)\n",
    "#                      .port\n",
    "#                      .rolling(window, center=True)\n",
    "#                      .apply(lambda x: entropy(calc_prob(x), base = 2))\n",
    "#                      .port)\n",
    "\n",
    "from utils.dfAnalysisHelpers import session_averager\n",
    "entropy_mean_dict = session_averager(subset_df[subset_df.block_group==1], metric= 'entropy', tasks = ['unstr', 'str', 'dms', 'dls', 'sham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "00eae533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\2479433384.py:48: SmallSampleWarning: After omitting NaNs, one or more axis-slices of one or more sample arguments is too small; corresponding elements of returned arrays will be NaN. See documentation for sample size requirements.\n",
      "  plt.fill_between(np.arange(trialsinsess), mean_unstr+sem(temp_unstr, nan_policy = 'omit'),\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\2479433384.py:49: SmallSampleWarning: After omitting NaNs, one or more axis-slices of one or more sample arguments is too small; corresponding elements of returned arrays will be NaN. See documentation for sample size requirements.\n",
      "  mean_unstr-sem(temp_unstr, nan_policy = 'omit'), color = color1, alpha = 0.2)\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\2479433384.py:53: SmallSampleWarning: After omitting NaNs, one or more axis-slices of one or more sample arguments is too small; corresponding elements of returned arrays will be NaN. See documentation for sample size requirements.\n",
      "  plt.fill_between(np.arange(trialsinsess),mean_str+sem(temp_str, nan_policy = 'omit'),\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\2479433384.py:54: SmallSampleWarning: After omitting NaNs, one or more axis-slices of one or more sample arguments is too small; corresponding elements of returned arrays will be NaN. See documentation for sample size requirements.\n",
      "  mean_str-sem(temp_str, nan_policy = 'omit'), color = color2, alpha = 0.2)\n"
     ]
    }
   ],
   "source": [
    "# plot average reponse\n",
    "from utils.plotSettings import *\n",
    "from scipy.stats import sem\n",
    "plt.figure(figsize = (5,4.5))\n",
    "temp_unstr, temp_str = [], []\n",
    "\n",
    "# set properties\n",
    "smooth = True\n",
    "window = 3\n",
    "label1, label2 = 'Pre-lesion', 'Post-lesion'\n",
    "# label1, label2 = 'Unstructured', 'Structured'\n",
    "color1, color2 = 'xkcd:cornflower', 'xkcd:slate grey'\n",
    "# color1, color2 = 'xkcd:pumpkin orange', 'xkcd:emerald green'\n",
    "# color1, color2 = '#7a2048', '#408ec6'\n",
    "\n",
    "# set data for plotting\n",
    "cond = 'sham'\n",
    "an_list = an_dict[cond]\n",
    "# fish = ['Alakazam', 'Yanma']\n",
    "for (animal, env) in entropy_mean_dict.keys():\n",
    "    if animal in an_list:\n",
    "        if env == 'unstr':\n",
    "            temp_unstr.append(entropy_mean_dict[(animal, env)])\n",
    "        elif (env == cond):\n",
    "            temp_str.append(entropy_mean_dict[(animal, env)])\n",
    "\n",
    "temp_unstr = np.array(temp_unstr)\n",
    "temp_str = np.array(temp_str)          \n",
    "if smooth:           \n",
    "    for i, row in enumerate(temp_unstr):\n",
    "        temp_unstr[i] = np.convolve(row, np.ones(3)/3, 'same')\n",
    "        temp_str[i] = np.convolve(temp_str[i], np.ones(3)/3, 'same')\n",
    "        # temp_dms[i] = np.convolve(temp_dms[i], np.ones(3)/3, 'same')\n",
    "\n",
    "    # works only for odd windows\n",
    "    temp_unstr[:, 0:(window//2)] = np.nan\n",
    "    temp_unstr[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "    \n",
    "    temp_str[:, 0:(window//2)] = np.nan\n",
    "    temp_str[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "# # \n",
    "\n",
    "mean_unstr = (np.mean(np.array(temp_unstr), axis = 0))\n",
    "mean_str = (np.mean(np.array(temp_str), axis = 0))\n",
    "# temp_str = (np.mean(np.array(temp_str), axis = 0))\n",
    "\n",
    "plt.plot(np.arange(trialsinsess), mean_unstr, color1, label = label1) #7a2048\n",
    "plt.fill_between(np.arange(trialsinsess), mean_unstr+sem(temp_unstr, nan_policy = 'omit'),\n",
    "                 mean_unstr-sem(temp_unstr, nan_policy = 'omit'), color = color1, alpha = 0.2)\n",
    "\n",
    "plt.plot(np.arange(trialsinsess), mean_str, color2, label = label2)\n",
    "\n",
    "plt.fill_between(np.arange(trialsinsess),mean_str+sem(temp_str, nan_policy = 'omit'), \n",
    "                 mean_str-sem(temp_str, nan_policy = 'omit'), color = color2, alpha = 0.2)\n",
    "\n",
    "# pvals = ttest_rel(temp_str, temp_unstr, axis =0 , nan_policy = 'omit')[1]\n",
    "# print(pvals[1].shape)\n",
    "# pvals_ind = [ind for ind, i in enumerate(pvals) if i < 0.05]\n",
    "# plt.scatter(pvals_ind, [0.1]*len(pvals_ind), marker = '.', color = 'r', alpha = 0.4) #(6, 2, 60) for asterisks\n",
    "# plt.axhline(1.95, color = 'k', linestyle = '--') # max entropy possible\n",
    "# plt.title('Variation in choice taken')\n",
    "plt.xlabel('Trials in session', fontsize = 'x-large')\n",
    "plt.ylabel('Entropy (bits)', fontsize = 'x-large')\n",
    "plt.xlim(0, trialsinsess)\n",
    "plt.ylim(0, 0.85)\n",
    "plt.xticks([0, 25, 50, 75, 100], [1, '', '', '', 100], color = 'grey', fontsize = 'large')\n",
    "plt.yticks([0, 0.2, 0.4, 0.6, 0.8], [0, '', '', \"\",0.8], color = 'grey', fontsize = 'large')\n",
    "plt.title(f'n = {temp_unstr.shape[0]}')\n",
    "# plt.ylim(0, 0.8)\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5250b467",
   "metadata": {},
   "source": [
    "## Entropy in block 2 and beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "29e416b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all groups which have a second block, plot first block entropy for first 100 trials of session\n",
    "# find if 2nd or greater block exists for animals\n",
    "block_2_exists = tempdf[(tempdf.block_group>=2) & (tempdf.task == 'unstr')].groupby(['animal', 'sess_block']).size().reset_index()[['animal', 'sess_block']]\n",
    "\n",
    "# remove animals with less than 10\n",
    "block_2_exists = block_2_exists[block_2_exists.animal.isin(block_2_exists.animal.value_counts()[block_2_exists.animal.value_counts()>10].index)]\n",
    "\n",
    "# find first blocks for these sessions\n",
    "all_blocked_groups = tempdf[tempdf.task == 'unstr'].merge(block_2_exists, on = ['animal', 'sess_block'])\n",
    "first_blocks = all_blocked_groups[all_blocked_groups.block_group == 1]\n",
    "other_blocks = all_blocked_groups[all_blocked_groups.block_group > 1]\n",
    "\n",
    "# convert to numpy array\n",
    "entropy2_dict_block_1 = {}\n",
    "for an, group in first_blocks.groupby('animal'):\n",
    "        g = group.groupby('session').cumcount()\n",
    "        L = (group.set_index(['session', g])\n",
    "                .unstack(fill_value=0)\n",
    "                .stack(future_stack= True).groupby(level=0)\n",
    "                .apply(lambda x: x.entropy.values.tolist())\n",
    "                .tolist())\n",
    "        entropy2_dict_block_1[an] = np.mean(L, axis = 0)\n",
    "entropy2_dict_block_others = {}\n",
    "for an, group in other_blocks.groupby('animal'):\n",
    "        g = group.groupby('session').cumcount()\n",
    "        L = (group.set_index(['session', g])\n",
    "                .unstack(fill_value=0)\n",
    "                .stack(future_stack= True).groupby(level=0)\n",
    "                .apply(lambda x: x.entropy.values.tolist())\n",
    "                .tolist())\n",
    "        entropy2_dict_block_others[an] = np.mean(L, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1870055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_19448\\2989309347.py:7: RuntimeWarning: Mean of empty slice\n",
      "  plt.plot(np.nanmean(y, axis = 0), color = 'xkcd:cornflower', lw = 2.25)\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize = (5, 4.5))\n",
    "prev_sess_size = 25\n",
    "y = np.zeros((len(entropy2_dict_block_1.keys()), 100+prev_sess_size))\n",
    "for ind, an in enumerate(entropy2_dict_block_1.keys()):\n",
    "    y[ind] = np.concatenate([entropy2_dict_block_1[an][-prev_sess_size:], entropy2_dict_block_others[an]])\n",
    "    plt.plot(y[ind], color = 'xkcd:cornflower', alpha = 0.3, lw = 0.75)\n",
    "plt.plot(np.nanmean(y, axis = 0), color = 'xkcd:cornflower', lw = 2.25)\n",
    "plt.xlabel('Block position', fontsize = 'x-large')\n",
    "plt.ylabel('Entropy (bits)', fontsize = 'x-large')\n",
    "plt.ylim(0, 0.4)\n",
    "plt.xticks(np.arange(0, 126, 25), np.arange(-25, 101, 25), color = 'grey', fontsize = 'large')\n",
    "plt.axvline(25, lw = 0.75, color = 'k', linestyle = '--')\n",
    "plt.yticks(color = 'grey', fontsize = 'large')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e32def",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50b1d003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### regret ######################################\n",
    "%matplotlib qt\n",
    "\n",
    "trialsinsess = 100\n",
    "\n",
    "from utils.dfLoading import subset_trials, add_shift_info, add_block_groups\n",
    "subset_df = add_block_groups(sessdf)\n",
    "# subset_df = add_shift_info(df)\n",
    "subset_df = subset_trials(subset_df, trialsinsess=trialsinsess, head_trials = trialsinsess)\n",
    "\n",
    "from utils.supplementaryFunctions import calc_prob\n",
    "window = 5\n",
    "subset_df['regret'] = abs(subset_df['rewprob'] - 80)\n",
    "\n",
    "\n",
    "from utils.dfAnalysisHelpers import session_averager\n",
    "reg_mean_dict = session_averager(subset_df[subset_df.block_group == 1], metric= 'regret', tasks = ['unstr', 'str', 'dms', 'dls', 'sham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917da590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_26240\\1611805775.py:63: SmallSampleWarning: After omitting NaNs, one or more axis-slices of one or more sample arguments is too small; corresponding elements of returned arrays will be NaN. See documentation for sample size requirements.\n",
      "  plt.fill_between(np.arange(trialsinsess), mean_unstr+sem(temp_unstr, nan_policy = 'omit'),\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_26240\\1611805775.py:64: SmallSampleWarning: After omitting NaNs, one or more axis-slices of one or more sample arguments is too small; corresponding elements of returned arrays will be NaN. See documentation for sample size requirements.\n",
      "  mean_unstr-sem(temp_unstr, nan_policy = 'omit'), color = color1, alpha = 0.2)\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_26240\\1611805775.py:68: SmallSampleWarning: After omitting NaNs, one or more axis-slices of one or more sample arguments is too small; corresponding elements of returned arrays will be NaN. See documentation for sample size requirements.\n",
      "  plt.fill_between(np.arange(trialsinsess), mean_str+sem(temp_str, nan_policy = 'omit'),\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_26240\\1611805775.py:69: SmallSampleWarning: After omitting NaNs, one or more axis-slices of one or more sample arguments is too small; corresponding elements of returned arrays will be NaN. See documentation for sample size requirements.\n",
      "  mean_str-sem(temp_str, nan_policy = 'omit'), color = color2, alpha = 0.2)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "from scipy.stats import sem\n",
    "# plot average reponse\n",
    "plt.figure(figsize = (5,4.5))\n",
    "temp_unstr, temp_str = [], []\n",
    "\n",
    "# set properties\n",
    "smooth = True\n",
    "window = 3\n",
    "label1 = 'Pre-lesion'\n",
    "label2 = 'Post-lesion'\n",
    "# label1 = 'Unstructured'\n",
    "# label2 = 'Structured'\n",
    "color1 = 'xkcd:cornflower'\n",
    "color2 = 'xkcd:slate grey'\n",
    "# color1 = '#7a2048', \n",
    "# color1 = 'xkcd:pumpkin orange'\n",
    "# color2 = 'xkcd:emerald green'\n",
    "# color2 = '#408ec6'\n",
    "\n",
    "# set data for plotting\n",
    "cond = 'dms'\n",
    "for (animal, env) in reg_mean_dict.keys():\n",
    "    if animal in an_dict[cond]:\n",
    "        if env == 'unstr':\n",
    "            temp_unstr.append(reg_mean_dict[(animal, env)])\n",
    "        elif (env == cond):\n",
    "            temp_str.append(reg_mean_dict[(animal, env)])\n",
    "\n",
    "# calculate performance index\n",
    "temp_unstr = (1-np.array(temp_unstr)/100)\n",
    "temp_str = (1-np.array(temp_str)/100)\n",
    "# temp_unstr = np.array(temp_unstr)\n",
    "# temp_str = np.array(temp_str)\n",
    "\n",
    "# smoothing details\n",
    "if smooth:           \n",
    "    for i, row in enumerate(temp_unstr):\n",
    "        temp_unstr[i] = np.convolve(row, np.ones(window)/window, 'same')\n",
    "        # temp_str[i] = np.convolve(temp_str[i], np.ones(window)/window, 'same')\n",
    "    \n",
    "    # works only for odd windows\n",
    "    temp_unstr[:, 0:(window//2)] = np.nan\n",
    "    temp_unstr[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "    \n",
    "    temp_str[:, 0:(window//2)] = np.nan\n",
    "    temp_str[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "\n",
    "# temp_str = [np.convolve(temp_str[i], np.ones(window)/window, 'same') for i, row in enumerate(temp_str)]\n",
    "# temp_str[:, 0:(window//2)] = np.nan\n",
    "# temp_str[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "\n",
    "# take mean of smoothed data   \n",
    "mean_unstr = (np.mean(np.array(temp_unstr), axis = 0))\n",
    "mean_str = (np.mean(np.array(temp_str), axis = 0))\n",
    "\n",
    "# plot line 1\n",
    "plt.plot(np.arange(trialsinsess), mean_unstr, color1, label = label1) \n",
    "plt.fill_between(np.arange(trialsinsess), mean_unstr+sem(temp_unstr, nan_policy = 'omit'),\n",
    "                 mean_unstr-sem(temp_unstr, nan_policy = 'omit'), color = color1, alpha = 0.2)\n",
    "\n",
    "# plot line 2 (or comment)\n",
    "plt.plot(np.arange(trialsinsess), mean_str, color2, label = label2)\n",
    "plt.fill_between(np.arange(trialsinsess), mean_str+sem(temp_str, nan_policy = 'omit'), \n",
    "                 mean_str-sem(temp_str, nan_policy = 'omit'), color = color2, alpha = 0.2)\n",
    "# for row in temp_str:\n",
    "#     plt.plot(row, color = color2, alpha  = 1)\n",
    "\n",
    "# plot significance\n",
    "# pvals = ttest_rel(temp_str, temp_unstr)[1]\n",
    "# pvals_ind = [ind for ind, i in enumerate(pvals) if i < 0.05]\n",
    "# plt.scatter(pvals_ind, [0.65]*len(pvals_ind), marker = '.', color = 'r', alpha = 0.4) #(6, 2, 60) for asterisks\n",
    "\n",
    "# plot settings\n",
    "plt.xlabel('Trials in session', fontsize = 'x-large')\n",
    "plt.ylabel('Performance index', fontsize = 'x-large')\n",
    "plt.xlim(0, trialsinsess)\n",
    "plt.axhline(0.625, color='k', linestyle = '--') # chance calc by\n",
    "plt.ylim(0.6, 0.8)\n",
    "plt.xticks([0, 25, 50, 75, 100], [1, '', '', '', 100], color = 'grey', fontsize = 'large')\n",
    "plt.yticks([0.6, 0.65, 0.7, 0.75, 0.8, 0.85], ['0.60', '', '', '', '', 0.85], color = 'grey', fontsize = 'large')\n",
    "# plt.ylim(0, 0.8)\n",
    "# plt.legend(loc='upper left')\n",
    "plt.title(f'n = {temp_unstr.shape[0]}')\n",
    "sns.despine()\n",
    "# sns.set_context('talk')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('C:/Users/dlab/OneDrive - Indian Institute of Science/Drawings/awp1/entropy_n_21.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "f81f17eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21a1b5cec50>]"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if fitting exp curve is reqd\n",
    "def logF(x, a, b, c):\n",
    "    return a*np.log(x+b)+c\n",
    "\n",
    "def f(x, a, b, c):\n",
    "    '''exponential fxn: a is amplitude, b is decay rate, c is offset'''\n",
    "    return a*np.exp(-b*x) + c\n",
    "\n",
    "popt_str, _ = curve_fit(f, np.arange(trialsinsess), mean_str, nan_policy = 'omit')\n",
    "popt_unstr, _ = curve_fit(f, np.arange(trialsinsess), mean_unstr, nan_policy = 'omit')\n",
    "plt.plot(np.arange(trialsinsess), f(np.arange(trialsinsess), *popt_str), color2, linestyle= 'dotted')\n",
    "plt.plot(np.arange(trialsinsess), f(np.arange(trialsinsess), *popt_unstr), color1, linestyle= 'dotted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc86f11-93cb-4a94-8671-f5db0133efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logic - if 46 next to 80 then structured, but also how visibly smooth it is\n",
    "l_str_sess = [\n",
    "    '[10 15 46 80]',\n",
    "    '[10 15 80 46]',\n",
    "    '[10 46 80 15]',\n",
    "    '[10 80 46 15]',\n",
    "    '[15 10 46 80]',\n",
    "    '[15 10 80 46]', \n",
    "    '[15 46 46 80]', \n",
    "    '[15 46 80 10]',\n",
    "    '[15 46 80 46]',\n",
    "    '[15 80 46 10]',\n",
    "    '[15 80 46 46]',\n",
    "    '[46 46 80 15]',\n",
    "    '[46 80 10 15]',\n",
    "    '[46 80 15 10]',\n",
    "    '[46 80 46 15]',\n",
    "    '[80 46 10 15]',\n",
    "    '[80 46 15 10]',\n",
    "    '[80 46 46 15]'\n",
    "]\n",
    "sessdf['assigned'] = sessdf.rewprobfull.isin(l_str_sess)\n",
    "sessdf.assigned.replace({True: 'str', False: 'unstr'}, inplace = True)\n",
    "\n",
    "struc = ['[80 46 15 10]', '[46 80 46 15]', '[15 46 80 46]', '[10 15 46 80]']\n",
    "sessdf['env'] = sessdf.rewprobfull.isin(struc)\n",
    "sessdf.env.replace({True: 'str', False: 'unstr'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "7f1a3a3e-c08d-4750-b2de-e138f2c81710",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "from scipy.signal import find_peaks\n",
    "plt.figure(figsize = (20, 10))\n",
    "unq_prob, _ = np.array(np.unique(sessdf[(sessdf.animal == 'Blissey')].rewprobfull,\n",
    "          return_counts = True))\n",
    "\n",
    "for i in range(unq_prob.shape[0]):\n",
    "    ax = plt.subplot(4, 9, i+1)\n",
    "    rp = [int(o) for o in unq_prob[i]]\n",
    "    pk = find_peaks(rp, height = 10)\n",
    "    ax.plot(rp)\n",
    "    ax.set_title(f'{pk[0].shape[0]}, {pk[1][\"peak_heights\"]}')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc261801",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Reward rate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d03f851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### rr ######################################\n",
    "# set_cwd('/home/rishika/sim/')\n",
    "%matplotlib qt\n",
    "# %matplotlib inline\n",
    "\n",
    "trialsinsess = 100\n",
    "\n",
    "from utils.dfLoading import subset_trials, add_shift_info, add_block_groups\n",
    "subset_df = add_block_groups(sessdf)\n",
    "# subset_df = add_shift_info(df)\n",
    "subset_df = subset_trials(subset_df, trialsinsess=trialsinsess, head_trials = trialsinsess)\n",
    "\n",
    "# window = \n",
    "# subset_df['rr'] = subset_df.groupby(['animal', 'session'], as_index = False).reward.rolling(window, center=True).mean().reward\n",
    "\n",
    "\n",
    "from utils.dfAnalysisHelpers import session_averager\n",
    "rr_mean_dict = session_averager(subset_df[subset_df.block_group == 1], metric= 'rr', tasks = ['unstr', 'str', 'dms', 'dls', 'sham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5b03c720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\1329893560.py:46: RuntimeWarning: Mean of empty slice\n",
      "  mean_unstr = (np.nanmean(np.array(temp_unstr), axis = 0))\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\1329893560.py:47: RuntimeWarning: Mean of empty slice\n",
      "  mean_str = (np.nanmean(np.array(temp_str), axis = 0))\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\1329893560.py:51: SmallSampleWarning: After omitting NaNs, one or more axis-slices of one or more sample arguments is too small; corresponding elements of returned arrays will be NaN. See documentation for sample size requirements.\n",
      "  plt.fill_between(np.arange(trialsinsess), mean_unstr+sem(temp_unstr, nan_policy = 'omit'),\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\1329893560.py:52: SmallSampleWarning: After omitting NaNs, one or more axis-slices of one or more sample arguments is too small; corresponding elements of returned arrays will be NaN. See documentation for sample size requirements.\n",
      "  mean_unstr-sem(temp_unstr, nan_policy = 'omit'), color = color1, alpha = 0.2)\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\1329893560.py:56: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  plt.fill_between(np.arange(trialsinsess), mean_str+sem(temp_str, nan_policy = 'omit'),\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\1329893560.py:57: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  mean_str-sem(temp_str, nan_policy = 'omit'), color = color2, alpha = 0.2)\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import sem\n",
    "from itertools import permutations\n",
    "# plot average reponse\n",
    "from utils.plotSettings import *\n",
    "plt.figure(figsize = (5,4.5))\n",
    "temp_unstr, temp_str = [], []\n",
    "\n",
    "# set properties\n",
    "smooth = False\n",
    "window = 3\n",
    "label1, label2 = 'Pre-lesion', 'Post-lesion'\n",
    "# label1, label2 = 'Unstructured', 'Structured'\n",
    "color1, color2 = 'xkcd:cornflower', 'xkcd:slate grey'\n",
    "# color1, color2 = 'xkcd:pumpkin orange', 'xkcd:emerald green'\n",
    "# # color1, color2 = '#7a2048', '#408ec6'\n",
    "\n",
    "# set data for plotting\n",
    "cond = 'unstr'\n",
    "for (animal, env) in rr_mean_dict.keys():\n",
    "    if animal in an_dict[cond]:\n",
    "        if env == 'unstr':\n",
    "            temp_unstr.append(rr_mean_dict[(animal, env)])\n",
    "        # elif (env == cond):\n",
    "        #     temp_str.append(rr_mean_dict[(animal, env)])\n",
    "temp_unstr = np.array(temp_unstr)\n",
    "# temp_str = np.array(temp_str)\n",
    "\n",
    "# smoothing details\n",
    "if smooth == True:           \n",
    "    for i, row in enumerate(temp_unstr):\n",
    "        temp_unstr[i] = np.convolve(row, np.ones(window)/window, 'same')\n",
    "        # temp_str[i] = np.convolve(temp_str[i], np.ones(window)/window, 'same')\n",
    "    \n",
    "    temp_unstr = np.array(temp_unstr)\n",
    "    # temp_str = np.array(temp_str)\n",
    "    # \n",
    "    # works only for odd windows\n",
    "    temp_unstr[:, 0:(window//2)] = np.nan\n",
    "    temp_unstr[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "    \n",
    "    # temp_str[:, 0:(window//2)] = np.nan\n",
    "    # temp_str[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "\n",
    "# take mean of smoothed data   \n",
    "mean_unstr = (np.nanmean(np.array(temp_unstr), axis = 0))\n",
    "mean_str = (np.nanmean(np.array(temp_str), axis = 0))\n",
    "\n",
    "# plot line 1\n",
    "plt.plot(np.arange(trialsinsess), mean_unstr, color1, label = label1)#, marker = '.') \n",
    "plt.fill_between(np.arange(trialsinsess), mean_unstr+sem(temp_unstr, nan_policy = 'omit'),\n",
    "                 mean_unstr-sem(temp_unstr, nan_policy = 'omit'), color = color1, alpha = 0.2)\n",
    "\n",
    "# plot line 2 (or comment)\n",
    "# plt.plot(np.arange(trialsinsess), mean_str, color2, label = label2)\n",
    "plt.fill_between(np.arange(trialsinsess), mean_str+sem(temp_str, nan_policy = 'omit'), \n",
    "                 mean_str-sem(temp_str, nan_policy = 'omit'), color = color2, alpha = 0.2)\n",
    "\n",
    "# plot significance\n",
    "# pvals = ttest_rel(temp_str, temp_unstr)[1]\n",
    "# pvals_ind = [ind for ind, i in enumerate(pvals) if i < 0.05]\n",
    "# plt.scatter(pvals_ind, [0.45]*len(pvals_ind), marker = '.', color = 'r', alpha = 0.4) #(6, 2, 60) for asterisks\n",
    "\n",
    "# chance calc\n",
    "plt.axhline(np.mean(np.unique(list(permutations([80, 46, 15, 10]))+list(permutations([46, 80, 46, 15])), axis = 0))/100,\n",
    "            color = 'k', linestyle = '--')\n",
    "# plt.axhline(np.mean([[80, 46, 15, 10], [46, 80, 46, 15], [15, 46, 80, 46], [10, 15, 46, 80]])/100, color = color2)\n",
    "\n",
    "# plot settings\n",
    "plt.xlabel('Trials in session', fontsize = 'x-large')\n",
    "plt.ylabel('Reward rate', fontsize = 'x-large')\n",
    "plt.xlim(0, trialsinsess)\n",
    "plt.ylim(0.4, 0.7)\n",
    "plt.xticks([0, 25, 50, 75, 100], [1, '', '', '', 100], color = 'grey', fontsize = 'large')\n",
    "plt.yticks([0.4, 0.5, 0.6, 0.7], [0.4, '', '', 0.7], color = 'grey', fontsize = 'large')\n",
    "plt.title(f'n = {temp_unstr.shape[0]}')\n",
    "plt.legend(loc = 'upper left')\n",
    "sns.despine()\n",
    "# sns.set_context('talk')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('C:/Users/dlab/OneDrive - Indian Institute of Science/Drawings/awp1/entropy_n_21.png', dpi = 300)\n",
    "\n",
    "\n",
    "# if fitting exp curve is reqd\n",
    "def logFunc(x, a, b):\n",
    "    return a + b*np.log(x)\n",
    "\n",
    "# popt_str, _ = curve_fit(logFunc, np.arange(150), temp_str, nan_policy = 'omit')\n",
    "# popt_unstr, _ = curve_fit(logFunc, np.arange(trialsinsess), mean_unstr, nan_policy = 'omit')\n",
    "# plt.plot(np.arange(150), logFunc(np.arange(150), *popt_str), '#408ec6', linestyle= 'dotted')\n",
    "# plt.plot(np.arange(trialsinsess), logFunc(np.arange(trialsinsess), *popt_unstr), color1, linestyle= 'dotted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "21ac70f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_unstr, temp_str = [], []\n",
    "for (animal, env) in rr_mean_dict.keys():\n",
    "    if animal in fish:\n",
    "        if env == 'unstr':\n",
    "            temp_unstr.append(rr_mean_dict[(animal, env)])\n",
    "        elif env == 'str':\n",
    "            temp_str.append(rr_mean_dict[(animal, env)])\n",
    "\n",
    "ttest_rel(np.nanmean(np.array(temp_str)[:, :25], axis = 1),\n",
    "          np.nanmean(np.array(temp_str)[:, -25:], axis = 1), nan_policy = 'omit')\n",
    "\n",
    "plt.figure(figsize = (3.5,4.5))\n",
    "rr_df = pd.DataFrame([np.nanmean(np.array(temp_str), axis = 1), np.nanmean(np.array(temp_unstr), axis = 1)],\n",
    "                     index = ['Structured', 'Unstructured'])\n",
    "plt.scatter(np.zeros(5), rr_df.loc['Structured'], color = '#408ec6', alpha = 0.5)\n",
    "plt.scatter(np.ones(5), rr_df.loc['Unstructured'], color = '#7a2048', alpha = 0.5)\n",
    "plt.plot(rr_df, '-', c = 'grey', alpha = 0.5)\n",
    "sns.pointplot(rr_df.T, join = False, palette = ['#408ec6','#7a2048'], errorbar = None)\n",
    "sns.despine()\n",
    "plt.xlim([-0.4,1.4])\n",
    "# ax.set_xticks([0,1])\n",
    "plt.xlabel('Session')\n",
    "# plt.xticks([0,1],['Structured', 'End'])\n",
    "plt.ylabel('Reward rate')\n",
    "plt.title('Reward rate across conditions', wrap = True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a65a189d-9182-4097-b1d9-811792b42e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 100) Blissey unstr\n",
      "(17, 100) Chikorita unstr\n",
      "(19, 100) Darkrai unstr\n",
      "(9, 100) Eevee unstr\n",
      "(18, 100) test05022023 unstr\n",
      "(177, 100) Blissey str\n",
      "(136, 100) Chikorita str\n",
      "(65, 100) Darkrai str\n",
      "(209, 100) Eevee str\n",
      "(104, 100) test05022023 str\n"
     ]
    }
   ],
   "source": [
    "# plot \n",
    "window = 7\n",
    "trialsinsess = 100\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "rr_mean_dict_unstr = {}\n",
    "# rem_les = sessdf[~(sessdf.task.isin(['dms', 'dls', 'sham']))]\n",
    "fish = ['test05022023', 'Blissey', 'Chikorita', 'Darkrai', 'Eevee']\n",
    "\n",
    "colors ={'str':'#1e2761', 'unstr':'#7a2048', 'dls':'xkcd:gold', 'dms':'xkcd:red', 'sham':'b', 'dms_str':'xkcd:orange'} \n",
    "for i in ['unstr', 'str']:\n",
    "\n",
    "    for ind, (animal, group) in enumerate(sessdf[sessdf.animal.isin(fish)].groupby('animal')):\n",
    "        ax = plt.subplot(4, 7, ind+1)\n",
    "        \n",
    "        # remove duplicates - if a session has duplicates remove it \n",
    "        # group = group.loc[~(sessdf.groupby('animal').get_group(animal)\n",
    "        #                           .duplicated(subset = 'trialstart', keep = False))]\n",
    "        \n",
    "        # filter by sessions>= length\n",
    "        filtered = (group[group.env.isin(['str']) & (group.task.isin([i]))]\n",
    "                    .groupby('session')).filter(lambda x: x.reward.size >= trialsinsess)\n",
    "\n",
    "        # take only those sessions\n",
    "        filtered = filtered.groupby('session').head(trialsinsess)\n",
    "        if filtered.empty==True:\n",
    "            continue\n",
    "            \n",
    "        # convert to numpy array\n",
    "        g = filtered.groupby('session').cumcount()\n",
    "        L = np.array(filtered.set_index(['session',g])\n",
    "               .unstack(fill_value=0)\n",
    "               .stack().groupby(level=0)\n",
    "               .apply(lambda x: x.rr.values.tolist())\n",
    "               .tolist())\n",
    "        \n",
    "        print(L.shape, animal, i)\n",
    "        # mean\n",
    "        rr_mean = np.mean(L, axis=0)\n",
    "        # reg_sem = np.std(L)\n",
    "        rr_mean_dict_unstr[animal, i] = rr_mean\n",
    "        ax.plot(rr_mean, label = i, c = colors[i])\n",
    "        # ax.fill_between(np.arange(trialsinsess), reg_sem+reg_mean, reg_mean-reg_sem, color = colors[i], alpha = 0.2)\n",
    "        ax.set_title(animal)\n",
    "        # ax.legend(['Pure unstructured','__', 'Structured (in unstr)'])\n",
    "        ax.set_xlabel('Trial')\n",
    "\n",
    "sns.despine()\n",
    "fig.supylabel('Reward rate, averaged across sessions')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b9c492ca-1d6a-4914-ae36-abb6f168e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average reponse and add structured in structured also\n",
    "plt.figure(figsize = (5,4.5))\n",
    "temp_unstr, temp_str, temp_str_str = [], [], []\n",
    "\n",
    "# set properties\n",
    "smooth = True\n",
    "window = 3\n",
    "label1 = 'Structured (in unstr)'\n",
    "label2 = 'Structured (in str)'\n",
    "# label3 = 'Structured (in str)'\n",
    "color1 = 'xkcd:azure'\n",
    "color2 = 'xkcd:slate grey'\n",
    "# color1 = '#7a2048', \n",
    "color1 = 'xkcd:olive'\n",
    "color2 = 'xkcd:emerald green'\n",
    "# color3 = 'xkcd:magenta'\n",
    "# color2 = '#408ec6'\n",
    "\n",
    "# set data for plotting\n",
    "# fish = ['Blissey', 'Darkrai', 'Mesprit', 'Quilava', 'Raltz', 'Inkay']\n",
    "# fish = ['Hoppip', 'Kirlia', 'Nidorina', 'Togepi']\n",
    "# fish = ['test05022023', 'Jirachi', 'Goldeen', 'Phione']\n",
    "fish = ['test05022023', 'Blissey', 'Chikorita', 'Darkrai', 'Eevee']\n",
    "for (animal, env) in rr_mean_dict_unstr.keys():\n",
    "    if animal in fish:\n",
    "        if env == 'unstr':\n",
    "            temp_unstr.append(rr_mean_dict_unstr[(animal, env)])\n",
    "        elif (env == 'str'):\n",
    "            temp_str.append(rr_mean_dict_unstr[(animal, env)])\n",
    "            # temp_str_str.append(rr_mean_dict[(animal, env)])\n",
    "\n",
    "# calculate performance index\n",
    "# temp_unstr = (1-np.array(temp_unstr)/100)\n",
    "# temp_str = (1-np.array(temp_str)/100)\n",
    "temp_unstr = np.array(temp_unstr)\n",
    "temp_str = np.array(temp_str)\n",
    "# temp_str_str = np.array(temp_str_str)\n",
    "\n",
    "# smoothing details\n",
    "if smooth:           \n",
    "    for i, row in enumerate(temp_unstr):\n",
    "        temp_unstr[i] = np.convolve(row, np.ones(window)/window, 'same')\n",
    "        temp_str[i] = np.convolve(temp_str[i], np.ones(window)/window, 'same')\n",
    "        # temp_str_str[i] = np.convolve(temp_str_str[i], np.ones(window)/window, 'same')\n",
    "    # \n",
    "    # works only for odd windows\n",
    "    temp_unstr[:, 0:(window//2)] = np.nan\n",
    "    temp_unstr[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "    \n",
    "    temp_str[:, 0:(window//2)] = np.nan\n",
    "    temp_str[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "\n",
    "    # temp_str_str[:, 0:(window//2)] = np.nan\n",
    "    # temp_str_str[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "\n",
    "# take mean of smoothed data   \n",
    "mean_unstr = (np.mean(np.array(temp_unstr), axis = 0))\n",
    "mean_str = (np.mean(np.array(temp_str), axis = 0))\n",
    "# mean_str_str = (np.mean(np.array(temp_str_str), axis = 0))\n",
    "\n",
    "# plot line 1\n",
    "plt.plot(np.arange(trialsinsess), mean_unstr, color1, label = label1) \n",
    "plt.fill_between(np.arange(trialsinsess), mean_unstr+sem(temp_unstr, nan_policy = 'omit'),\n",
    "                 mean_unstr-sem(temp_unstr, nan_policy = 'omit'), color = color1, alpha = 0.2)\n",
    "\n",
    "# plot line 2 (or comment)\n",
    "plt.plot(np.arange(trialsinsess), mean_str, color2, label = label2)\n",
    "plt.fill_between(np.arange(trialsinsess), mean_str+sem(temp_str, nan_policy = 'omit'), \n",
    "                 mean_str-sem(temp_str, nan_policy = 'omit'), color = color2, alpha = 0.2)\n",
    "\n",
    "# plot line 3 (or comment)\n",
    "# plt.plot(np.arange(trialsinsess), mean_str_str, color3, label = label3)\n",
    "# plt.fill_between(np.arange(trialsinsess), mean_str_str+sem(temp_str_str, nan_policy = 'omit'), \n",
    "#                  mean_str_str-sem(temp_str_str, nan_policy = 'omit'), color = color3, alpha = 0.2)\n",
    "\n",
    "# plot significance\n",
    "# pvals = ttest_rel(temp_str, temp_unstr)[1]\n",
    "# pvals_ind = [ind for ind, i in enumerate(pvals) if i < 0.05]\n",
    "# plt.scatter(pvals_ind, [0.65]*len(pvals_ind), marker = '.', color = 'r', alpha = 0.4) #(6, 2, 60) for asterisks\n",
    "\n",
    "# plot settings\n",
    "plt.xlabel('Trials in session', fontsize = 'x-large')\n",
    "plt.ylabel('Reward rate', fontsize = 'x-large')\n",
    "plt.xlim(0, trialsinsess)\n",
    "# plt.axhline(0.625, color='k', linestyle = '--') # chance calc by\n",
    "# plt.ylim(0.6, 0.95)\n",
    "plt.xticks([0, 25, 50, 75, 100], [1, '', '', '', 100], color = 'grey', fontsize = 'large')\n",
    "plt.ylim(0.4, 0.7)\n",
    "\n",
    "plt.yticks([0.4, 0.5, 0.6, 0.7], [0.4, '', '', 0.7], color = 'grey', fontsize = 'large')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "sns.despine()\n",
    "# sns.set_context('talk')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('C:/Users/dlab/OneDrive - Indian Institute of Science/Drawings/awp1/entropy_n_21.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724ade9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Bias analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59803489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stolen from Sanika\n",
    "#plot number of times each port was chosen/total trials in block as a function of rewprob at that port, for all trials indf; average across blocks\n",
    "port_choices = [1, 2, 3, 4]\n",
    "#group by unique rewprob values, find unique rewprob values across all ports first\n",
    "colors_ports = ['red', 'green', 'blue', 'purple']\n",
    "unique_rewprobs = np.unique(sessdf['rewprob'])\n",
    "# print(unique_rewprobs)\n",
    "#remove nan from unique_rewprobs\n",
    "unique_rewprobs = unique_rewprobs[~np.isnan(unique_rewprobs)]\n",
    "# print(unique_rewprobs)\n",
    "#remove rows with nan rewprob\n",
    "# sessdf = sessdf[~sessdf['rewprob'].isna()]\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "cond = 'dls'\n",
    "mask = (sessdf.task == cond) & (sessdf.animal.isin(an_dict[cond])) #& (sessdf.sess_bin >= 4)\n",
    "\n",
    "nanimals = sessdf[mask].animal.nunique()\n",
    "pn = 1\n",
    "\n",
    "for animal, group in sessdf[mask].groupby('animal'):\n",
    "    #for every block, calculate number of times each port was chosen/total trials in block for each unique rewprob value\n",
    "    nblocks = group['session'].nunique()\n",
    "    port_choice_matrix = np.zeros((len(unique_rewprobs), len(port_choices), nblocks))\n",
    "    #for all blocks\n",
    "    #save all rewprobfull per block in a list\n",
    "    for block in range(1, group['session'].nunique()+1):\n",
    "        block_data = group[group['session'] == block]\n",
    "        #for all ports\n",
    "        for p, port in enumerate(port_choices):\n",
    "            port_data = block_data[block_data['port'] == port]\n",
    "            #for all unique rewprobs\n",
    "            for r, rewprob in enumerate(unique_rewprobs):\n",
    "                n_choices = len(port_data[port_data['rewprob'] == rewprob])\n",
    "                port_choice_matrix[r, p, block-1] = n_choices\n",
    "\n",
    "    bias_matrix = np.zeros((port_choice_matrix.shape[0], port_choice_matrix.shape[1]))\n",
    "    counter = np.zeros((port_choice_matrix.shape[0], port_choice_matrix.shape[1]))\n",
    "\n",
    "    for p in range(port_choice_matrix.shape[1]):\n",
    "        for r in range(port_choice_matrix.shape[0]):\n",
    "            bias_matrix[r, p] = 0\n",
    "            for b in range(port_choice_matrix.shape[2]):\n",
    "                ntrls = np.sum(port_choice_matrix[:,:,b])\n",
    "                if ntrls != 0:\n",
    "                    bias_matrix[r, p] += port_choice_matrix[r, p, b] / ntrls\n",
    "                if port_choice_matrix[r, p, b] > 0:\n",
    "                    counter[r, p] += 1\n",
    "\n",
    "    #divide fin_mat by counter\n",
    "    for p in range(port_choice_matrix.shape[1]):\n",
    "        for r in range(port_choice_matrix.shape[0]):\n",
    "            if counter[r, p] > 0:\n",
    "                bias_matrix[r, p] = bias_matrix[r, p] / counter[r, p]\n",
    "# print('Bias matrix:', bias_matrix)\n",
    "\n",
    "    ax = plt.subplot(6, 8, pn)\n",
    "    #plot as line plots for each port\n",
    "    for p, port in enumerate(port_choices):\n",
    "        ax.plot([0,1,2,3], bias_matrix[:, p], label=f'Port {port}', marker='o', linewidth=2, color=colors_ports[p])\n",
    "    # plt.xlabel('Reward Probability')\n",
    "    ax.set_xticks([0,1,2,3], labels=[int(r) for r in unique_rewprobs])\n",
    "    # plt.ylabel(f'Fraction chosen (averaged across {nblocks} blocks)')\n",
    "    ax.set_title(f'{animal}')\n",
    "    pn+=1\n",
    "\n",
    "plt.tight_layout()\n",
    "    # n_rows, n_cols = bias_matrix.shape\n",
    "    # rpf = [10,15,46,80]\n",
    "    # labels = [i+1 for i in range(n_cols)]\n",
    "\n",
    "    # # Angles for radar\n",
    "    # angles = np.linspace(0, 2*np.pi, n_cols, endpoint=False)\n",
    "    # angles = np.concatenate([angles, [angles[0]]])  # close loop\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))\n",
    "    # for i in range(n_rows):\n",
    "    #     values = bias_matrix[i]\n",
    "    #     values = np.concatenate([values, [values[0]]])  # close loop\n",
    "\n",
    "    #     ax.plot(angles, values, linewidth=2, label=f'prob {rpf[i]}', color=colors_ports[i])\n",
    "    #     # ax.fill(angles, values, alpha=0.15)\n",
    "\n",
    "    # ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
    "    # #reduce the yticks to 3\n",
    "    # # ax.set_yticks([])\n",
    "    # ax.legend(loc='upper right', bbox_to_anchor=(1.25, 1.1))\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d40e6-206a-4d65-ba7d-0a14d61f14d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# predict avg performance based on reward probability - 25-09-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed57fcc3-76b5-4879-9f3a-0f1b35f166a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'assigned'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22488\\3692311628.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mrp_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massigned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# convert to numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'animal'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'session'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dlab\\miniforge3\\envs\\rishika\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'assigned'"
     ]
    }
   ],
   "source": [
    "#################################### perf grouped by rp ######################################\n",
    "# set_cwd('/home/rishika/sim/')\n",
    "%matplotlib qt\n",
    "window = 7\n",
    "trialsinsess = 100\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "# sessdf['rr'] = sessdf.groupby(['animal', 'session'], as_index = False).reward.rolling(window, center=True).mean().reward\n",
    "rr_mean_dict_rp = {}\n",
    "# rem_les = sessdf[~(sessdf.task.isin(['dms', 'dls', 'sham']))]\n",
    "\n",
    "colors ={'str':'#028f1e55', 'unstr':'#fb7d0755', 'dls':'xkcd:gold', 'dms':'xkcd:red', 'sham':'b', 'ds':'xkcd:orange'} \n",
    "for i in ['unstr']:\n",
    "\n",
    "    for ind, (rpfull_string, group) in enumerate(sessdf.groupby('rewprobfull')):\n",
    "        ax = plt.subplot(5, 8,  ind+1)\n",
    "        \n",
    "        # remove duplicates\n",
    "        # if animal == 'test05022023':\n",
    "        #     group = group.loc[~(sessdf.groupby('animal').get_group('test05022023')\n",
    "        #                               .duplicated(subset = 'trialstart', keep = False))]\n",
    "        \n",
    "        # filter by sessions>= length\n",
    "        filtered = (group[group.task.isin([i])]\n",
    "                    .groupby(['animal','session'])).filter(lambda x: x.reward.size >= trialsinsess)\n",
    "\n",
    "        # take only those sessions\n",
    "        filtered = filtered.groupby(['animal','session']).head(trialsinsess)\n",
    "        \n",
    "        # if animal=='Nidorina':\n",
    "        #     filtered = filtered[filtered.datetime.astype('datetime64[ns]')<datetime.datetime(2024, 5, 8)]\n",
    "        \n",
    "        if filtered.empty==True:\n",
    "            continue\n",
    "\n",
    "        rp_type = filtered.assigned.iloc[0]\n",
    "        \n",
    "        # convert to numpy array\n",
    "        g = filtered.groupby(['animal','session']).cumcount()\n",
    "        L = np.array(filtered.set_index(['animal','session',g])\n",
    "               .unstack(fill_value=0)\n",
    "               .stack().groupby(level = ['animal', 'session'])\n",
    "               .apply(lambda x: x.rr.values.tolist())\n",
    "               .tolist())\n",
    "        \n",
    "        # mean\n",
    "        rr_mean = np.mean(L, axis=0)\n",
    "        rr_mean_dict_rp[rpfull_string, rp_type] = rr_mean\n",
    "        ax.plot(rr_mean, label = i, c = 'k')\n",
    "        ax.set_title(rpfull_string.strip('[]'))\n",
    "        # ax.legend()\n",
    "        ax.set_facecolor(colors[rp_type])\n",
    "        # ax.set_xlabel('Trial')\n",
    "        ax.axhline(np.array(rpfull_string.strip('[]').split(), dtype = int).mean()/100, linestyle = '--', color = 'k')\n",
    "        ax.set_ylim(0.3, 0.8)\n",
    "\n",
    "sns.despine()\n",
    "fig.supylabel('Reward rate, averaged across sessions')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fd85a0bb-21e6-46a0-aa8f-9f187465f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "\n",
    "dat = pd.DataFrame(rr_mean_dict_rp).mean().sort_values().reset_index()\n",
    "dat.rename(columns = {'level_0':'rp', 'level_1':'rp_type', 0:'mu'}, inplace = True)\n",
    "sns.barplot(dat, x = 'rp', y = 'mu', hue = 'rp_type', palette = [color1, color2])\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "02914598-e1c0-48f7-a2e8-d5e14c9b87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "\n",
    "dat = pd.DataFrame(rr_mean_dict_rp).head(50).mean().sort_values().reset_index()\n",
    "dat.rename(columns = {'level_0':'rp', 'level_1':'rp_type', 0:'mu'}, inplace = True)\n",
    "sns.barplot(dat, x = 'rp', y = 'mu', hue = 'rp_type', palette = [color2, color1])\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.title('first 50')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c53bf350-774a-40fa-8a61-b9b90226e34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\miniforge3\\envs\\rishika\\lib\\site-packages\\ipykernel\\eventloops.py:145: UserWarning: The figure layout has changed to tight\n",
      "  el.exec() if hasattr(el, \"exec\") else el.exec_()\n"
     ]
    }
   ],
   "source": [
    "ax = plt.subplot(111)\n",
    "\n",
    "dat = pd.DataFrame(rr_mean_dict_rp).tail(50).mean().sort_values().reset_index()\n",
    "dat.rename(columns = {'level_0':'rp', 'level_1':'rp_type', 0:'mu'}, inplace = True)\n",
    "sns.barplot(dat, x = 'rp', y = 'mu', hue = 'rp_type', palette = [color1, color2])\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.title('last 50')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e2c4a073-4419-4b2d-989e-599397ec37ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\miniforge3\\envs\\rishika\\lib\\site-packages\\ipykernel\\eventloops.py:145: UserWarning: The figure layout has changed to tight\n",
      "  el.exec() if hasattr(el, \"exec\") else el.exec_()\n"
     ]
    }
   ],
   "source": [
    "ax = plt.subplot(111)\n",
    "\n",
    "dat = pd.DataFrame(rr_mean_dict_rp).tail(15).max().sort_values().reset_index()\n",
    "dat.rename(columns = {'level_0':'rp', 'level_1':'rp_type', 0:'mu'}, inplace = True)\n",
    "sns.barplot(dat, x = 'rp', y = 'mu', hue = 'rp_type', palette = [color1, color2])\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.title('max of last 15')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "dc003e93-e29d-44f7-836e-dee71906f033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\miniforge3\\envs\\rishika\\lib\\site-packages\\ipykernel\\eventloops.py:145: UserWarning: The figure layout has changed to tight\n",
      "  el.exec() if hasattr(el, \"exec\") else el.exec_()\n"
     ]
    }
   ],
   "source": [
    "ax = plt.subplot(111)\n",
    "\n",
    "dat = pd.DataFrame(rr_mean_dict_rp).median().sort_values().reset_index()\n",
    "dat.rename(columns = {'level_0':'rp', 'level_1':'rp_type', 0:'mu'}, inplace = True)\n",
    "sns.barplot(dat, x = 'rp', y = 'mu', hue = 'rp_type', palette = [color2, color1])\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.title('median')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5abfebe9-3770-4a63-b564-3def1d85ba86",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(temp_unstr):\n\u001b[0;32m     36\u001b[0m     temp_unstr[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconvolve(row, np\u001b[38;5;241m.\u001b[39mones(window)\u001b[38;5;241m/\u001b[39mwindow, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m     temp_str[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconvolve(\u001b[43mtemp_str\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, np\u001b[38;5;241m.\u001b[39mones(window)\u001b[38;5;241m/\u001b[39mwindow, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# works only for odd windows\u001b[39;00m\n\u001b[0;32m     40\u001b[0m temp_unstr[:, \u001b[38;5;241m0\u001b[39m:(window\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# plot average reponse\n",
    "plt.figure(figsize = (5,4.5))\n",
    "temp_unstr, temp_str = [], []\n",
    "\n",
    "# set properties\n",
    "smooth = True\n",
    "window = 3\n",
    "label1 = 'Unstructured'\n",
    "label2 = 'Structured'\n",
    "color1 = 'xkcd:azure'\n",
    "color2 = 'xkcd:slate grey'\n",
    "# color1 = '#7a2048', \n",
    "color1 = 'xkcd:pumpkin orange'\n",
    "color2 = 'xkcd:emerald green'\n",
    "# color2 = '#408ec6'\n",
    "\n",
    "# set data for plotting\n",
    "# fish = ['Blissey', 'Darkrai', 'Mesprit', 'Quilava', 'Raltz', 'Inkay']\n",
    "# fish = ['Hoppip', 'Kirlia', 'Nidorina', 'Togepi']\n",
    "# fish = ['test05022023', 'Jirachi', 'Goldeen', 'Phione']\n",
    "fish = ['test05022023', 'Blissey', 'Chikorita', 'Darkrai', 'Eevee']\n",
    "for (animal, env) in rr_mean_dict_rp.keys():\n",
    "    # if animal in fish:\n",
    "    if env == 'unstr':\n",
    "        temp_unstr.append(rr_mean_dict_rp[(animal, env)])\n",
    "    elif (env == 'str'):\n",
    "        temp_str.append(rr_mean_dict_rp[(animal, env)])\n",
    "\n",
    "# calculate performance index\n",
    "temp_unstr = np.array(temp_unstr)\n",
    "temp_str = np.array(temp_str)\n",
    "\n",
    "# smoothing details\n",
    "if smooth == True:           \n",
    "    for i, row in enumerate(temp_unstr):\n",
    "        temp_unstr[i] = np.convolve(row, np.ones(window)/window, 'same')\n",
    "        temp_str[i] = np.convolve(temp_str[i], np.ones(window)/window, 'same')\n",
    "    \n",
    "    # works only for odd windows\n",
    "    temp_unstr[:, 0:(window//2)] = np.nan\n",
    "    temp_unstr[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "    \n",
    "    temp_str[:, 0:(window//2)] = np.nan\n",
    "    temp_str[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "\n",
    "# take mean of smoothed data   \n",
    "mean_unstr = (np.mean(np.array(temp_unstr), axis = 0))\n",
    "mean_str = (np.mean(np.array(temp_str), axis = 0))\n",
    "\n",
    "# plot line 1\n",
    "plt.plot(np.arange(trialsinsess), mean_unstr, color1, label = label1) \n",
    "plt.fill_between(np.arange(trialsinsess), mean_unstr+sem(temp_unstr, nan_policy = 'omit'),\n",
    "                 mean_unstr-sem(temp_unstr, nan_policy = 'omit'), color = color1, alpha = 0.2)\n",
    "\n",
    "# plot line 2 (or comment)\n",
    "plt.plot(np.arange(trialsinsess), mean_str, color2, label = label2)\n",
    "plt.fill_between(np.arange(trialsinsess), mean_str+sem(temp_str, nan_policy = 'omit'), \n",
    "                 mean_str-sem(temp_str, nan_policy = 'omit'), color = color2, alpha = 0.2)\n",
    "\n",
    "# plot significance\n",
    "# pvals = ttest_rel(temp_str, temp_unstr)[1]\n",
    "# pvals_ind = [ind for ind, i in enumerate(pvals) if i < 0.05]\n",
    "# plt.scatter(pvals_ind, [0.65]*len(pvals_ind), marker = '.', color = 'r', alpha = 0.4) #(6, 2, 60) for asterisks\n",
    "\n",
    "# plot settings\n",
    "plt.xlabel('Trials in session', fontsize = 'x-large')\n",
    "plt.ylabel('Performance index', fontsize = 'x-large')\n",
    "plt.xlim(0, trialsinsess)\n",
    "plt.axhline(0.625, color='k', linestyle = '--') # chance calc by\n",
    "# plt.ylim(0.6, 0.85)\n",
    "plt.xticks([0, 25, 50, 75, 100], [1, '', '', '', 100], color = 'grey', fontsize = 'large')\n",
    "# plt.yticks([0.6, 0.65, 0.7, 0.75, 0.8, 0.85], ['0.60', '', '','','', 0.85], color = 'grey', fontsize = 'large')\n",
    "# plt.ylim(0, 0.8)\n",
    "plt.legend(loc='upper left')\n",
    "sns.despine()\n",
    "# sns.set_context('talk')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('C:/Users/dlab/OneDrive - Indian Institute of Science/Drawings/awp1/entropy_n_21.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572233ac-387c-45c2-96a3-440e652efa89",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# new rewprob-matched analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae204d7-6716-404c-a0db-f7051ceea30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# Process for each animal and offset in a single loop\n",
    "for n in range(-20, 21):\n",
    "    if n in [-2, -1, 0, 1, 2]:\n",
    "        continue\n",
    "\n",
    "    sessdf['entropy_shifted'] = (\n",
    "        sessdf.groupby(['animal', 'session'])['entropy'].shift(-n)\n",
    "    )\n",
    "\n",
    "    ported = (\n",
    "        sessdf[sessdf['task'] == 'unstr']\n",
    "        .groupby(['animal', 'session', 'rewprob', 'reward'], as_index=False)['entropy_shifted']\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    grouped = ported.groupby(['animal', 'rewprob', 'reward'], as_index=False)['entropy_shifted'].mean()\n",
    "    grouped['offset'] = n\n",
    "\n",
    "    # Append to results\n",
    "    results.append(grouped)\n",
    "\n",
    "# Combine results\n",
    "final_df = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0fb52f-d359-4eed-8000-78c55a0fd8d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m rew_an_dict, unrew_an_dict, diff_dict \u001b[38;5;241m=\u001b[39m {}, {}, {}\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Add NaNs in the middle\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m nan_series \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mSeries([np\u001b[38;5;241m.\u001b[39mnan] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m an \u001b[38;5;129;01min\u001b[39;00m final_df\u001b[38;5;241m.\u001b[39manimal\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# calc for each animal, for each rp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rewprob \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m46\u001b[39m, \u001b[38;5;241m80\u001b[39m]:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "rew_an_dict, unrew_an_dict, diff_dict = {}, {}, {}\n",
    "# Add NaNs in the middle\n",
    "nan_series = pd.Series([np.nan] * 5, index=range(-2, 3))\n",
    "\n",
    "for an in final_df.animal.unique():\n",
    "    # calc for each animal, for each rp\n",
    "    for rewprob in [10, 15, 46, 80]:\n",
    "        unrew = (final_df[(final_df['rewprob'] == rewprob) & (final_df['reward'] == 0) & (final_df['animal']==an)]\n",
    "            .set_index('offset')['entropy_shifted'])\n",
    "        rew = (final_df[(final_df['rewprob'] == rewprob) & (final_df['reward'] == 1) & (final_df['animal']==an)]\n",
    "            .set_index('offset')['entropy_shifted'])\n",
    "    \n",
    "        rew_an_dict[(an, rewprob)] = pd.concat([rew.iloc[:18], nan_series, rew.iloc[18:]])\n",
    "        unrew_an_dict[(an, rewprob)] = pd.concat([unrew.iloc[:18], nan_series, unrew.iloc[18:]])\n",
    "        diff_dict[(an, rewprob)] = unrew_an_dict[(an, rewprob)] - rew_an_dict[(an, rewprob)]\n",
    "    # if diff_dict[(an, rewprob)].isna().sum() > 0:\n",
    "    #     print(an, rewprob)\n",
    "data = pd.DataFrame(diff_dict).T.reset_index().groupby('level_1')[np.arange(-20, 21)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "220cf951-f2d6-4a28-b19a-a75e1ed80cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"crest\", as_cmap=True)(np.linspace(0, 1, 4))\n",
    "\n",
    "for ind, rewprob in enumerate([10, 15, 46, 80]):\n",
    "    plt.plot(data.T[ind], '.-', color = colors[ind], label = rewprob)\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c49ae-ec85-424f-9c4c-2fbe1ca1288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a filter for sessions to have one of each rp in that session\n",
    "# rpfull = sessdf.rewprobfull\n",
    "# sessdf['num_rp'] = [len(np.unique(np.array(x.strip('[]').split(), dtype = int))) for x in rpfull] \n",
    "\n",
    "# mask = (\n",
    "#     sessdf\n",
    "#     .groupby(['animal', 'session'], as_index=False)\n",
    "#     .apply(lambda g: g['rewprob'].nunique() == g['num_rp'].iloc[0])\n",
    "# )\n",
    "results = []\n",
    "mask.columns = ['animal', 'session', 'is_valid']\n",
    "cond = 'sham'\n",
    "an_list = an_dict[cond]\n",
    "\n",
    "filtered_sessdf = sessdf.merge(mask[mask['is_valid']], on=['animal', 'session'], how='inner')\n",
    "filtered_sessdf = filtered_sessdf[(filtered_sessdf.animal.isin(an_list))]\n",
    "# Process for each animal and offset in a single loop\n",
    "for n in range(-20, 21):\n",
    "    if n in [-2, -1, 0, 1, 2]:\n",
    "        continue\n",
    "\n",
    "    filtered_sessdf['entropy_shifted'] = (\n",
    "        filtered_sessdf.groupby(['animal', 'session'])['entropy'].shift(-n)\n",
    "    )\n",
    "\n",
    "    ported = (\n",
    "        filtered_sessdf[filtered_sessdf['task'] == 'unstr']\n",
    "        .groupby(['animal', 'session', 'rewprob', 'reward'], as_index=False)['entropy_shifted']\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    grouped = ported.groupby(['animal', 'rewprob', 'reward'], as_index=False)['entropy_shifted'].mean()\n",
    "    grouped['offset'] = n\n",
    "\n",
    "    # Append to results\n",
    "    results.append(grouped)\n",
    "\n",
    "# Combine results\n",
    "final_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "rew_an_dict, unrew_an_dict, diff_dict = {}, {}, {}\n",
    "# Add NaNs in the middle\n",
    "nan_series = pd.Series([np.nan] * 5, index=range(-2, 3))\n",
    "\n",
    "for an in final_df.animal.unique():\n",
    "    # calc for each animal, for each rp\n",
    "    for rewprob in [10, 15, 46, 80]:\n",
    "        unrew = (final_df[(final_df['rewprob'] == rewprob) & (final_df['reward'] == 0) & (final_df['animal']==an)]\n",
    "            .set_index('offset')['entropy_shifted'])\n",
    "        rew = (final_df[(final_df['rewprob'] == rewprob) & (final_df['reward'] == 1) & (final_df['animal']==an)]\n",
    "            .set_index('offset')['entropy_shifted'])\n",
    "    \n",
    "        rew_an_dict[(an, rewprob)] = pd.concat([rew.iloc[:18], nan_series, rew.iloc[18:]])\n",
    "        unrew_an_dict[(an, rewprob)] = pd.concat([unrew.iloc[:18], nan_series, unrew.iloc[18:]])\n",
    "        diff_dict[(an, rewprob)] = unrew_an_dict[(an, rewprob)] - rew_an_dict[(an, rewprob)]\n",
    "data = pd.DataFrame(diff_dict).T.reset_index().groupby('level_1')[np.arange(-20, 21)].mean().T.to_numpy()\n",
    "\n",
    "colors = sns.color_palette(\"crest\", as_cmap=True)(np.linspace(0, 1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a2e6fc70-f101-41fe-b01a-f8d5d07a1752",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for ind, rewprob in enumerate([10, 15, 46, 80]):\n",
    "    plt.plot(data.T[ind], '.-', color = colors[ind], label = rewprob)\n",
    "plt.legend()\n",
    "# plt.xticks(np.arange(-20, 20))\n",
    "plt.xlabel('Trials')\n",
    "plt.ylabel('Entropy no reward trials - reward trials')\n",
    "plt.ylim(-0.1, 0.25)\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9ee7acc4-ae1d-42d1-b2a3-ed41dc9d7acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "plt.figure(figsize = (20, 10))\n",
    "itera = 1\n",
    "pn=1\n",
    "col = 0\n",
    "ax = plt.subplot(7,4,pn)\n",
    "for key in diff_dict.keys():\n",
    "    \n",
    "    if itera % 4==0:\n",
    "        ax = plt.subplot(7,4,pn)\n",
    "        ax.set_title(key)\n",
    "        pn+=1\n",
    "        col = 0\n",
    "    ax.plot(diff_dict[key], '.-', color = colors[col])\n",
    "    col += 1\n",
    "    itera +=1\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e48398-9281-4cfc-890a-190c5645de6f",
   "metadata": {},
   "source": [
    "### why do DLS-lesioned animals only choose a few ports? are they able to perform perfectly (pre-lesion levels) in those sessions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a10376a2-d64d-493d-8419-388d080bb6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessdf['high_port'] = sessdf['rewprobfull'].apply(lambda x: np.where(np.array(x.strip('[]').split())=='80')[0][0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "325a5650-0a19-408e-a7a8-14690c94609a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rr_mean_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[191], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raltzdf\u001b[38;5;241m.\u001b[39mempty\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m ax\u001b[38;5;241m.\u001b[39mplot(\u001b[43mrr_mean_dict\u001b[49m[(rat, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munstr\u001b[39m\u001b[38;5;124m'\u001b[39m)], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# ax.set_xlim(trialsinsess)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# on this plot, plot mean RR curves for different highest rewprob along with transition matrix on right in smol\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# filter by sessions>= length\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m5\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rr_mean_dict' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "pn = 1\n",
    "trialsinsess = 25\n",
    "rr_port_dict = {}\n",
    "for rat in sessdf[sessdf.task == 'dls'].animal.unique():\n",
    "    ax = plt.subplot(3, 3, pn)\n",
    "    raltzdf = sessdf[(sessdf.task == 'dls') & (sessdf.animal == rat) & (sessdf.shift_t0 == 1)]\n",
    "    raltzdf = raltzdf.groupby('session').filter(lambda x: x.reward.size >= trialsinsess).groupby('session').head(trialsinsess)\n",
    "    if raltzdf.empty==True:\n",
    "        continue\n",
    "    ax.plot(rr_mean_dict[(rat, 'unstr')], 'k', label = 'all')\n",
    "    # ax.set_xlim(trialsinsess)\n",
    "    # on this plot, plot mean RR curves for different highest rewprob along with transition matrix on right in smol\n",
    "    # filter by sessions>= length\n",
    "    for n in range(1,5):\n",
    "        filtered = (sessdf[(sessdf.animal == rat) & (sessdf.high_port == n) & (sessdf.task == 'dls')]\n",
    "                    .groupby('session')).filter(lambda x: x.reward.size >= trialsinsess)\n",
    "        \n",
    "        # take only those sessions\n",
    "        filtered = filtered.groupby('session').head(trialsinsess)\n",
    "        if filtered.empty==True:\n",
    "            continue\n",
    "            \n",
    "        # convert to numpy array\n",
    "        g = filtered.groupby('session').cumcount()\n",
    "        L = np.array(filtered.set_index(['session', g])\n",
    "               .unstack(fill_value=0)\n",
    "               .stack().groupby(level=0)\n",
    "               .apply(lambda x: x.rr.values.tolist())\n",
    "               .tolist())\n",
    "        rr_port_dict[n] = np.mean(L, axis = 0)\n",
    "        ax.plot(rr_port_dict[n], label = n)\n",
    "        ax.set_title(rat)\n",
    "    ins = ax.inset_axes([0.7,0.7,0.25,0.25])\n",
    "    \n",
    "    sns.heatmap(pd.crosstab(raltzdf.port, raltzdf.choice_t1, normalize = 'index', dropna = False), \n",
    "                ax = ins,\n",
    "                cmap = 'YlGnBu',\n",
    "                annot = False,\n",
    "                fmt = '.2f',\n",
    "                vmin = 0.0,\n",
    "                vmax = 0.7,\n",
    "                square = True,\n",
    "                mask = np.eye(4),\n",
    "                xticklabels = np.arange(1,5),\n",
    "                yticklabels = np.arange(1,5))\n",
    "    ax.patch.set_facecolor('white')\n",
    "    sns.despine()\n",
    "    ax.legend()\n",
    "    pn+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1378f56-1712-4eba-b685-e8da61b7f9da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Early v/s late sessions - weekly analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a08ec521-2e4a-40ba-a049-7f5354eaa4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign week numbers to each session based on the date\n",
    "# min_year = pd.to_datetime(f\"{sessdf['datetime'].astype('datetime64[ns]').dt.year.min()}-01\")\n",
    "# sessdf['week'] = (sessdf['datetime'].astype('datetime64[ns]') - min_year) // pd.to_timedelta('7D') + 1\n",
    "\n",
    "# bin week numbers for each animal into 10 \n",
    "# sessdf['week_bin'] = sessdf.groupby('animal')['week'].transform(lambda x: pd.qcut(x, 7, labels = False, duplicates='drop'))\n",
    "# Mark each session number with a bin number. Each bin has 50 sessions.\n",
    "bin_size = 50\n",
    "sessdf['sess_bin'] = sessdf.groupby(['animal', 'task'])['session'].transform(lambda x: pd.cut(x, bins=range(0, x.max() + bin_size, bin_size), labels=False, right=False)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "2c8984d8-7a21-4e6e-8171-6618ab9adcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### regret ######################################\n",
    "window = 7\n",
    "trialsinsess = 100\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "sessdf['regret'] = abs(sessdf['rewprob'] - 80)\n",
    "\n",
    "reg_mean_dict_sess = {}\n",
    "\n",
    "colors ={'str':'#408ec6', 'unstr':'#7a2048', 'dls':'xkcd:gold', 'dms':'xkcd:red', 'sham':'b', 'ds':'xkcd:grey',\n",
    "         'dls_str':'red', 'dms_str':'xkcd:orange'} \n",
    "\n",
    "for ind, (animal, group) in enumerate(sessdf[sessdf.task == 'unstr'].groupby('animal')):\n",
    "    ax = plt.subplot(5, 7, ind+1)\n",
    "    cn = 0\n",
    "    for sess_b in group.sess_bin.unique():\n",
    "\n",
    "        # filter by sessions>= length\n",
    "        filtered = (group[group.task.isin(['unstr']) & (group.sess_bin == sess_b)]\n",
    "                    .groupby('session')).filter(lambda x: x.reward.size >= trialsinsess)\n",
    "\n",
    "        # take only those sessions\n",
    "        filtered = filtered.groupby('session').head(trialsinsess)\n",
    "        \n",
    "        if animal=='Nidorina':\n",
    "            filtered = filtered[filtered.datetime.astype('datetime64[ns]')<datetime.datetime(2024, 5, 8)]\n",
    "\n",
    "        if filtered.empty==True:\n",
    "            continue\n",
    "\n",
    "        # convert to numpy array\n",
    "        g = filtered.groupby('session').cumcount()\n",
    "        L = np.array(filtered.set_index(['session',g])\n",
    "                .unstack(fill_value=0)\n",
    "                .stack().groupby(level=0)\n",
    "                .apply(lambda x: x.regret.values.tolist())\n",
    "                .tolist())\n",
    "        # map colors from cmap viridis to each session bin\n",
    "        colors = plt.cm.cool_r(np.linspace(0, 1, len(group.sess_bin.unique())))\n",
    "\n",
    "        # mean\n",
    "        reg_mean = np.mean(L, axis = 0)\n",
    "        reg_mean_dict_sess[animal, sess_b] = reg_mean\n",
    "        ax.plot(reg_mean, color = colors[cn])\n",
    "        cn+=1\n",
    "    ax.set_title(animal)\n",
    "    ax.set_xlabel('Trial')\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "a161e8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_23560\\916938773.py:54: UserWarning: The label '_fish_' of <matplotlib.collections.PolyCollection object at 0x000001C4AA1DE5F0> starts with '_'. It is thus excluded from the legend.\n",
      "  plt.legend(['Naive','_fish_', 'Intermediate','_fish_', 'Expert'], loc = 'upper left')\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_23560\\916938773.py:54: UserWarning: The label '_fish_' of <matplotlib.collections.PolyCollection object at 0x000001C4AA1DEBF0> starts with '_'. It is thus excluded from the legend.\n",
      "  plt.legend(['Naive','_fish_', 'Intermediate','_fish_', 'Expert'], loc = 'upper left')\n"
     ]
    }
   ],
   "source": [
    "# plt.style.use('ggplot')\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('notebook')\n",
    "\n",
    "fig = plt.figure(figsize = (5,4.5))\n",
    "smooth = True\n",
    "# colors = plt.cm.cool_r(np.linspace(0, 1, len(sessdf.sess_bin.unique())+1))\n",
    "colors = plt.cm.cool_r(np.linspace(0, 1, 8))\n",
    "\n",
    "fish = ['test05022023', 'Blissey', 'Chikorita', 'Darkrai', 'Eevee']\n",
    "c = [0, 3, 7]\n",
    "ci = 0\n",
    "for sess_bin in range(1, 9):\n",
    "    temp_unstr = []\n",
    "    for (animal, env) in reg_mean_dict_sess.keys():\n",
    "        # if animal in fish:\n",
    "        if env == sess_bin:\n",
    "            temp_unstr.append(reg_mean_dict_sess[(animal, env)])\n",
    "\n",
    "    # calculate performance index\n",
    "    temp_unstr = (1-np.array(temp_unstr)/100)\n",
    "    temp_unstr = np.array(temp_unstr)\n",
    "    # temp_str = np.array(temp_str)\n",
    "\n",
    "    # smoothing details\n",
    "    if smooth == True:           \n",
    "        for i, row in enumerate(temp_unstr):\n",
    "            temp_unstr[i] = np.convolve(row, np.ones(window)/window, 'same')\n",
    "        \n",
    "        # works only for odd windows\n",
    "        temp_unstr[:, 0:(window//2)] = np.nan\n",
    "        temp_unstr[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "\n",
    "    # temp_unstr = [temp_unstr[i] for i in [0, 2, 6]]\n",
    "\n",
    "\n",
    "    # take mean of smoothed data   \n",
    "    mean_unstr = (np.mean(np.array(temp_unstr), axis = 0))\n",
    "\n",
    "    # plot line 1\n",
    "    plt.plot(np.arange(trialsinsess), mean_unstr, color = colors[c[ci]], label = f'sess bin {sess_bin}') \n",
    "    plt.fill_between(np.arange(trialsinsess), mean_unstr+sem(temp_unstr, nan_policy = 'omit'),\n",
    "                    mean_unstr-sem(temp_unstr, nan_policy = 'omit'), alpha = 0.2, color = colors[c[ci]])\n",
    "    ci+=1\n",
    "plt.xlabel('Trials in session', fontsize = 'x-large')\n",
    "plt.ylabel('Performance index', fontsize = 'x-large')\n",
    "plt.xlim(0, trialsinsess)\n",
    "# plt.ylim(0.1, 0.6)\n",
    "sns.despine()\n",
    "\n",
    "\n",
    "plt.xticks([0, 50, 100], [1, '', 100], fontsize = 'large', color = 'grey')\n",
    "plt.yticks([0.6, 0.7,0.8, 0.9], [0.6, '', '', 0.9], fontsize = 'large', color = 'grey')\n",
    "plt.legend(['Naive','_fish_', 'Intermediate','_fish_', 'Expert'], loc = 'upper left')\n",
    "plt.title(f'each session bin = {bin_size} sessions, n = {temp_unstr.shape[0]}')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "4018a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transition matrices for first n bins of sessions \n",
    "ind = 1\n",
    "trialsinsess = 100\n",
    "fig = plt.figure(figsize = (10, 4))\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "tempdf = tempdf[~(tempdf.animal.isin(['Kakuna', 'Finneon']))]\n",
    "an_list = tempdf.animal.unique()\n",
    "mat = np.zeros((len(an_list), 4, 4))\n",
    "\n",
    "\n",
    "for sess_bin in range(1,9):\n",
    "    ax = plt.subplot(2, 4, sess_bin)\n",
    "    temperdf = tempdf[(tempdf.sess_bin == sess_bin) & (tempdf.task == 'unstr')]\n",
    "    sns.heatmap(pd.crosstab(temperdf.port, temperdf.choice_t1, normalize = 'index', dropna = False),\n",
    "                cmap = parula_map,\n",
    "                annot = False,\n",
    "                fmt = '.2f',\n",
    "                vmin = 0.0,\n",
    "                vmax = 0.12,\n",
    "                square = True,\n",
    "                # mask = np.eye(4),\n",
    "                xticklabels = np.arange(1,5),\n",
    "                yticklabels = np.arange(1,5),\n",
    "                ax = ax)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_title(f'Sessions {sess_bin*bin_size-49} to {sess_bin*bin_size}')\n",
    "fig.supxlabel('Choice at trial t+1')\n",
    "fig.supylabel('Choice at trial t')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "94c1afa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dlab\\miniforge3\\envs\\rishika\\lib\\site-packages\\ipykernel\\eventloops.py:145: UserWarning: The figure layout has changed to tight\n",
      "  el.exec() if hasattr(el, \"exec\") else el.exec_()\n"
     ]
    }
   ],
   "source": [
    "# difference transition matrices for first n bins of sessions \n",
    "ind = 1\n",
    "trialsinsess = 100\n",
    "\n",
    "fig = plt.figure(figsize = (10, 4))\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "tempdf = tempdf[~(tempdf.animal.isin(['Kakuna', 'Finneon']))]\n",
    "an_list = tempdf.animal.unique()\n",
    "mat = np.zeros((len(an_list), 4, 4))\n",
    "\n",
    "\n",
    "for sess_bin in range(1,9):\n",
    "    ax = plt.subplot(2, 4, sess_bin)\n",
    "    temperdf = tempdf[(tempdf.sess_bin == sess_bin) & (tempdf.task == 'unstr')]\n",
    "    rew_mat = pd.crosstab(temperdf[temperdf.reward==1].port, temperdf[temperdf.reward==1].choice_t1, normalize = 'index', dropna = False)\n",
    "    unrew_mat = pd.crosstab(temperdf[temperdf.reward==0].port, temperdf[temperdf.reward==0].choice_t1, normalize = 'index', dropna = False)\n",
    "    sns.heatmap(rew_mat - unrew_mat,\n",
    "                cmap = \"seismic\",\n",
    "                annot = False,\n",
    "                fmt = '.2f',\n",
    "                vmin = -0.3,\n",
    "                vmax = 0.3,\n",
    "                square = True,\n",
    "                # mask = np.eye(4),\n",
    "                xticklabels = np.arange(1,5),\n",
    "                yticklabels = np.arange(1,5),\n",
    "                ax = ax)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_title(f'Sessions {sess_bin*bin_size-49} to {sess_bin*bin_size}')\n",
    "fig.supxlabel('Choice at trial t+1')\n",
    "fig.supylabel('Choice at trial t')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "fea8e473",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameGroupBy' object has no attribute 'dist_abs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[569], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m temperdf \u001b[38;5;241m=\u001b[39m tempdf[(tempdf\u001b[38;5;241m.\u001b[39msess_bin \u001b[38;5;241m==\u001b[39m sess_bin) \u001b[38;5;241m&\u001b[39m (tempdf\u001b[38;5;241m.\u001b[39mshift_t0 \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# calculate for each animal, mean and sem\u001b[39;00m\n\u001b[0;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m (\u001b[43mtemperdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manimal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m---> 16\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdist_abs\u001b[49m\n\u001b[0;32m     17\u001b[0m                       \u001b[38;5;241m.\u001b[39mvalue_counts(normalize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m     18\u001b[0m x\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdist_abs\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdivisor\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mSeries(randdisp)\u001b[38;5;241m.\u001b[39mvalue_counts(normalize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msort_index()\n",
      "File \u001b[1;32mc:\\Users\\dlab\\miniforge3\\envs\\rishika\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:952\u001b[0m, in \u001b[0;36mGroupBy.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attr]\n\u001b[1;32m--> 952\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    954\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrameGroupBy' object has no attribute 'dist_abs'"
     ]
    }
   ],
   "source": [
    "# distance moved for first n bins of sessions \n",
    "ind = 1\n",
    "trialsinsess = 100\n",
    "fig = plt.figure(figsize = (9, 5))\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "tempdf = tempdf[~(tempdf.animal.isin(['Kakuna', 'Finneon']))]\n",
    "an_list = tempdf.animal.unique()\n",
    "colors = plt.cm.cool_r(np.linspace(0, 1, 8))\n",
    "\n",
    "\n",
    "for sess_bin in range(1,9):\n",
    "    ax = plt.subplot(2, 4, sess_bin)\n",
    "    temperdf = tempdf[(tempdf.sess_bin == sess_bin) & (tempdf.shift_t0 == 1)]\n",
    "    # calculate for each animal, mean and sem\n",
    "    x = (temperdf.groupby('animal', as_index = False)\n",
    "                          .dist_abs\n",
    "                          .value_counts(normalize = True))\n",
    "    x.set_index('dist_abs', inplace = True)\n",
    "    x['divisor']=pd.Series(randdisp).value_counts(normalize = True).sort_index()\n",
    "    x['ratio']= x.proportion/x.divisor\n",
    "    x['log_odds']= x.ratio.apply(np.log2)\n",
    "    x['difference']=x.proportion-x.divisor\n",
    "    \n",
    "    mean_calc = x.reset_index().groupby('dist_abs').difference.mean()\n",
    "    sem_calc = x.reset_index().groupby('dist_abs').difference.sem()\n",
    "\n",
    "    # plot average statistic - although could have calculated this in a much much simpler way(?)\n",
    "    # statmat = x.sort_values(['dist_abs', 'animal']).reset_index()[['dist_abs', 'difference']].to_numpy().reshape(3, -1, 2)\n",
    "    # avg_grouped_statmat =  np.mean(statmat, axis = 1)\n",
    "\n",
    "    # plot here\n",
    "    ax.bar(np.array([1,2,3]), mean_calc, yerr = sem_calc, color = colors[sess_bin-1], width = 0.7)\n",
    "    ax.set_xticks([1,2,3], ['1', '2', '3'], fontsize = 'large', color = 'grey')\n",
    "    ax.axhline(0, color='k')\n",
    "    ax.set_yticks([-0.2, 0, 0.2, 0.4], ['-0.2', '0.0', '0.2', '0.4'], fontsize = 'large', color = 'grey')\n",
    "    sns.despine()\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_title(f'Sessions {sess_bin*bin_size-49} to {sess_bin*bin_size}')\n",
    "fig.supxlabel('Distance')\n",
    "fig.supylabel(\"$\\Delta$ probability of switching\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "c6459953",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialsinsess = 100\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "# & tempdf.animal.isin(['test05022023','Blissey', 'Chikorita', 'Darkrai', 'Eevee', 'Goldeen', 'Hoppip', 'Inkay', 'Jirachi', 'Kirlia', 'Nidorina', 'Phione', 'Quilava', 'Raltz', 'Togepi', 'Umbreon', 'Vulpix', 'Xatu', 'Yanma', 'Zacian'])\n",
    "tempdf = tempdf[~(tempdf.animal.isin(['Kakuna', 'Finneon'])) & (tempdf.task == 'unstr')]\n",
    "tempdf = tempdf[tempdf.sess_bin <= 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "id": "711d2694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dlab\\miniforge3\\envs\\rishika\\lib\\site-packages\\seaborn\\axisgrid.py:123: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1c5470ccd30>,\n",
       "  <matplotlib.axis.XTick at 0x1c5470ccca0>,\n",
       "  <matplotlib.axis.XTick at 0x1c5455a65c0>,\n",
       "  <matplotlib.axis.XTick at 0x1c6711b5c90>],\n",
       " [Text(1, 0, '1'), Text(2, 0, '2'), Text(3, 0, '3'), Text(4, 0, '4')])"
      ]
     },
     "execution_count": 933,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.displot(data = tempdf,\n",
    "            x = 'port',\n",
    "            stat = 'probability',\n",
    "            hue = 'sess_bin',\n",
    "            col = 'sess_bin',\n",
    "            col_wrap = 8,\n",
    "            common_norm = False,\n",
    "            bins = 4,\n",
    "            discrete = True, \n",
    "            palette = 'cool_r',\n",
    "            kind = 'hist')\n",
    "plt.xticks([1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d9e5d",
   "metadata": {},
   "source": [
    "# Bias by port proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "f612851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get most sampled to least sampled port for each animal in each session bin (L to R)\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "tempdf = tempdf[~(tempdf.animal.isin(['Kakuna', 'Finneon']))]\n",
    "\n",
    "# take port proportion and arrange by highest to lowest. then average highest with highest, second highest with second highest etc\n",
    "port_prop = tempdf[(tempdf.task == 'unstr') & (tempdf.sess_bin <= 8)].groupby(['animal', 'sess_bin'], as_index = False).port.value_counts(normalize = True, sort = True)\n",
    "port_prop['highness'] = port_prop.groupby(['animal', 'sess_bin']).cumcount()+1\n",
    "bars = port_prop.groupby(['sess_bin', 'highness']).proportion.mean().unstack().to_numpy()\n",
    "\n",
    "err = port_prop.groupby(['sess_bin', 'highness']).proportion.sem().unstack().to_numpy()\n",
    "\n",
    "colors = plt.cm.cool_r(np.linspace(0, 1, 8))\n",
    "plt.figure(figsize = (17, 3.5))\n",
    "for i in range(1, 9):\n",
    "    ax = plt.subplot(1, 8, i)\n",
    "    ax.bar(np.arange(1, 5), bars[i-1], color = colors[i-1], yerr = err[i-1])\n",
    "    ax.set_title(f'sess bin {i}')\n",
    "    ax.set_xticks([1, 4], ['Most \\n sampled',  'Least \\n sampled'], fontsize = 'large', color = 'grey')\n",
    "    ax.set_ylim([0, 0.6])\n",
    "    ax.set_yticks([0, 0.3, 0.6], ['0.0', '', '0.6'], fontsize = 'large', color = 'grey')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "696e7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each port, calculate the proportion of choices in each session bin. then calculate entropy in that session bin \n",
    "ys = port_prop.groupby(['animal', 'sess_bin']).proportion.apply(lambda x: entropy(x, base = 2)).groupby('sess_bin').mean().to_list()\n",
    "# ys = [ys[0], ys[2], ys[7]]\n",
    "yerrs = port_prop.groupby(['animal', 'sess_bin']).proportion.apply(lambda x: entropy(x, base = 2)).groupby('sess_bin').sem().to_list()\n",
    "# yerrs = [yerrs[0], yerrs[2], yerrs[7]]\n",
    "x = 1\n",
    "colors = plt.cm.cool_r(np.linspace(0, 1, 8))\n",
    "# colors = colors[[0, 3, 7]]\n",
    "x = 1\n",
    "for y, c in zip(ys, colors):\n",
    "    plt.bar(x, y, color=c, yerr = yerrs[ys.index(y)])\n",
    "    x +=1\n",
    "plt.ylim(0.8, 1.6)\n",
    "plt.yticks([0.8, 1.2, 1.6], [0.8, '', 1.6], fontsize = 'large', color = 'grey')\n",
    "plt.xticks(np.arange(1, 9), np.arange(1, 9), fontsize = 'large', color = 'grey')\n",
    "plt.xlabel('Session bin', fontsize = 'x-large')\n",
    "plt.ylabel('Entropy (bits)', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "d47ea21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLS group\n",
    "# get most sampled to least sampled port for each animal in each session bin (L to R)\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "tempdf = tempdf[~(tempdf.animal.isin(['Kakuna', 'Finneon']))]\n",
    "\n",
    "def calc_bias(tempdf, mask):\n",
    "# take port proportion and arrange by highest to lowest. then average highest with highest, second highest with second highest etc\n",
    "    port_prop = tempdf[mask].groupby('animal', as_index = False).port.value_counts(normalize = True, sort = True)\n",
    "    port_prop['highness'] = port_prop.groupby('animal').cumcount()+1\n",
    "    y = port_prop.groupby(['animal', 'highness']).proportion.mean().unstack().T.apply(lambda x: entropy(x, base = 2))\n",
    "    return y\n",
    "fish = ['test05022023', 'Blissey', 'Chikorita', 'Darkrai', 'Eevee']\n",
    "\n",
    "\n",
    "mask = (tempdf.task == 'unstr') & (tempdf.animal.isin(dls_an)) & (tempdf.sess_bin>=4)\n",
    "y_pre = calc_bias(tempdf, mask)\n",
    "y_pre_sem = y_pre.sem()\n",
    "\n",
    "mask = (tempdf.task == 'dls') & (tempdf.animal.isin(dls_an))\n",
    "y_les = calc_bias(tempdf, mask)\n",
    "y_les_sem = y_les.sem()\n",
    "\n",
    "plt.figure(figsize = (3.5, 4.5))\n",
    "plt.bar([0, 1], [y_pre.mean(), y_les.mean()], yerr = [y_pre_sem, y_les_sem], color = ['xkcd:azure', 'xkcd:slate grey'], width = 0.6)\n",
    "plt.xticks([0, 1], ['Pre-lesion', 'Post-lesion'], fontsize = 'large', color = 'grey')\n",
    "plt.ylim(1.25, 2)\n",
    "plt.yticks(fontsize = 'large', color = 'grey')\n",
    "plt.title(round(ttest_rel(y_pre, y_les)[1], 4))\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "009ece80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.zeros(len(y_pre)), y_pre, color = 'xkcd:azure', alpha = 0.5)\n",
    "plt.scatter(np.ones(len(y_les)), y_les, color = 'xkcd:slate grey', alpha = 0.5)\n",
    "for row in y_pre.index:\n",
    "    plt.plot([0, 1], [y_pre[row], y_les[row]], color = 'grey', alpha = 0.2)\n",
    "\n",
    "plt.xticks([0, 1], ['Pre-lesion', 'Post-lesion'], fontsize = 'large', color = 'grey')\n",
    "plt.ylim(0.0, 2)\n",
    "plt.yticks(fontsize = 'large', color = 'grey')\n",
    "plt.title(round(ttest_rel(y_pre, y_les)[1], 4))\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "ae8beba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "animal\n",
       "Blissey    0.724974\n",
       "Darkrai    0.728391\n",
       "Inkay      0.835456\n",
       "Mesprit    0.744715\n",
       "Quilava    0.793589\n",
       "Raltz      0.755387\n",
       "Zacian     0.830155\n",
       "Name: regret, dtype: float64"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- (tempdf[mask].groupby('animal').regret.mean()/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfaf8f0",
   "metadata": {},
   "source": [
    "# Frac of sessions vs session length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "task_arr = ['unstr', 'str', 'dls', 'dms', 'sham']\n",
    "\n",
    "an_list = [an_dict[task_arr[i]] for i in task_arr]\n",
    "colors = ['xkcd:pumpkin orange', 'xkcd:emerald green', 'xkcd:red', 'xkcd:gold', 'grey']\n",
    "for task in task_arr:\n",
    "    lendf = sessdf[(sessdf.task == task) & (sessdf.animal.isin(an_list[task_arr.index(task)]))].groupby(['animal', 'session']).trial.nunique().reset_index()\n",
    "    frac_array = np.zeros((2, lendf.trial.unique().shape[0]))\n",
    "    frac_array[0] = lendf.trial.unique()\n",
    "    frac_array[1] = [(lendf.trial>=trial).sum() for trial in lendf.trial.unique()]\n",
    "    plt.scatter(frac_array[0], frac_array[1]/lendf.shape[0], s = 2, c = colors[task_arr.index(task)])\n",
    "    if task =='unstr':\n",
    "        plt.plot(np.arange(max(frac_array[0]))[::-1], np.arange(max(frac_array[0]))/max(frac_array[0]), color = 'k', lw = 0.2, label = \"_nolegend_\")\n",
    "\n",
    "plt.ylabel('fraction of sessions with atleast x trials')\n",
    "plt.xlabel('trials in session')\n",
    "plt.legend(task_arr, markerscale = 5)\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "a7f2d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "task_arr = ['unstr', 'sham']\n",
    "fish = ['Blissey', 'Chikorita', 'Darkrai', 'Eevee', 'test05022023']\n",
    "dls_an = ['Blissey', 'Darkrai', 'Inkay', 'Mesprit', 'Quilava', 'Raltz', 'Zacian']\n",
    "dms_an = ['Hoppip', 'Kirlia', 'Nidorina', 'Togepi', 'Xatu']\n",
    "sham_an = ['test05022023','Jirachi', 'Goldeen', 'Phione', 'Umbreon', 'Vulpix']\n",
    "an_list = [sham_an, sham_an]\n",
    "# colors = ['xkcd:pumpkin orange', 'xkcd:emerald green', 'xkcd:red', 'xkcd:gold', 'grey']\n",
    "colors = ['xkcd:azure', 'xkcd:slate grey']\n",
    "for task in task_arr:\n",
    "    lendf = sessdf[(sessdf.task == task) & (sessdf.animal.isin(an_list[task_arr.index(task)]))].groupby(['animal', 'session']).trial.nunique().reset_index()\n",
    "    if task == 'unstr':\n",
    "        lendf = sessdf[(sessdf.task == task) & (sessdf.animal.isin(an_list[task_arr.index(task)]) & (sessdf.sess_bin >= 4))].groupby(['animal', 'session']).trial.nunique().reset_index()\n",
    "    frac_array = np.zeros((2, lendf.trial.unique().shape[0]))\n",
    "    frac_array[0] = lendf.trial.unique()\n",
    "    indices = np.argsort(frac_array[0])\n",
    "    frac_array[1] = [(lendf.trial>=trial).sum() for trial in lendf.trial.unique()]\n",
    "    a1 = np.array([frac_array[0][i] for i in indices])\n",
    "    b1 = np.array([frac_array[1][i] for i in indices])\n",
    "    # plt.scatter(frac_array[0], frac_array[1]/lendf.shape[0], s = 2, color = colors[task_arr.index(task)])\n",
    "    plt.plot(a1, b1/lendf.shape[0], '.-', color = colors[task_arr.index(task)])\n",
    "    # if task =='unstr':\n",
    "    #     plt.plot(np.arange(max(frac_array[0]))[::-1], np.arange(max(frac_array[0]))/max(frac_array[0]), color = 'k', lw = 0.2, label = \"_nolegend_\")\n",
    "\n",
    "plt.ylabel('Fraction of sessions with atleast x trials', fontsize = 'x-large')\n",
    "plt.xlabel('Trials in session', fontsize = 'x-large')\n",
    "plt.xlim(0, 250)\n",
    "plt.ylim(0, 1)\n",
    "plt.yticks([0, 0.25, 0.5, 0.75, 1], ['0.00', '0.25', '0.50', '0.75', '1.00'], fontsize = 'large', color = 'grey')\n",
    "plt.xticks([0, 50, 100, 150, 200, 250], ['0', '50', '100', '150', '200', '250'], fontsize = 'large', color = 'grey')\n",
    "plt.legend(['Unstructured', 'Sham'], markerscale = 2)\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "e0734580",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['level_0', 'level_1' ,90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
    "perf_ind = pd.DataFrame(reg_mean_dict_sess).apply(lambda x: 1-x/100).T.reset_index()[cols]\n",
    "perf_ind['avg'] = perf_ind[np.arange(90, 100)].mean(axis = 1)\n",
    "ys = perf_ind.groupby('level_1').avg.mean().iloc[1:9].to_list()\n",
    "yerrs = perf_ind.groupby('level_1').avg.sem().iloc[1:9].to_list()\n",
    "x = 1\n",
    "colors = plt.cm.cool_r(np.linspace(0, 1, len(ys)))\n",
    "for y, c in zip(ys, colors):\n",
    "    plt.bar(x, y, color=c, yerr = yerrs[ys.index(y)])\n",
    "    x +=1\n",
    "plt.ylim(0.7, 0.9)\n",
    "plt.yticks([0.7, 0.8, 0.9], [0.7, '', 0.9], fontsize = 'large', color = 'grey')\n",
    "plt.xticks(np.arange(1, 9), np.arange(1, 9), fontsize = 'large', color = 'grey')\n",
    "plt.xlabel('Session bin', fontsize = 'x-large')\n",
    "plt.ylabel('Performance index (trials 90-100)', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f035fd",
   "metadata": {},
   "source": [
    "# Entropy in a trial across sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f97c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_an_dict = {'unblocked': ['test05022023', 'Blissey', 'Chikorita', 'Darkrai', 'Eevee',\n",
    "       'Goldeen', 'Hoppip', 'Inkay', 'Jirachi', 'Kirlia', 'Mesprit',\n",
    "       'Nidorina', 'Oddish', 'Phione', 'Quilava', 'Raltz', 'Shinx',\n",
    "       'Togepi', 'Umbreon', 'Vulpix', 'Xatu', 'Yanma', 'Zacian',\n",
    "       'Alakazam', 'Bayleef', 'Cresselia'],\n",
    "       'cued':['Emolga', 'Giratina','Haxorus', 'Ivysaur',\n",
    "              'Jigglypuff', 'Lugia', 'Ninetales', 'Onix',\n",
    "              'Pichu'],\n",
    "       'uncued' : ['Quaxly', 'Torchic', 'Uxie', 'Vanillish',\n",
    "              'Whismur', 'Xerneas', 'Yamper', 'Zorua']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d80a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dlab\\banditAnalysis\\utils\\dfLoading.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sess_block'] = 0\n",
      "c:\\Users\\dlab\\banditAnalysis\\utils\\dfLoading.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sess_block'] = df.groupby(['animal', 'task']).sess_block.cumsum()\n",
      "c:\\Users\\dlab\\banditAnalysis\\utils\\dfLoading.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['block_group'] = df.groupby(['animal', 'task', 'session']).ngroup()\n",
      "c:\\Users\\dlab\\banditAnalysis\\utils\\dfLoading.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['block_group'] = (\n",
      "c:\\Users\\dlab\\banditAnalysis\\utils\\dfLoading.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['choice_t1'] = df.groupby(['animal','session']).port.shift(-1)\n",
      "c:\\Users\\dlab\\banditAnalysis\\utils\\dfLoading.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['choice_t2'] = df.groupby(['animal','session']).port.shift(-2)\n",
      "c:\\Users\\dlab\\banditAnalysis\\utils\\dfLoading.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['disp'] = df['choice_t1']-df['port']\n",
      "c:\\Users\\dlab\\banditAnalysis\\utils\\dfLoading.py:80: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['shift_t0'] = (df['choice_t1']==df['port']).replace({True: 0, False: 1})\n",
      "c:\\Users\\dlab\\banditAnalysis\\utils\\dfLoading.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['shift_t0'] = (df['choice_t1']==df['port']).replace({True: 0, False: 1})\n",
      "c:\\Users\\dlab\\banditAnalysis\\utils\\dfLoading.py:81: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['shift_t1'] = (df['choice_t2']==df['port']).replace({True: 0, False: 1})\n",
      "c:\\Users\\dlab\\banditAnalysis\\utils\\dfLoading.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['shift_t1'] = (df['choice_t2']==df['port']).replace({True: 0, False: 1})\n"
     ]
    }
   ],
   "source": [
    "#################################### moving entropy ######################################\n",
    "# set_cwd('/home/rishika/sim/')\n",
    "%matplotlib qt\n",
    "window = 5\n",
    "trialsinsess = 100\n",
    "# fig = plt.figure(figsize=(20,10))\n",
    "trialsinsess = 100\n",
    "df = sessdf\n",
    "from utils.dfLoading import subset_trials, add_block_groups, add_shift_info\n",
    "subset_df_nohead = add_block_groups(df[(df.task == 'unstr') & (df.animal.isin(block_an_dict['cued']))])\n",
    "subset_df_nohead = add_shift_info(subset_df_nohead)\n",
    "subset_df_nohead = subset_trials(subset_df_nohead, trialsinsess=trialsinsess, head_trials=trialsinsess)\n",
    "\n",
    "\n",
    "task = 'unstr'\n",
    "block_2_exists = (subset_df_nohead[(subset_df_nohead.block_group>=2) & (subset_df_nohead.task == task)]\n",
    "                  .groupby(['animal', 'sess_block'])\n",
    "                  .size()\n",
    "                  .reset_index()[['animal', 'sess_block']])\n",
    "\n",
    "# remove animals with less than 10\n",
    "block_2_exists = block_2_exists[block_2_exists.animal.isin(block_2_exists.animal.value_counts()[block_2_exists.animal.value_counts()>10].index)]\n",
    "\n",
    "# find first blocks for these sessions\n",
    "all_blocked_groups = subset_df_nohead[subset_df_nohead.task == task].merge(block_2_exists, on = ['animal', 'sess_block'])\n",
    "first_blocks = all_blocked_groups[all_blocked_groups.block_group == 1]\n",
    "second_blocks = all_blocked_groups[all_blocked_groups.block_group == 2]\n",
    "\n",
    "other_blocks = all_blocked_groups[all_blocked_groups.block_group > 1]\n",
    "\n",
    "entropy_mean_sess_dict = {}\n",
    "i = 'unstr'\n",
    "colors ={'str':'#408ec6', 'unstr':'#7a2048', 'dls':'xkcd:gold', 'dms':'xkcd:red', 'sham':'b', 'ds':'xkcd:orange'} \n",
    "for i in ['unstr', 'str', 'dms', 'dls', 'sham']:\n",
    "    for ind, (animal, group) in enumerate(other_blocks.groupby('animal')):\n",
    "        # ax = plt.subplot(5, 7, ind+1)\n",
    "\n",
    "        if i == 'unstr':\n",
    "            group = group[group.sess_bin>=4]\n",
    "        \n",
    "        # filter by sessions>= length\n",
    "        filtered = (group[group.task.isin([i])]\n",
    "                    .groupby('session')).filter(lambda x: x.reward.size >= trialsinsess)\n",
    "\n",
    "        # take only those sessions\n",
    "        filtered = filtered.groupby('session').head(trialsinsess)\n",
    "        \n",
    "        if animal=='Nidorina':\n",
    "            filtered = filtered[filtered.datetime.astype('datetime64[ns]')<datetime.datetime(2024, 5, 8)]\n",
    "        \n",
    "        if filtered.empty==True:\n",
    "            continue\n",
    "            \n",
    "        # convert to numpy array\n",
    "        g = filtered.groupby('session').cumcount()\n",
    "        L = np.array(filtered.set_index(['session',g])\n",
    "                .unstack(fill_value=0)\n",
    "                .stack(future_stack=True).groupby(level=0)\n",
    "                .apply(lambda x: x.port.values.tolist())\n",
    "                .tolist())\n",
    "        # mean\n",
    "        # entropy_trial = np.mean(L, axis = 0)\n",
    "        entropy_trial = [entropy(calc_prob(L[:, col]), base = 2) for col in range(L.shape[1])]\n",
    "        entropy_mean_sess_dict[animal, i] = entropy_trial\n",
    "        # ax.plot(entropy_trial, label = i, c = colors[i])\n",
    "        # ax.set_title(animal)\n",
    "        # ax.legend()\n",
    "\n",
    "\n",
    "# sns.despine()\n",
    "# fig.supylabel('Entropy, averaged across sessions')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "75008929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\4229600451.py:50: SmallSampleWarning: After omitting NaNs, one or more axis-slices of one or more sample arguments is too small; corresponding elements of returned arrays will be NaN. See documentation for sample size requirements.\n",
      "  plt.fill_between(np.arange(trialsinsess), mean_unstr+sem(temp_unstr, nan_policy = 'omit'),\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\4229600451.py:51: SmallSampleWarning: After omitting NaNs, one or more axis-slices of one or more sample arguments is too small; corresponding elements of returned arrays will be NaN. See documentation for sample size requirements.\n",
      "  mean_unstr-sem(temp_unstr, nan_policy = 'omit'), color = color1, alpha = 0.2)\n"
     ]
    }
   ],
   "source": [
    "# plot average reponse\n",
    "# plt.figure(figsize = (5,4.5))\n",
    "temp_unstr, temp_str = [], []\n",
    "from scipy.stats import sem\n",
    "# set properties\n",
    "smooth = True\n",
    "window = 3\n",
    "label1, label2 = 'Pre-lesion', 'Post-lesion'\n",
    "# label1, label2 = 'Unstructured', 'Structured'\n",
    "color1, color2 = 'xkcd:cornflower', 'xkcd:slate grey'\n",
    "# color1, color2 = 'xkcd:pumpkin orange', 'xkcd:emerald green'\n",
    "# color1, color2 = '#7a2048', '#408ec6'\n",
    "\n",
    "# set data for plotting\n",
    "fish = ['Blissey', 'Darkrai', 'Mesprit', 'Quilava', 'Raltz', 'Inkay', 'Zacian']\n",
    "# fish = ['Hoppip', 'Kirlia', 'Nidorina', 'Togepi', 'Xatu']\n",
    "# fish = ['test05022023', 'Jirachi', 'Goldeen', 'Phione', 'Umbreon', 'Vulpix']\n",
    "# fish = ['test05022023', 'Blissey', 'Chikorita', 'Darkrai', 'Eevee']\n",
    "# fish = ['Alakazam', 'Yanma']\n",
    "for (animal, env) in entropy_mean_sess_dict.keys():\n",
    "    # if animal in fish:\n",
    "    if env == 'unstr':\n",
    "        temp_unstr.append(entropy_mean_sess_dict[(animal, env)])\n",
    "        # elif (env == 'dls'):\n",
    "        #     temp_str.append(entropy_mean_sess_dict[(animal, env)])\n",
    "            \n",
    "if smooth:           \n",
    "    for i, row in enumerate(temp_unstr):\n",
    "        temp_unstr[i] = np.convolve(row, np.ones(3)/3, 'same')\n",
    "        # temp_str[i] = np.convolve(temp_str[i], np.ones(3)/3, 'same')\n",
    "    #     temp_dms[i] = np.convolve(temp_dms[i], np.ones(3)/3, 'same')\n",
    "\n",
    "    temp_unstr = np.array(temp_unstr)\n",
    "    # temp_str = np.array(temp_str)\n",
    "\n",
    "    # works only for odd windows\n",
    "    temp_unstr[:, 0:(window//2)] = np.nan\n",
    "    temp_unstr[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "    \n",
    "    # temp_str[:, 0:(window//2)] = np.nan\n",
    "    # temp_str[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "# # \n",
    "\n",
    "mean_unstr = (np.mean(np.array(temp_unstr), axis = 0))\n",
    "# mean_str = (np.mean(np.array(temp_str), axis = 0))\n",
    "# temp_str = (np.mean(np.array(temp_str), axis = 0))\n",
    "\n",
    "# [plt.plot(np.arange(trialsinsess), x, color = 'grey', alpha = 0.1) for x in temp_unstr]\n",
    "plt.plot(np.arange(trialsinsess), mean_unstr, color1, label = label1) #7a2048\n",
    "plt.fill_between(np.arange(trialsinsess), mean_unstr+sem(temp_unstr, nan_policy = 'omit'),\n",
    "                 mean_unstr-sem(temp_unstr, nan_policy = 'omit'), color = color1, alpha = 0.2)\n",
    "\n",
    "# plt.plot(np.arange(trialsinsess), mean_str, color2, label = label2)\n",
    "\n",
    "# plt.fill_between(np.arange(trialsinsess),mean_str+sem(temp_str, nan_policy = 'omit'), \n",
    "#                  mean_str-sem(temp_str, nan_policy = 'omit'), color = color2, alpha = 0.2)\n",
    "\n",
    "plt.xlabel('Trials in session', fontsize = 'x-large')\n",
    "plt.ylabel('Entropy (bits)', fontsize = 'x-large')\n",
    "plt.xlim(0, trialsinsess)\n",
    "# plt.ylim(1.5, 2.0)\n",
    "plt.xticks([0, 25, 50, 75, 100], [1, '', '', '', 100], color = 'grey', fontsize = 'large')\n",
    "# plt.yticks([1.25, 1.5, 1.75, 2.0], [1.25, '', '', 2.0], color = 'grey', fontsize = 'large')\n",
    "plt.title(f'n = {temp_unstr.shape[0]}')\n",
    "# plt.ylim(0, 0.8)\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "# sns.set_context('talk')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b89970",
   "metadata": {},
   "source": [
    "# switch distance comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "982e7b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dlab\\miniforge3\\envs\\rishika\\lib\\site-packages\\seaborn\\axisgrid.py:123: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.08)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.displot(data = tempdf[(tempdf.task == 'unstr') & (tempdf.sess_bin <= 8)], x = 'disp', discrete = True, col = 'sess_bin', col_wrap = 4, hue = 'sess_bin', palette='cool_r', stat = 'probability', common_norm = False, alpha = 1)\n",
    "plt.ylim(0., 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e657ce56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "tempdf['trial_num'] = tempdf.groupby(['animal', 'session']).cumcount()\n",
    "tempdf['trial_group'] = pd.cut(tempdf['trial_num']+1, bins = np.arange(0, 101, 10), labels = np.arange(1, 11))\n",
    "sns.displot(data = tempdf[(tempdf.task == 'unstr') & (tempdf.sess_bin <= 8)], x = 'disp', discrete = True, col = 'trial_group', col_wrap = 5, hue = 'trial_group', palette='crest', stat = 'probability', common_norm = False, alpha = 1)\n",
    "plt.ylim(0., 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91dc9d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_22440\\59138584.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n"
     ]
    }
   ],
   "source": [
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "tempdf = calc_dist_metric(tempdf, (tempdf.shift_t0==1) & (tempdf.task == 'unstr') & (tempdf.sess_bin <= 8))\n",
    "y = tempdf.groupby(['sess_bin','animal']).d_value.mean().unstack().mean(axis = 1)\n",
    "# y = [y[1], y[3], y[7]]\n",
    "yerr = tempdf.groupby(['sess_bin','animal']).d_value.mean().unstack().sem(axis = 1)\n",
    "# yerr = [yerr[1], yerr[3], yerr[7]]\n",
    "x = tempdf.groupby(['sess_bin','animal']).d_chance.mean().unstack().mean(axis = 1)\n",
    "# x = [x[1], x[3], x[7]]\n",
    "# colors = [plt.cm.cool_r(np.linspace(0, 1, 8)[0]), plt.cm.cool_r(np.linspace(0, 1, 8)[3]), plt.cm.cool_r(np.linspace(0, 1, 8)[7])]\n",
    "plt.figure()\n",
    "for i in y.index[:8]:    \n",
    "    plt.bar(i, y[i], color = plt.cm.cool_r(np.linspace(0, 1, 8)[int(i)-1]), yerr = yerr[i])\n",
    "plt.bar(np.arange(len(x))+1, x, color = 'grey', alpha = 0.2)\n",
    "# plt.xticks(np.arange(1, 4), ['Naive', 'Intermediate', 'Expert'], fontsize = 'large', color = 'grey')\n",
    "plt.xticks(np.arange(1, 9), np.arange(1, 9), fontsize = 'large', color = 'grey')\n",
    "plt.xlabel('Session bin', fontsize = 'x-large')\n",
    "plt.ylim(1, 1.65)\n",
    "plt.yticks([1, 1.2, 1.4, 1.6], [1,'', '', 1.6], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Distance metric', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7239de71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_26796\\2368743184.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_26796\\2368743184.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n"
     ]
    }
   ],
   "source": [
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "mask = ((tempdf.sess_bin >= 4) & (tempdf.shift_t0 == 1) & (tempdf.task == 'unstr'))\n",
    "dist_moved = calc_dist_metric(tempdf, mask).groupby('animal').d_value.mean()\n",
    "chance_move = calc_dist_metric(tempdf, mask).groupby('animal').d_chance.mean()\n",
    "\n",
    "plt.figure(figsize=(3.5,4))\n",
    "plt.bar(0, chance_move.mean(), color = 'grey',  yerr = chance_move.sem(), width = 0.6)\n",
    "plt.bar(1, dist_moved.mean(), color = 'xkcd:cornflower', yerr = dist_moved.sem(), width = 0.6)\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(1,1.65)\n",
    "plt.xticks([0, 1], ['Chance', 'Animal data'], fontsize = 'large', color = 'grey')\n",
    "plt.yticks([1, 1.2, 1.4, 1.6], [1,'', '', 1.6], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Distance moved', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "893eb376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\2368743184.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\2368743184.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n"
     ]
    }
   ],
   "source": [
    "# for r and nr\n",
    "def calc_dist_metric(tempdf, mask):\n",
    "    mean_distance = pd.Series([2, 4/3, 4/3, 2], index=[1, 2, 3, 4])\n",
    "\n",
    "    filtered = tempdf[mask]\n",
    "\n",
    "    # calculate `d_value` for each group\n",
    "    d_values = filtered.groupby(['animal', 'session'])['disp'].apply(lambda x: x.abs().mean())\n",
    "\n",
    "    # calculate `d_chance` for each group\n",
    "    d_chances = filtered.groupby(['animal', 'session']).apply(\n",
    "        lambda group: np.sum(group['port'].value_counts(normalize=True) * mean_distance)\n",
    "    )\n",
    "\n",
    "    tempdf['d_value'] = tempdf.set_index(['animal', 'session']).index.map(d_values).values\n",
    "    tempdf['d_chance'] = tempdf.set_index(['animal', 'session']).index.map(d_chances).values\n",
    "    return tempdf\n",
    "trialsinsess = 100\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "mask = (tempdf.reward == 0) & (tempdf.sess_bin >= 4) & (tempdf.shift_t0 == 1) & (tempdf.task == 'unstr')\n",
    "nr = calc_dist_metric(tempdf, mask)\n",
    "ys_nr = nr.groupby('animal').d_value.mean()\n",
    "\n",
    "mask = (tempdf.reward == 1) & (tempdf.sess_bin >= 4) & (tempdf.shift_t0 == 1) & (tempdf.task == 'unstr')\n",
    "r = calc_dist_metric(tempdf, mask)\n",
    "ys_r = r.groupby('animal').d_value.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ae8684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3.5,4))\n",
    "plt.bar(1, nr.groupby('animal').d_chance.mean().mean(), color = 'grey', alpha = 0.2, width = 0.6)\n",
    "plt.bar(1, ys_nr.mean(), color = 'blue', yerr = ys_nr.sem(), width = 0.6)\n",
    "plt.hlines(y = nr.groupby('animal').d_chance.mean().mean(), xmin = -0.3, xmax = 0.3, color = 'grey', ls = '--', lw = 2)\n",
    "plt.bar(0, r.groupby('animal').d_chance.mean().mean(), color = 'grey', alpha = 0.2, width = 0.6)\n",
    "plt.bar(0, ys_r.mean(), color = 'red', yerr = ys_r.sem(), width = 0.6)\n",
    "plt.hlines(y = r.groupby('animal').d_chance.mean().mean(), xmin = 1-0.3, xmax = 1+0.3, color = 'grey', ls = '--', lw = 2)\n",
    "\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(1,1.7)\n",
    "plt.xticks([0, 1], ['Reward', 'No reward'], fontsize = 'large', color = 'grey')\n",
    "plt.yticks([1, 1.2, 1.4, 1.6], [1,'', '', 1.6], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Distance metric', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f8c61dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=np.float64(5.6253652404618775), pvalue=np.float64(2.9110772608503093e-06), df=np.int64(33))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(ys_nr, ys_r, nan_policy='omit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730d94f2",
   "metadata": {},
   "source": [
    "##  changes with trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0bafd8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dlab\\rishika_sim\\utils\\dfLoading.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sess_block'] = 0\n",
      "c:\\Users\\dlab\\rishika_sim\\utils\\dfLoading.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sess_block'] = df.groupby(['animal', 'task']).sess_block.cumsum()\n",
      "c:\\Users\\dlab\\rishika_sim\\utils\\dfLoading.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['block_group'] = df.groupby(['animal', 'task', 'session']).ngroup()\n",
      "c:\\Users\\dlab\\rishika_sim\\utils\\dfLoading.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['block_group'] = (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "11\n",
      "12\n",
      "18\n",
      "19\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "92\n",
      "93\n",
      "103\n",
      "105\n",
      "106\n",
      "110\n",
      "112\n",
      "114\n",
      "115\n",
      "118\n",
      "124\n",
      "125\n",
      "128\n",
      "129\n",
      "132\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "178\n",
      "179\n",
      "180\n",
      "184\n",
      "185\n",
      "191\n",
      "192\n",
      "194\n",
      "195\n",
      "198\n",
      "208\n",
      "211\n",
      "222\n",
      "229\n",
      "235\n",
      "238\n",
      "245\n",
      "255\n",
      "257\n",
      "259\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "282\n",
      "284\n",
      "291\n",
      "304\n",
      "307\n",
      "308\n",
      "316\n",
      "333\n",
      "337\n",
      "338\n",
      "339\n",
      "341\n",
      "354\n",
      "360\n",
      "364\n",
      "371\n",
      "374\n",
      "375\n",
      "376\n",
      "379\n",
      "386\n",
      "392\n",
      "394\n",
      "395\n",
      "403\n",
      "412\n",
      "420\n",
      "424\n",
      "426\n",
      "428\n",
      "430\n",
      "436\n",
      "451\n",
      "452\n",
      "458\n",
      "459\n",
      "466\n",
      "467\n",
      "468\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "485\n",
      "486\n",
      "488\n",
      "489\n",
      "500\n",
      "501\n",
      "511\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "522\n",
      "523\n",
      "532\n",
      "533\n",
      "554\n",
      "555\n",
      "573\n",
      "574\n",
      "584\n",
      "585\n",
      "594\n",
      "595\n",
      "598\n",
      "603\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "617\n",
      "618\n",
      "649\n",
      "650\n",
      "736\n",
      "737\n",
      "805\n",
      "806\n",
      "882\n",
      "883\n",
      "933\n",
      "934\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "988\n",
      "989\n",
      "991\n",
      "992\n",
      "1050\n",
      "1051\n",
      "1139\n",
      "1140\n",
      "1142\n",
      "1143\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1151\n",
      "1152\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1214\n",
      "1215\n",
      "1223\n",
      "1224\n",
      "1226\n",
      "1227\n",
      "1248\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1322\n",
      "1323\n",
      "1329\n",
      "1330\n",
      "1338\n",
      "1339\n",
      "1343\n",
      "1344\n",
      "1346\n",
      "1347\n",
      "1349\n",
      "1350\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1374\n",
      "1375\n",
      "1377\n",
      "1378\n",
      "1391\n",
      "1392\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1417\n",
      "1418\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1442\n",
      "1443\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1494\n",
      "1495\n",
      "1502\n",
      "1503\n",
      "1505\n",
      "1506\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1523\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1534\n",
      "1535\n",
      "1537\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1545\n",
      "1548\n",
      "1549\n",
      "1551\n",
      "1552\n",
      "1554\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1568\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1577\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1585\n",
      "1586\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1594\n",
      "1595\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1607\n",
      "1610\n",
      "1612\n",
      "1613\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1624\n",
      "1625\n",
      "1627\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1640\n",
      "1646\n",
      "1649\n",
      "1650\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1659\n",
      "1662\n",
      "1664\n",
      "1666\n",
      "1667\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1676\n",
      "1680\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1730\n",
      "1732\n",
      "1734\n",
      "1735\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1742\n",
      "1743\n",
      "1746\n",
      "1747\n",
      "1751\n",
      "1754\n",
      "1757\n",
      "1758\n",
      "1760\n",
      "1762\n",
      "1765\n",
      "1768\n",
      "1769\n",
      "1771\n",
      "1772\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1779\n",
      "1780\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1792\n",
      "1794\n",
      "1796\n",
      "1797\n",
      "1800\n",
      "1803\n",
      "1807\n",
      "1808\n",
      "1810\n",
      "1811\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1827\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1836\n",
      "1838\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1888\n",
      "1889\n",
      "1900\n",
      "1901\n",
      "1904\n",
      "1905\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1937\n",
      "1938\n",
      "1945\n",
      "1946\n",
      "1952\n",
      "1953\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1980\n",
      "1981\n",
      "1994\n",
      "1995\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2026\n",
      "2027\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2040\n",
      "2041\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2091\n",
      "2092\n",
      "2108\n",
      "2110\n",
      "2120\n",
      "2125\n",
      "2131\n",
      "2145\n",
      "2149\n",
      "2161\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2167\n",
      "2171\n",
      "2178\n",
      "2196\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2226\n",
      "2231\n",
      "2247\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2259\n",
      "2263\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2280\n",
      "2282\n",
      "2283\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2298\n",
      "2302\n",
      "2303\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2323\n",
      "2324\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2352\n",
      "2353\n",
      "2358\n",
      "2359\n",
      "2363\n",
      "2364\n",
      "2367\n",
      "2376\n",
      "2378\n",
      "2380\n",
      "2382\n",
      "2384\n",
      "2394\n",
      "2403\n",
      "2409\n",
      "2414\n",
      "2417\n",
      "2419\n",
      "2420\n",
      "2422\n",
      "2423\n",
      "2434\n",
      "2436\n",
      "2437\n",
      "2440\n",
      "2441\n",
      "2445\n",
      "2466\n",
      "2487\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2508\n",
      "2509\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2519\n",
      "2522\n",
      "2526\n",
      "2538\n",
      "2618\n",
      "2625\n",
      "2626\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2644\n",
      "2645\n",
      "2647\n",
      "2648\n",
      "2650\n",
      "2651\n",
      "2658\n",
      "2665\n",
      "2674\n",
      "2704\n",
      "2719\n",
      "2724\n",
      "2745\n",
      "2769\n",
      "2787\n",
      "2798\n",
      "2807\n",
      "2808\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2827\n",
      "2829\n",
      "2830\n",
      "2832\n",
      "2833\n",
      "2837\n",
      "2838\n",
      "2840\n",
      "2841\n",
      "2843\n",
      "2845\n",
      "2846\n",
      "2850\n",
      "2854\n",
      "2855\n",
      "2858\n",
      "2861\n",
      "2864\n",
      "2865\n",
      "2867\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2894\n",
      "2896\n",
      "2899\n",
      "2900\n",
      "2902\n",
      "2906\n",
      "2910\n",
      "2911\n",
      "2913\n",
      "2915\n",
      "2919\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2928\n",
      "2929\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2937\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2948\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2957\n",
      "2958\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2968\n",
      "2969\n",
      "2972\n",
      "2977\n",
      "2978\n",
      "2980\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2986\n",
      "2987\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3005\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3015\n",
      "3016\n",
      "3018\n",
      "3020\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3031\n",
      "3032\n",
      "3034\n",
      "3035\n",
      "3038\n",
      "3039\n",
      "3041\n",
      "3043\n",
      "3044\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3053\n",
      "3054\n",
      "3056\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3066\n",
      "3068\n",
      "3070\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3079\n",
      "3080\n",
      "3082\n",
      "3084\n",
      "3085\n",
      "3091\n",
      "3097\n",
      "3098\n",
      "3100\n",
      "3102\n",
      "3105\n",
      "3106\n",
      "3107\n",
      "3109\n",
      "3110\n",
      "3113\n",
      "3118\n",
      "3119\n",
      "3121\n",
      "3123\n",
      "3124\n",
      "3125\n",
      "3129\n",
      "3130\n",
      "3131\n",
      "3132\n",
      "3135\n",
      "3139\n",
      "3141\n",
      "3144\n",
      "3145\n",
      "3147\n",
      "3149\n",
      "3150\n",
      "3151\n",
      "3152\n",
      "3153\n",
      "3154\n",
      "3155\n",
      "3158\n",
      "3161\n",
      "3165\n",
      "3166\n",
      "3171\n",
      "3174\n",
      "3175\n",
      "3176\n",
      "3178\n",
      "3179\n",
      "3181\n",
      "3182\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3191\n",
      "3193\n",
      "3194\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3205\n",
      "3206\n",
      "3214\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3227\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3234\n",
      "3236\n",
      "3238\n",
      "3240\n",
      "3241\n",
      "3244\n",
      "3245\n",
      "3251\n",
      "3252\n",
      "3254\n",
      "3256\n",
      "3257\n",
      "3259\n",
      "3260\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3267\n",
      "3274\n",
      "3275\n",
      "3291\n",
      "3292\n",
      "3296\n",
      "3297\n",
      "3302\n",
      "3303\n",
      "3308\n",
      "3309\n",
      "3324\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3335\n",
      "3336\n",
      "3341\n",
      "3342\n",
      "3371\n",
      "3372\n",
      "3400\n",
      "3401\n",
      "3409\n",
      "3410\n",
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3482\n",
      "3483\n",
      "3507\n",
      "3508\n",
      "3556\n",
      "3557\n",
      "3562\n",
      "3563\n",
      "3570\n",
      "3571\n",
      "3576\n",
      "3577\n",
      "3578\n",
      "3579\n",
      "3602\n",
      "3630\n",
      "3639\n",
      "3643\n",
      "3646\n",
      "3648\n",
      "3649\n",
      "3655\n",
      "3658\n",
      "3666\n",
      "3669\n",
      "3673\n",
      "3680\n",
      "3681\n",
      "3686\n",
      "3697\n",
      "3701\n",
      "3704\n",
      "3712\n",
      "3731\n",
      "3732\n",
      "3743\n",
      "3744\n",
      "3745\n",
      "3749\n",
      "3750\n",
      "3753\n",
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3759\n",
      "3761\n",
      "3762\n",
      "3764\n",
      "3765\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3773\n",
      "3775\n",
      "3777\n",
      "3779\n",
      "3780\n",
      "3783\n",
      "3784\n",
      "3788\n",
      "3794\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3803\n",
      "3805\n",
      "3806\n",
      "3810\n",
      "3811\n",
      "3816\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3828\n",
      "3829\n",
      "3834\n",
      "3836\n",
      "3840\n",
      "3841\n",
      "3843\n",
      "3845\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3855\n",
      "3857\n",
      "3858\n",
      "3864\n",
      "3867\n",
      "3868\n",
      "3872\n",
      "3876\n",
      "3877\n",
      "3884\n",
      "3885\n",
      "3887\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3897\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3914\n",
      "3918\n",
      "3920\n",
      "3922\n",
      "3925\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3962\n",
      "3963\n",
      "3964\n",
      "3965\n",
      "3992\n",
      "3993\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4002\n",
      "4003\n",
      "4005\n",
      "4006\n",
      "4015\n",
      "4016\n",
      "4018\n",
      "4019\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4029\n",
      "4030\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4052\n",
      "4053\n",
      "4055\n",
      "4056\n",
      "4058\n",
      "4059\n",
      "4061\n",
      "4062\n",
      "4068\n",
      "4069\n",
      "4072\n",
      "4073\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4085\n",
      "4086\n",
      "4088\n",
      "4090\n",
      "4095\n",
      "4096\n",
      "4105\n",
      "4106\n",
      "4109\n",
      "4110\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4122\n",
      "4123\n",
      "4133\n",
      "4134\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4150\n",
      "4151\n",
      "4152\n",
      "4159\n",
      "4160\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4189\n",
      "4190\n",
      "4196\n",
      "4197\n",
      "4201\n",
      "4202\n",
      "4211\n",
      "4212\n",
      "4213\n",
      "4214\n",
      "4215\n",
      "4216\n",
      "4217\n",
      "4218\n",
      "4219\n",
      "4223\n",
      "4224\n",
      "4225\n",
      "4229\n",
      "4230\n",
      "4231\n",
      "4232\n",
      "4235\n",
      "4236\n",
      "4239\n",
      "4240\n",
      "4243\n",
      "4244\n",
      "4245\n",
      "4246\n",
      "4247\n",
      "4248\n",
      "4249\n",
      "4250\n",
      "4251\n",
      "4252\n",
      "4253\n",
      "4254\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4266\n",
      "4267\n",
      "4268\n",
      "4269\n",
      "4271\n",
      "4272\n",
      "4273\n",
      "4274\n",
      "4277\n",
      "4278\n",
      "4286\n",
      "4287\n",
      "4288\n",
      "4289\n",
      "4291\n",
      "4292\n",
      "4312\n",
      "4313\n",
      "4314\n",
      "4315\n",
      "4411\n",
      "4412\n",
      "4416\n",
      "4417\n",
      "4418\n",
      "4419\n",
      "4426\n",
      "4427\n",
      "4463\n",
      "4464\n",
      "4465\n",
      "4466\n",
      "4468\n",
      "4469\n",
      "4479\n",
      "4480\n",
      "4482\n",
      "4483\n",
      "4487\n",
      "4488\n",
      "4489\n",
      "4490\n",
      "4491\n",
      "4492\n",
      "4493\n",
      "4494\n",
      "4495\n",
      "4496\n",
      "4497\n",
      "4501\n",
      "4502\n",
      "4504\n",
      "4507\n",
      "4510\n",
      "4513\n",
      "4514\n",
      "4515\n",
      "4520\n",
      "4523\n",
      "4524\n",
      "4525\n",
      "4526\n",
      "4527\n",
      "4528\n",
      "4529\n",
      "4530\n",
      "4531\n",
      "4532\n",
      "4535\n",
      "4536\n",
      "4538\n",
      "4539\n",
      "4541\n",
      "4542\n",
      "4597\n",
      "4598\n",
      "4656\n",
      "4694\n",
      "4695\n",
      "4696\n",
      "4697\n",
      "4709\n",
      "4710\n",
      "4711\n",
      "4713\n",
      "4714\n",
      "4715\n",
      "4724\n",
      "4725\n",
      "4727\n",
      "4728\n",
      "4730\n",
      "4733\n",
      "4734\n",
      "4741\n",
      "4742\n",
      "4754\n",
      "4757\n",
      "4759\n",
      "4787\n",
      "4788\n",
      "4799\n",
      "4800\n",
      "4809\n",
      "4810\n",
      "4812\n",
      "4816\n",
      "4817\n",
      "4820\n",
      "4829\n",
      "4836\n",
      "4837\n",
      "4844\n",
      "4845\n",
      "4848\n",
      "4850\n",
      "4854\n",
      "4855\n",
      "4856\n",
      "4857\n",
      "4858\n",
      "4861\n",
      "4862\n",
      "4863\n",
      "4864\n",
      "4865\n",
      "4866\n",
      "4868\n",
      "4870\n",
      "4871\n",
      "4873\n",
      "4874\n",
      "4875\n",
      "4877\n",
      "4878\n",
      "4883\n",
      "4884\n",
      "4885\n",
      "4905\n",
      "4906\n",
      "4909\n",
      "4911\n",
      "4912\n",
      "4915\n",
      "4918\n",
      "4921\n",
      "4924\n",
      "4925\n",
      "4926\n",
      "4927\n",
      "4930\n",
      "4933\n",
      "4934\n",
      "4939\n",
      "4940\n",
      "4946\n",
      "4953\n",
      "4958\n",
      "4969\n",
      "4971\n",
      "4973\n",
      "4987\n",
      "4988\n",
      "4999\n",
      "5001\n",
      "5003\n",
      "5005\n",
      "5016\n",
      "5019\n",
      "5020\n",
      "5022\n",
      "5026\n",
      "5027\n",
      "5028\n",
      "5033\n",
      "5039\n",
      "5041\n",
      "5046\n",
      "5047\n",
      "5050\n",
      "5053\n",
      "5057\n",
      "5065\n",
      "5066\n",
      "5069\n",
      "5080\n",
      "5094\n",
      "5098\n",
      "5105\n",
      "5108\n",
      "5109\n",
      "5110\n",
      "5114\n",
      "5116\n",
      "5118\n",
      "5121\n",
      "5122\n",
      "5123\n",
      "5132\n",
      "5136\n",
      "5140\n",
      "5141\n",
      "5143\n",
      "5144\n",
      "5146\n",
      "5148\n",
      "5151\n",
      "5152\n",
      "5153\n",
      "5155\n",
      "5179\n",
      "5181\n",
      "5186\n",
      "5188\n",
      "5193\n",
      "5194\n",
      "5200\n",
      "5201\n",
      "5202\n",
      "5211\n",
      "5212\n",
      "5219\n",
      "5228\n",
      "5229\n",
      "5230\n",
      "5233\n",
      "5234\n",
      "5243\n",
      "5244\n",
      "5251\n",
      "5258\n",
      "5263\n",
      "5267\n",
      "5268\n",
      "5281\n",
      "5282\n",
      "5286\n",
      "5287\n",
      "5294\n",
      "5295\n",
      "5297\n",
      "5298\n",
      "5301\n",
      "5302\n",
      "5304\n",
      "5305\n",
      "5311\n",
      "5312\n",
      "5319\n",
      "5320\n",
      "5321\n",
      "5322\n",
      "5323\n",
      "5324\n",
      "5325\n",
      "5326\n",
      "5330\n",
      "5331\n",
      "5339\n",
      "5340\n",
      "5344\n",
      "5345\n",
      "5346\n",
      "5347\n",
      "5353\n",
      "5354\n",
      "5357\n",
      "5358\n",
      "5360\n",
      "5361\n",
      "5369\n",
      "5370\n",
      "5377\n",
      "5378\n",
      "5383\n",
      "5384\n",
      "5386\n",
      "5387\n",
      "5388\n",
      "5389\n",
      "5390\n",
      "5391\n",
      "5392\n",
      "5396\n",
      "5397\n",
      "5398\n",
      "5399\n",
      "5400\n",
      "5401\n",
      "5402\n",
      "5405\n",
      "5406\n",
      "5412\n",
      "5413\n",
      "5416\n",
      "5417\n",
      "5424\n",
      "5425\n",
      "5426\n",
      "5441\n",
      "5442\n",
      "5446\n",
      "5447\n",
      "5449\n",
      "5450\n",
      "5451\n",
      "5453\n",
      "5454\n",
      "5486\n",
      "5487\n",
      "5495\n",
      "5496\n",
      "5500\n",
      "5501\n",
      "5505\n",
      "5506\n",
      "5527\n",
      "5528\n",
      "5541\n",
      "5542\n",
      "5546\n",
      "5547\n",
      "5552\n",
      "5553\n",
      "5554\n",
      "5555\n",
      "5556\n",
      "5557\n",
      "5558\n",
      "5559\n",
      "5560\n",
      "5566\n",
      "5567\n",
      "5582\n",
      "5583\n",
      "5588\n",
      "5589\n",
      "5591\n",
      "5592\n",
      "5608\n",
      "5609\n",
      "5611\n",
      "5612\n",
      "5618\n",
      "5619\n",
      "5620\n",
      "5621\n",
      "5626\n",
      "5627\n",
      "5631\n",
      "5632\n",
      "5633\n",
      "5634\n",
      "5636\n",
      "5637\n",
      "5638\n",
      "5639\n",
      "5640\n",
      "5642\n",
      "5643\n",
      "5644\n",
      "5645\n",
      "5646\n",
      "5650\n",
      "5651\n",
      "5652\n",
      "5653\n",
      "5655\n",
      "5656\n",
      "5663\n",
      "5664\n",
      "5665\n",
      "5666\n",
      "5673\n",
      "5674\n",
      "5681\n",
      "5682\n",
      "5688\n",
      "5689\n",
      "5690\n",
      "5691\n",
      "5692\n",
      "5698\n",
      "5700\n",
      "5701\n",
      "5702\n",
      "5704\n",
      "5708\n",
      "5709\n",
      "5714\n",
      "5715\n",
      "5716\n",
      "5719\n",
      "5722\n",
      "5723\n",
      "5729\n",
      "5730\n",
      "5731\n",
      "5736\n",
      "5737\n",
      "5738\n",
      "5739\n",
      "5740\n",
      "5745\n",
      "5746\n",
      "5749\n",
      "5750\n",
      "5751\n",
      "5755\n",
      "5756\n",
      "5757\n",
      "5759\n",
      "5760\n",
      "5761\n",
      "5782\n",
      "5783\n",
      "5784\n",
      "5785\n",
      "5786\n",
      "5788\n",
      "5794\n",
      "5795\n",
      "5802\n",
      "5803\n",
      "5808\n",
      "5809\n",
      "5812\n",
      "5813\n",
      "5821\n",
      "5822\n",
      "5832\n",
      "5834\n",
      "5835\n",
      "5838\n",
      "5839\n",
      "5840\n",
      "5846\n",
      "5847\n",
      "5851\n",
      "5852\n",
      "5855\n",
      "5856\n",
      "5857\n",
      "5858\n",
      "5868\n",
      "5871\n",
      "5874\n",
      "5877\n",
      "5884\n",
      "5885\n",
      "5886\n",
      "5887\n",
      "5888\n",
      "5889\n",
      "5890\n",
      "5891\n",
      "5893\n",
      "5905\n",
      "5906\n",
      "5910\n",
      "5911\n",
      "5912\n",
      "5913\n",
      "5915\n",
      "5916\n",
      "5924\n",
      "5925\n",
      "5926\n",
      "5932\n",
      "5935\n",
      "5936\n",
      "5937\n",
      "5938\n",
      "5941\n",
      "5942\n",
      "5947\n",
      "5948\n",
      "5951\n",
      "5952\n",
      "5955\n",
      "5956\n",
      "5957\n",
      "5958\n",
      "5960\n",
      "5961\n",
      "5962\n",
      "5966\n",
      "5967\n",
      "5968\n",
      "5969\n",
      "5975\n",
      "5976\n",
      "5993\n",
      "5994\n",
      "5995\n",
      "5996\n",
      "5997\n",
      "5999\n",
      "6000\n",
      "6004\n",
      "6005\n",
      "6006\n",
      "6012\n",
      "6013\n",
      "6014\n",
      "6016\n",
      "6017\n",
      "6023\n",
      "6024\n",
      "6025\n",
      "6026\n",
      "6028\n",
      "6029\n",
      "6030\n",
      "6034\n",
      "6035\n",
      "6045\n",
      "6046\n",
      "6050\n",
      "6051\n",
      "6052\n",
      "6053\n",
      "6054\n",
      "6055\n",
      "6056\n",
      "6057\n",
      "6064\n",
      "6065\n",
      "6067\n",
      "6068\n",
      "6070\n",
      "6071\n",
      "6072\n",
      "6073\n",
      "6076\n",
      "6077\n",
      "6078\n",
      "6079\n",
      "6080\n",
      "6081\n",
      "6082\n",
      "6086\n",
      "6087\n",
      "6088\n",
      "6089\n",
      "6092\n",
      "6093\n",
      "6094\n",
      "6095\n",
      "6098\n",
      "6099\n",
      "6100\n",
      "6101\n",
      "6102\n",
      "6106\n",
      "6107\n",
      "6108\n",
      "6109\n",
      "6110\n",
      "6111\n",
      "6116\n",
      "6117\n",
      "6118\n",
      "6119\n",
      "6123\n",
      "6124\n",
      "6130\n",
      "6131\n",
      "6132\n",
      "6133\n",
      "6134\n",
      "6135\n",
      "6138\n",
      "6139\n",
      "6147\n",
      "6148\n",
      "6151\n",
      "6152\n",
      "6153\n",
      "6154\n",
      "6155\n",
      "6156\n",
      "6157\n",
      "6158\n",
      "6159\n",
      "6160\n",
      "6161\n",
      "6162\n",
      "6163\n",
      "6164\n",
      "6166\n",
      "6167\n",
      "6170\n",
      "6171\n",
      "6172\n",
      "6174\n",
      "6175\n",
      "6176\n",
      "6177\n",
      "6182\n",
      "6183\n",
      "6184\n",
      "6188\n",
      "6189\n",
      "6193\n",
      "6205\n",
      "6206\n",
      "6212\n",
      "6213\n",
      "6214\n",
      "6215\n",
      "6216\n",
      "6217\n",
      "6218\n",
      "6219\n",
      "6224\n",
      "6225\n",
      "6226\n",
      "6227\n",
      "6229\n",
      "6230\n",
      "6231\n",
      "6233\n",
      "6234\n",
      "6235\n",
      "6236\n",
      "6237\n",
      "6240\n",
      "6241\n",
      "6251\n",
      "6252\n",
      "6256\n",
      "6257\n",
      "6266\n",
      "6267\n",
      "6268\n",
      "6271\n",
      "6280\n",
      "6281\n",
      "6288\n",
      "6308\n",
      "6309\n",
      "6321\n",
      "6322\n",
      "6325\n",
      "6326\n",
      "6327\n",
      "6340\n",
      "6345\n",
      "6361\n",
      "6369\n",
      "6379\n",
      "6394\n",
      "6397\n",
      "6398\n",
      "6399\n",
      "6403\n",
      "6404\n",
      "6405\n",
      "6406\n",
      "6407\n",
      "6409\n",
      "6410\n",
      "6416\n",
      "6417\n",
      "6418\n",
      "6419\n",
      "6425\n",
      "6426\n",
      "6427\n",
      "6428\n",
      "6438\n",
      "6439\n",
      "6449\n",
      "6450\n",
      "6451\n",
      "6452\n",
      "6453\n",
      "6454\n",
      "6456\n",
      "6457\n",
      "6458\n",
      "6459\n",
      "6463\n",
      "6464\n",
      "6476\n",
      "6477\n",
      "6478\n",
      "6479\n",
      "6488\n",
      "6489\n",
      "6494\n",
      "6495\n",
      "6497\n",
      "6498\n",
      "6499\n",
      "6500\n",
      "6501\n",
      "6502\n",
      "6503\n",
      "6504\n",
      "6505\n",
      "6526\n",
      "6527\n",
      "6528\n",
      "6529\n",
      "6530\n",
      "6531\n",
      "6532\n",
      "6533\n",
      "6534\n",
      "6535\n",
      "6536\n",
      "6538\n",
      "6539\n",
      "6540\n",
      "6541\n",
      "6542\n",
      "6543\n",
      "6544\n",
      "6545\n",
      "6546\n",
      "6551\n",
      "6552\n",
      "6553\n",
      "6554\n",
      "6557\n",
      "6558\n",
      "6559\n",
      "6560\n",
      "6561\n",
      "6563\n",
      "6564\n",
      "6567\n",
      "6568\n",
      "6569\n",
      "6570\n",
      "6571\n",
      "6574\n",
      "6575\n",
      "6578\n",
      "6579\n",
      "6580\n",
      "6581\n",
      "6583\n",
      "6584\n",
      "6585\n",
      "6586\n",
      "6587\n",
      "6589\n",
      "6590\n",
      "6591\n",
      "6592\n",
      "6593\n",
      "6594\n",
      "6595\n",
      "6596\n",
      "6597\n",
      "6598\n",
      "6599\n",
      "6600\n",
      "6601\n",
      "6602\n",
      "6603\n",
      "6604\n",
      "6605\n",
      "6606\n",
      "6608\n",
      "6609\n",
      "6610\n",
      "6611\n",
      "6612\n",
      "6613\n",
      "6614\n",
      "6615\n",
      "6616\n",
      "6617\n",
      "6618\n",
      "6619\n",
      "6620\n",
      "6621\n",
      "6622\n",
      "6623\n",
      "6624\n",
      "6625\n",
      "6626\n",
      "6627\n",
      "6628\n",
      "6629\n",
      "6630\n",
      "6633\n",
      "6634\n",
      "6635\n",
      "6636\n",
      "6637\n",
      "6638\n",
      "6639\n",
      "6640\n",
      "6641\n",
      "6642\n",
      "6643\n",
      "6644\n",
      "6645\n",
      "6646\n",
      "6652\n",
      "6653\n",
      "6657\n",
      "6658\n",
      "6659\n",
      "6660\n",
      "6662\n",
      "6663\n",
      "6664\n",
      "6666\n",
      "6667\n",
      "6671\n",
      "6672\n",
      "6674\n",
      "6677\n",
      "6678\n",
      "6685\n",
      "6688\n",
      "6689\n",
      "6695\n",
      "6696\n",
      "6707\n",
      "6708\n",
      "6709\n",
      "6722\n",
      "6723\n",
      "6724\n",
      "6726\n",
      "6731\n",
      "6732\n",
      "6733\n",
      "6735\n",
      "6736\n",
      "6743\n",
      "6744\n",
      "6751\n",
      "6752\n",
      "6754\n",
      "6761\n",
      "6762\n",
      "6768\n",
      "6770\n",
      "6773\n",
      "6782\n",
      "6785\n",
      "6793\n",
      "6796\n",
      "6797\n",
      "6802\n",
      "6816\n",
      "6822\n",
      "6829\n",
      "6845\n",
      "6853\n",
      "6857\n",
      "6859\n",
      "6863\n",
      "6866\n",
      "6870\n",
      "6871\n",
      "6882\n",
      "6883\n",
      "6887\n",
      "6897\n",
      "6905\n",
      "6906\n",
      "6907\n",
      "6910\n",
      "6911\n",
      "6912\n",
      "6913\n",
      "6914\n",
      "6915\n",
      "6916\n",
      "6918\n",
      "6919\n",
      "6920\n",
      "6921\n",
      "6922\n",
      "6923\n",
      "6924\n",
      "6925\n",
      "6926\n",
      "6927\n",
      "6928\n",
      "6929\n",
      "6930\n",
      "6931\n",
      "6932\n",
      "6934\n",
      "6935\n",
      "6936\n",
      "6937\n",
      "6938\n",
      "6939\n",
      "6940\n",
      "6941\n",
      "6942\n",
      "6943\n",
      "6944\n",
      "6945\n",
      "6946\n",
      "6949\n",
      "6950\n",
      "6954\n",
      "6955\n",
      "6959\n",
      "6960\n",
      "6961\n",
      "6962\n",
      "6963\n",
      "6964\n",
      "6965\n",
      "6966\n",
      "6969\n",
      "6970\n",
      "6973\n",
      "6974\n",
      "6978\n",
      "6979\n",
      "6980\n",
      "6981\n",
      "6987\n",
      "6988\n",
      "6989\n",
      "6990\n",
      "6992\n",
      "6993\n",
      "6996\n",
      "6997\n",
      "7000\n",
      "7001\n",
      "7004\n",
      "7005\n",
      "7006\n",
      "7007\n",
      "7008\n",
      "7009\n",
      "7010\n",
      "7011\n",
      "7012\n",
      "7013\n",
      "7014\n",
      "7015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3843822824.py:55: RuntimeWarning: Mean of empty slice\n",
      "  group_mean = {k: np.nanmean(np.vstack(v), axis=0) for k, v in grouped.items()}\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3843822824.py:74: RuntimeWarning: Mean of empty slice\n",
      "  mean_across_animals = np.nanmean(temp_unstr, axis = 0)\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3843822824.py:75: SmallSampleWarning: After omitting NaNs, one or more axis-slices of one or more sample arguments is too small; corresponding elements of returned arrays will be NaN. See documentation for sample size requirements.\n",
      "  sem_across_animals = sem(temp_unstr, axis = 0, nan_policy='omit')\n",
      "c:\\Users\\dlab\\rishika_sim\\utils\\dfLoading.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sess_block'] = 0\n",
      "c:\\Users\\dlab\\rishika_sim\\utils\\dfLoading.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sess_block'] = df.groupby(['animal', 'task']).sess_block.cumsum()\n",
      "c:\\Users\\dlab\\rishika_sim\\utils\\dfLoading.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['block_group'] = df.groupby(['animal', 'task', 'session']).ngroup()\n",
      "c:\\Users\\dlab\\rishika_sim\\utils\\dfLoading.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['block_group'] = (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "3\n",
      "4\n",
      "5\n",
      "8\n",
      "11\n",
      "12\n",
      "14\n",
      "16\n",
      "17\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "25\n",
      "26\n",
      "28\n",
      "29\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "36\n",
      "37\n",
      "39\n",
      "40\n",
      "42\n",
      "45\n",
      "46\n",
      "47\n",
      "50\n",
      "52\n",
      "53\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "61\n",
      "63\n",
      "65\n",
      "68\n",
      "72\n",
      "74\n",
      "77\n",
      "79\n",
      "81\n",
      "82\n",
      "88\n",
      "89\n",
      "90\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "98\n",
      "99\n",
      "103\n",
      "105\n",
      "108\n",
      "110\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "117\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "126\n",
      "129\n",
      "135\n",
      "136\n",
      "137\n",
      "141\n",
      "142\n",
      "148\n",
      "149\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "175\n",
      "176\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "202\n",
      "203\n",
      "205\n",
      "206\n",
      "211\n",
      "212\n",
      "219\n",
      "220\n",
      "225\n",
      "226\n",
      "227\n",
      "229\n",
      "230\n",
      "231\n",
      "244\n",
      "249\n",
      "250\n",
      "251\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "286\n",
      "287\n",
      "294\n",
      "295\n",
      "296\n",
      "310\n",
      "311\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "349\n",
      "350\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "391\n",
      "392\n",
      "397\n",
      "398\n",
      "415\n",
      "416\n",
      "431\n",
      "432\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "439\n",
      "443\n",
      "444\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "457\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "464\n",
      "466\n",
      "468\n",
      "470\n",
      "475\n",
      "476\n",
      "479\n",
      "482\n",
      "483\n",
      "490\n",
      "492\n",
      "493\n",
      "495\n",
      "497\n",
      "498\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "506\n",
      "515\n",
      "518\n",
      "520\n",
      "527\n",
      "529\n",
      "532\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "539\n",
      "543\n",
      "544\n",
      "545\n",
      "550\n",
      "552\n",
      "555\n",
      "558\n",
      "560\n",
      "561\n",
      "562\n",
      "564\n",
      "572\n",
      "573\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "581\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "588\n",
      "589\n",
      "591\n",
      "592\n",
      "595\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "605\n",
      "607\n",
      "608\n",
      "610\n",
      "611\n",
      "612\n",
      "614\n",
      "615\n",
      "616\n",
      "618\n",
      "621\n",
      "623\n",
      "625\n",
      "626\n",
      "627\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "636\n",
      "637\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "648\n",
      "649\n",
      "651\n",
      "652\n",
      "653\n",
      "655\n",
      "656\n",
      "659\n",
      "660\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "674\n",
      "675\n",
      "679\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "698\n",
      "699\n",
      "702\n",
      "703\n",
      "705\n",
      "706\n",
      "715\n",
      "716\n",
      "735\n",
      "741\n",
      "751\n",
      "753\n",
      "754\n",
      "755\n",
      "757\n",
      "767\n",
      "776\n",
      "780\n",
      "786\n",
      "787\n",
      "791\n",
      "800\n",
      "803\n",
      "807\n",
      "809\n",
      "812\n",
      "816\n",
      "823\n",
      "824\n",
      "828\n",
      "829\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "850\n",
      "851\n",
      "853\n",
      "854\n",
      "862\n",
      "868\n",
      "869\n",
      "879\n",
      "885\n",
      "890\n",
      "891\n",
      "895\n",
      "896\n",
      "897\n",
      "899\n",
      "900\n",
      "909\n",
      "912\n",
      "915\n",
      "917\n",
      "918\n",
      "922\n",
      "927\n",
      "934\n",
      "940\n",
      "941\n",
      "944\n",
      "945\n",
      "952\n",
      "963\n",
      "964\n",
      "973\n",
      "980\n",
      "981\n",
      "983\n",
      "994\n",
      "1017\n",
      "1033\n",
      "1097\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1141\n",
      "1146\n",
      "1148\n",
      "1160\n",
      "1161\n",
      "1164\n",
      "1166\n",
      "1167\n",
      "1175\n",
      "1184\n",
      "1188\n",
      "1189\n",
      "1194\n",
      "1195\n",
      "1201\n",
      "1203\n",
      "1210\n",
      "1211\n",
      "1216\n",
      "1217\n",
      "1228\n",
      "1229\n",
      "1248\n",
      "1259\n",
      "1263\n",
      "1270\n",
      "1271\n",
      "1273\n",
      "1290\n",
      "1291\n",
      "1296\n",
      "1303\n",
      "1304\n",
      "1307\n",
      "1313\n",
      "1314\n",
      "1335\n",
      "1339\n",
      "1349\n",
      "1353\n",
      "1361\n",
      "1407\n",
      "1408\n",
      "1446\n",
      "1458\n",
      "1508\n",
      "1527\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1541\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1550\n",
      "1555\n",
      "1556\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1567\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1581\n",
      "1583\n",
      "1584\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1647\n",
      "1648\n",
      "1653\n",
      "1654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3843822824.py:55: RuntimeWarning: Mean of empty slice\n",
      "  group_mean = {k: np.nanmean(np.vstack(v), axis=0) for k, v in grouped.items()}\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3843822824.py:74: RuntimeWarning: Mean of empty slice\n",
      "  mean_across_animals = np.nanmean(temp_unstr, axis = 0)\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3843822824.py:75: SmallSampleWarning: After omitting NaNs, one or more axis-slices of one or more sample arguments is too small; corresponding elements of returned arrays will be NaN. See documentation for sample size requirements.\n",
      "  sem_across_animals = sem(temp_unstr, axis = 0, nan_policy='omit')\n"
     ]
    }
   ],
   "source": [
    "# select block 1 transitions with > 100 trials\n",
    "plt.figure(figsize = (5,4.5))\n",
    "colors = ['xkcd:cornflower', 'xkcd:slate grey']\n",
    "labels = ['Pre-lesion', 'Post-lesion']\n",
    "from utils.dfLoading import add_block_groups\n",
    "for ind, task in enumerate(['unstr', 'sham']):\n",
    "    df = add_block_groups(sessdf[sessdf.task == task])\n",
    "    bl3 = (\n",
    "        df[(df.block_group == 1) & (df.task == task)]\n",
    "        .groupby(['animal', 'session'])\n",
    "        .trial\n",
    "        .count()[df[(df.block_group == 1) & (df.task == task)]\n",
    "                    .groupby(['animal', 'session'])\n",
    "                    .trial\n",
    "                    .count()>100]\n",
    "                    .index\n",
    "                    .to_numpy()\n",
    "                    )\n",
    "    bl1_head = np.zeros(shape = (bl3.shape[0], 100))\n",
    "\n",
    "    empty_row = []\n",
    "\n",
    "    grouped = dict(tuple(df.groupby(['animal', 'session'])))\n",
    "    for row, i in enumerate(bl3):\n",
    "        key_bl3 = (i[0], i[1])\n",
    "        key_bl2 = (i[0], i[1]-1)\n",
    "        key_bl1 = (i[0], i[1]-2)\n",
    "        if key_bl1 not in grouped or grouped[key_bl1].trial.count() < 100:\n",
    "            empty_row.append(row)\n",
    "            print(row)\n",
    "        elif key_bl2 not in grouped or grouped[key_bl2].trial.count() < 100:\n",
    "            empty_row.append(row)\n",
    "            print(row)\n",
    "        else:\n",
    "            bl1_head[row] = grouped[key_bl1].head(100).port\n",
    "    bl1_head[empty_row]= np.nan\n",
    "\n",
    "    # each animal in switch_array\n",
    "    an_ = np.array([val for i, val in enumerate(bl3) if i not in empty_row])[:, 0]\n",
    "    switch_arr = np.abs(np.diff(bl1_head))\n",
    "    switch_arr = switch_arr[~np.isnan(switch_arr).any(axis=1)]\n",
    "    switch_arr[switch_arr == 0] = np.nan\n",
    "\n",
    "    # keep rows without NaNs and align an_ with switch_arr\n",
    "    mask = ~np.isnan(switch_arr).all(axis=1)\n",
    "    switch_arr = switch_arr[mask]\n",
    "    an_filtered = an_[mask]\n",
    "\n",
    "    from collections import defaultdict\n",
    "    grouped = defaultdict(list)\n",
    "    for animal, row in zip(an_filtered, switch_arr):\n",
    "        grouped[animal].append(row)\n",
    "\n",
    "    # per-animal mean & sem (stack rows for each animal)\n",
    "    group_mean = {k: np.nanmean(np.vstack(v), axis=0) for k, v in grouped.items()}\n",
    "\n",
    "    # mean across animals (average of per-animal means)\n",
    "    mean_across_animals = np.nanmean(np.vstack(list(group_mean.values())), axis=0)\n",
    "    sem_across_animals = sem(np.vstack(list(group_mean.values())), axis=0, nan_policy='omit')\n",
    "\n",
    "    smooth = True\n",
    "    window = 3\n",
    "    temp_unstr = np.ones(shape = (len(group_mean), 99))*np.nan\n",
    "    trialsinsess = 99\n",
    "    # smoothing details\n",
    "    if smooth:           \n",
    "        for i, row in enumerate(np.array(list(group_mean.values()))):\n",
    "            temp_unstr[i] = np.convolve(row, np.ones(window)/window, 'same')\n",
    "        \n",
    "        # works only for odd windows\n",
    "        temp_unstr[:, 0:(window//2)] = np.nan\n",
    "        temp_unstr[:, (trialsinsess-window//2):trialsinsess] = np.nan\n",
    "\n",
    "        mean_across_animals = np.nanmean(temp_unstr, axis = 0)\n",
    "        sem_across_animals = sem(temp_unstr, axis = 0, nan_policy='omit')\n",
    "    plt.plot(mean_across_animals, color=colors[ind], label = labels[ind])\n",
    "    plt.fill_between(np.arange(mean_across_animals.size),\n",
    "                 mean_across_animals - sem_across_animals,\n",
    "                 mean_across_animals + sem_across_animals,\n",
    "                 color=colors[ind], alpha=0.3)\n",
    "\n",
    "# plot per-animal traces and the group average\n",
    "\n",
    "\n",
    "plt.xlabel('Trials in session')\n",
    "plt.xticks(np.arange(0, 101, 25), [1, '', '', '', 100])\n",
    "plt.title(f'n = {len(group_mean)}')\n",
    "plt.ylabel('Switch distance')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0e4f9d",
   "metadata": {},
   "source": [
    "## pairwise condition comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f8e4d420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3827990971.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3827990971.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TtestResult(statistic=np.float64(0.13597937383112021), pvalue=np.float64(0.8984064333814432), df=np.int64(4))\n"
     ]
    }
   ],
   "source": [
    "# sessdf.drop(columns = ['d_value', 'd_chance'], inplace = True)\n",
    "trialsinsess = 100\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "struc = calc_dist_metric(tempdf, (tempdf.task == 'str') & (tempdf.animal.isin(fish)) & (tempdf.shift_t0 == 1))\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "unstruc = calc_dist_metric(tempdf, (tempdf.task == 'unstr') & (tempdf.animal.isin(fish)) & (tempdf.shift_t0 == 1) & (tempdf.sess_bin >= 4))\n",
    "y_str = struc[struc.animal.isin(fish)].groupby('animal').d_value.mean()\n",
    "y_unstr = unstruc[unstruc.animal.isin(fish)].groupby('animal').d_value.mean()\n",
    "plt.figure(figsize=(3.5,4))\n",
    "plt.bar(0, unstruc[unstruc.animal.isin(fish)].groupby('animal').d_chance.mean().mean(), color = 'grey', alpha = 0.2, width = 0.6)\n",
    "plt.bar(0, y_unstr.mean(), color = 'xkcd:pumpkin orange', yerr = y_unstr.sem(), width = 0.6)\n",
    "plt.bar(1, struc[struc.animal.isin(fish)].groupby('animal').d_chance.mean().mean(), color = 'grey', alpha = 0.2, width = 0.6)\n",
    "plt.bar(1, y_str.mean(), color = 'xkcd:emerald green', yerr = y_str.sem(), width = 0.6)\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(1,1.7)\n",
    "plt.xticks([0, 1], ['Unstructured', 'Structured'], fontsize = 'large', color = 'grey')\n",
    "plt.yticks([1, 1.2, 1.4, 1.6], [1,'', '', 1.6], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Distance metric', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "print(ttest_rel(y_unstr, y_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02f870a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\2368743184.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\2368743184.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TtestResult(statistic=np.float64(-0.9872314795757795), pvalue=np.float64(0.3447471510148764), df=np.int64(11))\n",
      "TtestResult(statistic=np.float64(-2.9917392711353012), pvalue=np.float64(0.012259523813411255), df=np.int64(11))\n",
      "TtestResult(statistic=np.float64(-2.5752125258030394), pvalue=np.float64(0.02580956474399872), df=np.int64(11))\n"
     ]
    }
   ],
   "source": [
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "struc = calc_dist_metric(tempdf, (tempdf.task == 'dms') & (tempdf.animal.isin(dms_an)) & (tempdf.shift_t0 == 1))\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "unstruc = calc_dist_metric(tempdf, (tempdf.task == 'unstr') & (tempdf.animal.isin(dms_an)) & (tempdf.shift_t0 == 1) & (tempdf.sess_bin >= 4))\n",
    "y_str = struc[struc.animal.isin(dms_an)].groupby('animal').d_value.mean()\n",
    "y_unstr = unstruc[unstruc.animal.isin(dms_an)].groupby('animal').d_value.mean()\n",
    "width = 0.6\n",
    "plt.figure(figsize=(3.5,4))\n",
    "plt.bar(0, unstruc[unstruc.animal.isin(dms_an)].groupby('animal').d_chance.mean().mean(), color = 'grey', alpha = 0.2, width = 0.6)\n",
    "plt.bar(0, y_unstr.mean(), color = 'xkcd:cornflower', yerr = y_unstr.sem(), width = 0.6)\n",
    "plt.bar(1, struc[struc.animal.isin(dms_an)].groupby('animal').d_chance.mean().mean(), color = 'grey', alpha = 0.2, width = 0.6)\n",
    "plt.bar(1, y_str.mean(), color = 'xkcd:slate grey', yerr = y_str.sem(), width = 0.6)\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(1,1.9)\n",
    "plt.xticks([0, 1], ['Pre-lesion', 'Post-lesion'], fontsize = 'large', color = 'grey')\n",
    "plt.yticks([1, 1.2, 1.4, 1.6, 1.8], [1,'', '', '',1.8], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Distance metric', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "print(ttest_rel(y_unstr, y_str))\n",
    "print(ttest_rel(y_unstr, unstruc[unstruc.animal.isin(dms_an)].groupby('animal').d_chance.mean()))\n",
    "print(ttest_rel(y_str, struc[struc.animal.isin(dms_an)].groupby('animal').d_chance.mean()))\n",
    "# Statistical annotations using matplotlib\n",
    "from scipy.stats import ttest_rel\n",
    "annot = True\n",
    "if annot:\n",
    "    # Perform t-tests\n",
    "    t_stat1, p_val1 = ttest_rel(y_unstr, y_str)\n",
    "    t_stat2, p_val2 = ttest_rel(y_unstr, unstruc[unstruc.animal.isin(dms_an)].groupby('animal').d_chance.mean())\n",
    "    t_stat3, p_val3 = ttest_rel(y_str, struc[struc.animal.isin(dms_an)].groupby('animal').d_chance.mean())\n",
    "\n",
    "    # Add annotations\n",
    "    max_y = (unstruc[unstruc.animal.isin(dms_an)].groupby('animal').d_chance.mean()).mean()\n",
    "\n",
    "    if p_val1:\n",
    "        plt.plot([0, 1], [max_y + 0.02, max_y + 0.02], color='black', linewidth=1)\n",
    "        plt.text(0.5, max_y + 0.03, f'p={p_val1:.3f}', ha='center', fontsize=10)\n",
    "\n",
    "    if p_val2:\n",
    "        plt.plot([width/2 +0.05, width/2 + 0.05], [(y_unstr.mean()+1)/2, (max_y - y_unstr.mean())/2 + y_unstr.mean()], color='black', linewidth=1)\n",
    "        plt.text(width/2 +0.1, y_unstr.mean() - 0.15, f'p={p_val2:.3f}', ha='center', fontsize=10, rotation = 270)\n",
    "\n",
    "    if p_val3:\n",
    "        plt.plot([width/2+1.05, width/2+1.05], [(y_str.mean()+1)/2, (max_y - y_str.mean())/2 + y_str.mean()], color='black', linewidth=1)\n",
    "        plt.text(width/2+1.1, y_str.mean() - 0.15, f'p={p_val3:.3f}', ha='center', fontsize=10, rotation = 270)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79f140d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\2368743184.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\2368743184.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TtestResult(statistic=np.float64(-1.1594353333240175), pvalue=np.float64(0.268829526560833), df=np.int64(12))\n",
      "TtestResult(statistic=np.float64(-5.5864437044468405), pvalue=np.float64(0.00011867162051950857), df=np.int64(12))\n",
      "TtestResult(statistic=np.float64(-1.5816978693772266), pvalue=np.float64(0.1397034682278947), df=np.int64(12))\n"
     ]
    }
   ],
   "source": [
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "struc = calc_dist_metric(tempdf, (tempdf.task == 'dls') & (tempdf.animal.isin(dls_an)) & (tempdf.shift_t0 == 1))\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "unstruc = calc_dist_metric(tempdf, (tempdf.task == 'unstr') & (tempdf.animal.isin(dls_an)) & (tempdf.shift_t0 == 1) & (tempdf.sess_bin >= 4))\n",
    "y_str = struc[struc.animal.isin(dls_an)].groupby('animal').d_value.mean()\n",
    "y_unstr = unstruc[unstruc.animal.isin(dls_an)].groupby('animal').d_value.mean()\n",
    "width = 0.6\n",
    "plt.figure(figsize=(3.5,4))\n",
    "plt.bar(0, unstruc[unstruc.animal.isin(dls_an)].groupby('animal').d_chance.mean().mean(), color = 'grey', alpha = 0.2, width = 0.6)\n",
    "plt.bar(0, y_unstr.mean(), color = 'xkcd:cornflower', yerr = y_unstr.sem(), width = 0.6)\n",
    "plt.bar(1, struc[struc.animal.isin(dls_an)].groupby('animal').d_chance.mean().mean(), color = 'grey', alpha = 0.2, width = 0.6)\n",
    "plt.bar(1, y_str.mean(), color = 'xkcd:slate grey', yerr = y_str.sem(), width = 0.6)\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(1,1.9)\n",
    "plt.xticks([0, 1], ['Pre-lesion', 'Post-lesion'], fontsize = 'large', color = 'grey')\n",
    "plt.yticks([1, 1.2, 1.4, 1.6, 1.8], [1,'', '', '', 1.8], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Distance metric', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "print(ttest_rel(y_unstr, y_str))\n",
    "print(ttest_rel(y_unstr, unstruc[unstruc.animal.isin(dls_an)].groupby('animal').d_chance.mean()))\n",
    "print(ttest_rel(y_str, struc[struc.animal.isin(dls_an)].groupby('animal').d_chance.mean()))\n",
    "# Statistical annotations using matplotlib\n",
    "from scipy.stats import ttest_rel\n",
    "annot = True\n",
    "if annot:\n",
    "    # Perform t-tests\n",
    "    t_stat1, p_val1 = ttest_rel(y_unstr, y_str)\n",
    "    t_stat2, p_val2 = ttest_rel(y_unstr, unstruc[unstruc.animal.isin(dls_an)].groupby('animal').d_chance.mean())\n",
    "    t_stat3, p_val3 = ttest_rel(y_str, struc[struc.animal.isin(dls_an)].groupby('animal').d_chance.mean())\n",
    "\n",
    "    # Add annotations\n",
    "    max_y = (unstruc[unstruc.animal.isin(dls_an)].groupby('animal').d_chance.mean()).mean()\n",
    "\n",
    "    if p_val1:\n",
    "        plt.plot([0, 1], [max_y + 0.02, max_y + 0.02], color='black', linewidth=1)\n",
    "        plt.text(0.5, max_y + 0.03, f'p={p_val1:.3f}', ha='center', fontsize=10)\n",
    "\n",
    "    if p_val2:\n",
    "        plt.plot([width/2 +0.05, width/2 + 0.05], [(y_unstr.mean()+1)/2, (max_y - y_unstr.mean())/2 + y_unstr.mean()], color='black', linewidth=1)\n",
    "        plt.text(width/2 +0.1, y_unstr.mean() - 0.15, f'p={p_val2:.3f}', ha='center', fontsize=10, rotation = 270)\n",
    "\n",
    "    if p_val3:\n",
    "        plt.plot([width/2+1.05, width/2+1.05], [(y_str.mean()+1)/2, (max_y - y_str.mean())/2 + y_str.mean()], color='black', linewidth=1)\n",
    "        plt.text(width/2+1.1, y_str.mean() - 0.15, f'p={p_val3:.3f}', ha='center', fontsize=10, rotation = 270, color = 'red')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3dfc33e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\2368743184.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_27724\\2368743184.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TtestResult(statistic=np.float64(-0.015446702498175658), pvalue=np.float64(0.9880540849631145), df=np.int64(8))\n",
      "TtestResult(statistic=np.float64(-3.4781724611786644), pvalue=np.float64(0.008341986294539198), df=np.int64(8))\n",
      "TtestResult(statistic=np.float64(-5.779804117773085), pvalue=np.float64(0.0004146098651563682), df=np.int64(8))\n"
     ]
    }
   ],
   "source": [
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "struc = calc_dist_metric(tempdf, (tempdf.task == 'sham') & (tempdf.animal.isin(sham_an)) & (tempdf.shift_t0 == 1))\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "unstruc = calc_dist_metric(tempdf, (tempdf.task == 'unstr') & (tempdf.animal.isin(sham_an)) & (tempdf.shift_t0 == 1) & (tempdf.sess_bin >= 4))\n",
    "y_str = struc[struc.animal.isin(sham_an)].groupby('animal').d_value.mean()\n",
    "y_unstr = unstruc[unstruc.animal.isin(sham_an)].groupby('animal').d_value.mean()\n",
    "width = 0.6\n",
    "plt.figure(figsize=(3.5,4))\n",
    "plt.bar(0, unstruc.groupby('animal').d_chance.mean().mean(), color = 'grey', alpha = 0.2, width = 0.6)\n",
    "plt.bar(0, y_unstr.mean(), color = 'xkcd:cornflower', yerr = y_unstr.sem(), width = 0.6)\n",
    "plt.bar(1, struc.groupby('animal').d_chance.mean().mean(), color = 'grey', alpha = 0.2, width = 0.6)\n",
    "plt.bar(1, y_str.mean(), color = 'xkcd:slate grey', yerr = y_str.sem(), width = 0.6)\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(1,1.9)\n",
    "plt.xticks([0, 1], ['Pre-lesion', 'Post-lesion'], fontsize = 'large', color = 'grey')\n",
    "plt.yticks([1, 1.2, 1.4, 1.6, 1.8], [1,'', '', '', 1.8], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Distance metric', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "print(ttest_rel(y_unstr, y_str))\n",
    "print(ttest_rel(y_unstr, unstruc[unstruc.animal.isin(sham_an)].groupby('animal').d_chance.mean()))\n",
    "print(ttest_rel(y_str, struc[struc.animal.isin(sham_an)].groupby('animal').d_chance.mean()))\n",
    "# Statistical annotations using matplotlib\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Perform t-tests\n",
    "t_stat1, p_val1 = ttest_rel(y_unstr, y_str)\n",
    "t_stat2, p_val2 = ttest_rel(y_unstr, unstruc[unstruc.animal.isin(sham_an)].groupby('animal').d_chance.mean())\n",
    "t_stat3, p_val3 = ttest_rel(y_str, struc[struc.animal.isin(sham_an)].groupby('animal').d_chance.mean())\n",
    "\n",
    "# Add annotations\n",
    "max_y = (unstruc[unstruc.animal.isin(sham_an)].groupby('animal').d_chance.mean()).mean()\n",
    "\n",
    "if p_val1:\n",
    "    plt.plot([0, 1], [max_y + 0.02, max_y + 0.02], color='black', linewidth=1)\n",
    "    plt.text(0.5, max_y + 0.03, f'p={p_val1:.3f}', ha='center', fontsize=10)\n",
    "\n",
    "if p_val2:\n",
    "    plt.plot([width/2 +0.05, width/2 + 0.05], [(y_unstr.mean()+1)/2, (max_y - y_unstr.mean())/2 + y_unstr.mean()], color='black', linewidth=1)\n",
    "    plt.text(width/2 +0.1, y_unstr.mean() - 0.15, f'p={p_val2:.3f}', ha='center', fontsize=10, rotation = 270)\n",
    "\n",
    "if p_val3:\n",
    "    plt.plot([width/2+1.05, width/2+1.05], [(y_str.mean()+1)/2, (max_y - y_str.mean())/2 + y_str.mean()], color='black', linewidth=1)\n",
    "    plt.text(width/2+1.1, y_str.mean() - 0.15, f'p={p_val3:.3f}', ha='center', fontsize=10, rotation = 270)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "1c69bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_22488\\2368743184.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_22488\\2368743184.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TtestResult(statistic=np.float64(-0.015446702498175658), pvalue=np.float64(0.9880540849631145), df=np.int64(8))\n",
      "TtestResult(statistic=np.float64(-3.4781724611786644), pvalue=np.float64(0.008341986294539198), df=np.int64(8))\n",
      "TtestResult(statistic=np.float64(-5.779804117773085), pvalue=np.float64(0.0004146098651563682), df=np.int64(8))\n"
     ]
    }
   ],
   "source": [
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "struc = calc_dist_metric(tempdf, (tempdf.task == 'sham') & (tempdf.animal.isin(sham_an)) & (tempdf.shift_t0 == 1))\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "unstruc = calc_dist_metric(tempdf, (tempdf.task == 'unstr') & (tempdf.animal.isin(sham_an)) & (tempdf.shift_t0 == 1) & (tempdf.sess_bin >= 4))\n",
    "y_str = struc[struc.animal.isin(sham_an)].groupby('animal').d_value.mean()\n",
    "y_unstr = unstruc[unstruc.animal.isin(sham_an)].groupby('animal').d_value.mean()\n",
    "width = 0.6\n",
    "plt.figure(figsize=(3.5,4))\n",
    "plt.bar(0, unstruc.groupby('animal').d_chance.mean().mean(), color = 'grey', alpha = 0.2, width = 0.6)\n",
    "plt.bar(0, y_unstr.mean(), color = 'xkcd:cornflower', yerr = y_unstr.sem(), width = 0.6)\n",
    "plt.bar(1, struc.groupby('animal').d_chance.mean().mean(), color = 'grey', alpha = 0.2, width = 0.6)\n",
    "plt.bar(1, y_str.mean(), color = 'xkcd:slate grey', yerr = y_str.sem(), width = 0.6)\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(1,1.9)\n",
    "plt.xticks([0, 1], ['Pre-lesion', 'Post-lesion'], fontsize = 'large', color = 'grey')\n",
    "plt.yticks([1, 1.2, 1.4, 1.6, 1.8], [1,'', '', '', 1.8], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Distance metric', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "print(ttest_rel(y_unstr, y_str))\n",
    "print(ttest_rel(y_unstr, unstruc[unstruc.animal.isin(sham_an)].groupby('animal').d_chance.mean()))\n",
    "print(ttest_rel(y_str, struc[struc.animal.isin(sham_an)].groupby('animal').d_chance.mean()))\n",
    "\n",
    "# Statistical annotations using matplotlib\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Perform t-tests\n",
    "t_stat1, p_val1 = ttest_rel(y_unstr, y_str)\n",
    "t_stat2, p_val2 = ttest_rel(y_unstr, unstruc[unstruc.animal.isin(sham_an)].groupby('animal').d_chance.mean())\n",
    "t_stat3, p_val3 = ttest_rel(y_str, struc[struc.animal.isin(sham_an)].groupby('animal').d_chance.mean())\n",
    "\n",
    "# Add annotations\n",
    "max_y = (unstruc[unstruc.animal.isin(sham_an)].groupby('animal').d_chance.mean()).mean()\n",
    "\n",
    "if p_val1:\n",
    "    plt.plot([0, 1], [max_y + 0.02, max_y + 0.02], color='black', linewidth=1)\n",
    "    plt.text(0.5, max_y + 0.03, f'p={p_val1:.3f}', ha='center', fontsize=10)\n",
    "\n",
    "if p_val2:\n",
    "    plt.plot([width/2 +0.05, width/2 + 0.05], [(y_unstr.mean()+1)/2, (max_y - y_unstr.mean())/2 + y_unstr.mean()], color='black', linewidth=1)\n",
    "    plt.text(width/2 +0.1, y_unstr.mean() - 0.15, f'p={p_val2:.3f}', ha='center', fontsize=10, rotation = 270)\n",
    "\n",
    "if p_val3:\n",
    "    plt.plot([width/2+1.05, width/2+1.05], [(y_str.mean()+1)/2, (max_y - y_str.mean())/2 + y_str.mean()], color='black', linewidth=1)\n",
    "    plt.text(width/2+1.1, y_str.mean() - 0.15, f'p={p_val3:.3f}', ha='center', fontsize=10, rotation = 270)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "c2a1a3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 1 artists>"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "unstruc = calc_dist_metric(tempdf, (tempdf.task == 'unstr') & (~tempdf.animal.isin(['Kakuna', \"Finneon\"])) & (tempdf.shift_t0 == 1) & (tempdf.sess_bin >= 4))\n",
    "y_unstr = unstruc[~tempdf.animal.isin(['Kakuna', \"Finneon\"])].groupby('animal').d_value.mean()\n",
    "plt.figure(figsize=(3.5,4))\n",
    "plt.bar(0, unstruc.groupby('animal').d_chance.mean().mean(), color = 'grey', alpha = 0.2, width = 0.6)\n",
    "plt.bar(1, y_unstr.mean(), color = 'xkcd:azure', yerr = y_unstr.sem(), width = 0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "88bedb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3827990971.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3827990971.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3827990971.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3827990971.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n"
     ]
    }
   ],
   "source": [
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "les_r = calc_dist_metric(tempdf, (tempdf.task == 'sham') & (tempdf.animal.isin(sham_an)) & (tempdf.shift_t0 == 1) & (tempdf.reward == 1))\n",
    "\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "les_nr = calc_dist_metric(tempdf, (tempdf.task == 'sham') & (tempdf.animal.isin(sham_an)) & (tempdf.shift_t0 == 1) & (tempdf.reward == 0))\n",
    "\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "pre_r = calc_dist_metric(tempdf, (tempdf.task == 'unstr') & (tempdf.animal.isin(sham_an)) & (tempdf.shift_t0 == 1) & (tempdf.sess_bin >= 4) & (tempdf.reward == 1))\n",
    "\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "pre_nr = calc_dist_metric(tempdf, (tempdf.task == 'unstr') & (tempdf.animal.isin(sham_an)) & (tempdf.shift_t0 == 1) & (tempdf.sess_bin >= 4) & (tempdf.reward == 0))\n",
    "\n",
    "y_pre_r = pre_r[pre_r.animal.isin(sham_an)].groupby('animal').d_value.mean()\n",
    "y_pre_nr = pre_nr[pre_nr.animal.isin(sham_an)].groupby('animal').d_value.mean()\n",
    "y_pre_r_chance = pre_r[pre_r.animal.isin(sham_an)].groupby('animal').d_chance.mean()\n",
    "y_pre_nr_chance = pre_nr[pre_nr.animal.isin(sham_an)].groupby('animal').d_chance.mean()\n",
    "\n",
    "y_les_r = les_r[les_r.animal.isin(sham_an)].groupby('animal').d_value.mean()\n",
    "y_les_nr = les_nr[les_nr.animal.isin(sham_an)].groupby('animal').d_value.mean()\n",
    "y_les_r_chance = les_r[les_r.animal.isin(sham_an)].groupby('animal').d_chance.mean()\n",
    "y_les_nr_chance = les_nr[les_nr.animal.isin(sham_an)].groupby('animal').d_chance.mean()\n",
    "\n",
    "plt.figure(figsize=(3.5,4))\n",
    "width = 0.4\n",
    "# plt.bar(0-width/2, y_pre_r_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "# plt.bar(0+width/2, y_pre_nr_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "\n",
    "plt.bar(0-width/2, y_pre_r.mean(), color = 'red', yerr = y_pre_r.sem(), width = width)\n",
    "plt.bar(0+width/2, y_pre_nr.mean(), color = 'blue', yerr = y_pre_nr.sem(), width = width)\n",
    "\n",
    "plt.hlines(y_pre_r_chance.mean(), xmin = -width, xmax = 0, color = 'grey', ls = '--', lw = 2)\n",
    "plt.hlines(y_pre_nr_chance.mean(), xmin = 0, xmax = width, color = 'grey', ls = '--', lw = 2)\n",
    "\n",
    "# plt.bar(1-width/2, y_les_r_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "# plt.bar(1+width/2, y_les_nr_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "\n",
    "plt.bar(1-width/2, y_les_r.mean(), color = 'red', yerr = y_les_r.sem(), width = width)\n",
    "plt.bar(1+width/2, y_les_nr.mean(), color = 'blue', yerr = y_les_nr.sem(), width = width)\n",
    "\n",
    "plt.hlines(y_les_r_chance.mean(), xmin = 1-width, xmax = 1, color = 'grey', ls = '--', lw = 2)\n",
    "plt.hlines(y_les_nr_chance.mean(), xmin = 1, xmax = width+1, color = 'grey', ls = '--', lw = 2)\n",
    "\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(1,1.9)\n",
    "plt.xticks([0, 1], ['Pre-lesion', 'Post-lesion'], fontsize = 'large', color = 'grey')\n",
    "plt.yticks([1, 1.2, 1.4, 1.6, 1.8], [1,'', '', '', 1.8], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Distance metric', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "96a54200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TtestResult(statistic=np.float64(-1.0516376713083069), pvalue=np.float64(0.33346442197301746), df=np.int64(6)),\n",
       " TtestResult(statistic=np.float64(-1.1102494601715123), pvalue=np.float64(0.30939408024261356), df=np.int64(6)))"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(y_pre_r, y_les_r), ttest_rel(y_pre_nr, y_les_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "815aca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3827990971.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3827990971.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3827990971.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3827990971.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n"
     ]
    }
   ],
   "source": [
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "les_r = calc_dist_metric(tempdf, (tempdf.task == 'dls') & (tempdf.animal.isin(dls_an)) & (tempdf.shift_t0 == 1) & (tempdf.reward == 1))\n",
    "\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "les_nr = calc_dist_metric(tempdf, (tempdf.task == 'dls') & (tempdf.animal.isin(dls_an)) & (tempdf.shift_t0 == 1) & (tempdf.reward == 0))\n",
    "\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "pre_r = calc_dist_metric(tempdf, (tempdf.task == 'unstr') & (tempdf.animal.isin(dls_an)) & (tempdf.shift_t0 == 1) & (tempdf.sess_bin >= 4) & (tempdf.reward == 1))\n",
    "\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "pre_nr = calc_dist_metric(tempdf, (tempdf.task == 'unstr') & (tempdf.animal.isin(dls_an)) & (tempdf.shift_t0 == 1) & (tempdf.sess_bin >= 4) & (tempdf.reward == 0))\n",
    "\n",
    "y_pre_r = pre_r[pre_r.animal.isin(dls_an)].groupby('animal').d_value.mean()\n",
    "y_pre_nr = pre_nr[pre_nr.animal.isin(dls_an)].groupby('animal').d_value.mean()\n",
    "y_pre_r_chance = pre_r[pre_r.animal.isin(dls_an)].groupby('animal').d_chance.mean()\n",
    "y_pre_nr_chance = pre_nr[pre_nr.animal.isin(dls_an)].groupby('animal').d_chance.mean()\n",
    "\n",
    "y_les_r = les_r[les_r.animal.isin(dls_an)].groupby('animal').d_value.mean()\n",
    "y_les_nr = les_nr[les_nr.animal.isin(dls_an)].groupby('animal').d_value.mean()\n",
    "y_les_r_chance = les_r[les_r.animal.isin(dls_an)].groupby('animal').d_chance.mean()\n",
    "y_les_nr_chance = les_nr[les_nr.animal.isin(dls_an)].groupby('animal').d_chance.mean()\n",
    "\n",
    "plt.figure(figsize=(3.5,4))\n",
    "width = 0.4\n",
    "# plt.bar(0-width/2, y_pre_r_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "# plt.bar(0+width/2, y_pre_nr_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "\n",
    "plt.bar(0-width/2, y_pre_r.mean(), color = 'red', yerr = y_pre_r.sem(), width = width)\n",
    "plt.bar(0+width/2, y_pre_nr.mean(), color = 'blue', yerr = y_pre_nr.sem(), width = width)\n",
    "\n",
    "plt.hlines(y_pre_r_chance.mean(), xmin = -width, xmax = 0, color = 'grey', ls = '--', lw = 2)\n",
    "plt.hlines(y_pre_nr_chance.mean(), xmin = 0, xmax = width, color = 'grey', ls = '--', lw = 2)\n",
    "\n",
    "# plt.bar(1-width/2, y_les_r_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "# plt.bar(1+width/2, y_les_nr_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "\n",
    "plt.bar(1-width/2, y_les_r.mean(), color = 'red', yerr = y_les_r.sem(), width = width)\n",
    "plt.bar(1+width/2, y_les_nr.mean(), color = 'blue', yerr = y_les_nr.sem(), width = width)\n",
    "\n",
    "plt.hlines(y_les_r_chance.mean(), xmin = 1 - width, xmax = 1, color = 'grey', ls = '--', lw = 2)\n",
    "plt.hlines(y_les_nr_chance.mean(), xmin = 1, xmax = 1+ width, color = 'grey', ls = '--', lw = 2)\n",
    "\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(1,1.9)\n",
    "plt.xticks([0, 1], ['Pre-lesion', 'Post-lesion'], fontsize = 'large', color = 'grey')\n",
    "plt.yticks([1, 1.2, 1.4, 1.6, 1.8], [1,'', '', '', 1.8], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Distance metric', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f0beaff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3827990971.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3827990971.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3827990971.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n",
      "C:\\Users\\dlab\\AppData\\Local\\Temp\\ipykernel_8772\\3827990971.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  d_chances = filtered.groupby(['animal', 'session']).apply(\n"
     ]
    }
   ],
   "source": [
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "les_r = calc_dist_metric(tempdf, (tempdf.task == 'dms') & (tempdf.animal.isin(dms_an)) & (tempdf.shift_t0 == 1) & (tempdf.reward == 1))\n",
    "\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "les_nr = calc_dist_metric(tempdf, (tempdf.task == 'dms') & (tempdf.animal.isin(dms_an)) & (tempdf.shift_t0 == 1) & (tempdf.reward == 0))\n",
    "\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "pre_r = calc_dist_metric(tempdf, (tempdf.task == 'unstr') & (tempdf.animal.isin(dms_an)) & (tempdf.shift_t0 == 1) & (tempdf.sess_bin >= 4) & (tempdf.reward == 1))\n",
    "\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "pre_nr = calc_dist_metric(tempdf, (tempdf.task == 'unstr') & (tempdf.animal.isin(dms_an)) & (tempdf.shift_t0 == 1) & (tempdf.sess_bin >= 4) & (tempdf.reward == 0))\n",
    "\n",
    "y_pre_r = pre_r[pre_r.animal.isin(dms_an)].groupby('animal').d_value.mean()\n",
    "y_pre_nr = pre_nr[pre_nr.animal.isin(dms_an)].groupby('animal').d_value.mean()\n",
    "y_pre_r_chance = pre_r[pre_r.animal.isin(dms_an)].groupby('animal').d_chance.mean()\n",
    "y_pre_nr_chance = pre_nr[pre_nr.animal.isin(dms_an)].groupby('animal').d_chance.mean()\n",
    "\n",
    "y_les_r = les_r[les_r.animal.isin(dms_an)].groupby('animal').d_value.mean()\n",
    "y_les_nr = les_nr[les_nr.animal.isin(dms_an)].groupby('animal').d_value.mean()\n",
    "y_les_r_chance = les_r[les_r.animal.isin(dms_an)].groupby('animal').d_chance.mean()\n",
    "y_les_nr_chance = les_nr[les_nr.animal.isin(dms_an)].groupby('animal').d_chance.mean()\n",
    "\n",
    "plt.figure(figsize=(3.5,4))\n",
    "width = 0.4\n",
    "# plt.bar(0-width/2, y_pre_r_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "# plt.bar(0+width/2, y_pre_nr_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "\n",
    "plt.bar(0-width/2, y_pre_r.mean(), color = 'red', yerr = y_pre_r.sem(), width = width)\n",
    "plt.bar(0+width/2, y_pre_nr.mean(), color = 'blue', yerr = y_pre_nr.sem(), width = width)\n",
    "\n",
    "plt.hlines(y_pre_r_chance.mean(), xmin = -width, xmax = 0, color = 'grey', ls = '--', lw = 2)\n",
    "plt.hlines(y_pre_nr_chance.mean(), xmin = 0, xmax = width, color = 'grey', ls = '--', lw = 2)\n",
    "\n",
    "# plt.bar(1-width/2, y_les_r_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "# plt.bar(1+width/2, y_les_nr_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "\n",
    "plt.bar(1-width/2, y_les_r.mean(), color = 'red', yerr = y_les_r.sem(), width = width)\n",
    "plt.bar(1+width/2, y_les_nr.mean(), color = 'blue', yerr = y_les_nr.sem(), width = width)\n",
    "\n",
    "plt.hlines(y_les_r_chance.mean(), xmin = 1-width, xmax = 1, color = 'grey', ls = '--', lw = 2)\n",
    "plt.hlines(y_les_nr_chance.mean(), xmin = 1, xmax = 1+width, color = 'grey', ls = '--', lw = 2)\n",
    "\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(1,1.9)\n",
    "plt.xticks([0, 1], ['Pre-lesion', 'Post-lesion'], fontsize = 'large', color = 'grey')\n",
    "plt.yticks([1, 1.2, 1.4, 1.6, 1.8], [1,'', '', '', 1.8], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Distance metric', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "53c14706",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "les_r = calc_dist_metric(tempdf, (tempdf.task == 'str') & (tempdf.animal.isin(fish)) & (tempdf.shift_t0 == 1) & (tempdf.reward == 1))\n",
    "\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "les_nr = calc_dist_metric(tempdf, (tempdf.task == 'str') & (tempdf.animal.isin(fish)) & (tempdf.shift_t0 == 1) & (tempdf.reward == 0))\n",
    "\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "pre_r = calc_dist_metric(tempdf, (tempdf.task == 'unstr') & (tempdf.animal.isin(fish)) & (tempdf.shift_t0 == 1) & (tempdf.sess_bin >= 4) & (tempdf.reward == 1))\n",
    "\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)\n",
    "pre_nr = calc_dist_metric(tempdf, (tempdf.task == 'unstr') & (tempdf.animal.isin(fish)) & (tempdf.shift_t0 == 1) & (tempdf.sess_bin >= 4) & (tempdf.reward == 0))\n",
    "\n",
    "y_pre_r = pre_r[pre_r.animal.isin(fish)].groupby('animal').d_value.mean()\n",
    "y_pre_nr = pre_nr[pre_nr.animal.isin(fish)].groupby('animal').d_value.mean()\n",
    "y_pre_r_chance = pre_r[pre_r.animal.isin(fish)].groupby('animal').d_chance.mean()\n",
    "y_pre_nr_chance = pre_nr[pre_nr.animal.isin(fish)].groupby('animal').d_chance.mean()\n",
    "\n",
    "y_les_r = les_r[les_r.animal.isin(fish)].groupby('animal').d_value.mean()\n",
    "y_les_nr = les_nr[les_nr.animal.isin(fish)].groupby('animal').d_value.mean()\n",
    "y_les_r_chance = les_r[les_r.animal.isin(fish)].groupby('animal').d_chance.mean()\n",
    "y_les_nr_chance = les_nr[les_nr.animal.isin(fish)].groupby('animal').d_chance.mean()\n",
    "\n",
    "plt.figure(figsize=(3.5,4))\n",
    "width = 0.4\n",
    "plt.bar(0-width/2, y_pre_r_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "plt.bar(0+width/2, y_pre_nr_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "\n",
    "plt.bar(0-width/2, y_pre_r.mean(), color = 'red', yerr = y_pre_r.sem(), width = width)\n",
    "plt.bar(0+width/2, y_pre_nr.mean(), color = 'blue', yerr = y_pre_nr.sem(), width = width)\n",
    "\n",
    "plt.bar(1-width/2, y_les_r_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "plt.bar(1+width/2, y_les_nr_chance.mean(), color = 'grey', alpha = 0.2, width = width)\n",
    "\n",
    "plt.bar(1-width/2, y_les_r.mean(), color = 'red', yerr = y_les_r.sem(), width = width)\n",
    "plt.bar(1+width/2, y_les_nr.mean(), color = 'blue', yerr = y_les_nr.sem(), width = width)\n",
    "\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(1,1.9)\n",
    "plt.xticks([0, 1], ['Unstructured', 'Structured'], fontsize = 'large', color = 'grey')\n",
    "plt.yticks([1, 1.2, 1.4, 1.6, 1.8], [1,'', '', '', 1.8], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Distance metric', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5569bd5",
   "metadata": {},
   "source": [
    "# Switch probability pairwise comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85825d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialsinsess = 100\n",
    "from utils.dfLoading import subset_trials\n",
    "tempdf = subset_trials(sessdf, trialsinsess=trialsinsess, head_trials=True)\n",
    "cond = 'str'\n",
    "yr = tempdf[(tempdf.task == 'unstr') & (tempdf.animal.isin(an_dict[cond])) & (tempdf.sess_bin>=4)].groupby('animal').shift_t0.mean().mean()\n",
    "ynr = tempdf[(tempdf.task == cond) & (tempdf.animal.isin(an_dict[cond]))].groupby('animal').shift_t0.mean().mean()\n",
    "\n",
    "yr_err = tempdf[(tempdf.task == 'unstr') & (tempdf.animal.isin(an_dict[cond])) & (tempdf.sess_bin>=4)].groupby('animal').shift_t0.mean().sem()\n",
    "ynr_err = tempdf[(tempdf.task == cond) & (tempdf.animal.isin(an_dict[cond]))].groupby('animal').shift_t0.mean().sem()\n",
    "\n",
    "plt.figure(figsize=(3.5,4))\n",
    "plt.bar(0, yr, color = 'xkcd:pumpkin orange', yerr = yr_err, width = 0.6)\n",
    "plt.bar(1, ynr, color = 'xkcd:emerald green', yerr = ynr_err, width = 0.6)\n",
    "plt.xticks([0, 1], ['Unstructured', 'Structured'], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Switch probability', fontsize = 'x-large')\n",
    "# plt.yticks([0, 0.25], ['0.00', 0.25], fontsize = 'large', color = 'grey')///////////\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d40d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.dfLoading import subset_trials, add_shift_info\n",
    "# sessdf = add_shift_info(sessdf)\n",
    "# tempdf = subset_trials(sessdf, trialsinsess=trialsinsess, head_trials=trialsinsess)\n",
    "yr = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 1) & (tempdf.sess_bin>=4)].groupby('animal').shift_t0.mean().mean()\n",
    "ynr = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 0) & (tempdf.sess_bin>=4)].groupby('animal').shift_t0.mean().mean()\n",
    "\n",
    "yr_err = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 1) & (tempdf.sess_bin>=4)].groupby('animal').shift_t0.mean().sem()\n",
    "ynr_err = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 0) & (tempdf.sess_bin>=4)].groupby('animal').shift_t0.mean().sem()\n",
    "\n",
    "plt.figure(figsize=(3.5,4))\n",
    "plt.bar(0, yr, color = 'red', yerr = yr_err, width = 0.6)\n",
    "plt.bar(1, ynr, color = 'blue', yerr = ynr_err, width = 0.6)\n",
    "plt.xticks([0, 1], ['Reward', 'No reward'], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Switch probability', fontsize = 'x-large')\n",
    "plt.yticks([0, 0.25], ['0.00', 0.25], fontsize = 'large', color = 'grey')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4d7dd725",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish = an_dict['str']\n",
    "yr_unstr = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 1) & (tempdf.sess_bin>=4) & tempdf.animal.isin(fish)].groupby('animal').shift_t0.mean().mean()\n",
    "ynr_unstr = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 0) & (tempdf.sess_bin>=4) & tempdf.animal.isin(fish)].groupby('animal').shift_t0.mean().mean()\n",
    "\n",
    "yr_unstr_err = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 1) & (tempdf.sess_bin>=4) & tempdf.animal.isin(fish)].groupby('animal').shift_t0.mean().sem()\n",
    "ynr_unstr_err = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 0) & (tempdf.sess_bin>=4) & tempdf.animal.isin(fish)].groupby('animal').shift_t0.mean().sem()\n",
    "\n",
    "yr_str = tempdf[(tempdf.task == 'str') & (tempdf.reward == 1) & tempdf.animal.isin(fish)].groupby('animal').shift_t0.mean().mean()\n",
    "ynr_str = tempdf[(tempdf.task == 'str') & (tempdf.reward == 0) & tempdf.animal.isin(fish)].groupby('animal').shift_t0.mean().mean()\n",
    "\n",
    "yr_str_err = tempdf[(tempdf.task == 'str') & (tempdf.reward == 1) & tempdf.animal.isin(fish)].groupby('animal').shift_t0.mean().sem()\n",
    "ynr_str_err = tempdf[(tempdf.task == 'str') & (tempdf.reward == 0) & tempdf.animal.isin(fish)].groupby('animal').shift_t0.mean().sem()\n",
    "\n",
    "plt.figure(figsize=(3.5,4))\n",
    "width = 0.4\n",
    "plt.bar(0 - width/2, yr_unstr, color = 'red', yerr = yr_unstr_err, width = width)\n",
    "plt.bar(0 + width/2, ynr_unstr, color = 'blue', yerr = yr_unstr_err, width = width)\n",
    "\n",
    "plt.bar(1 - width/2, yr_str, color = 'red', yerr = yr_str_err, width = width)\n",
    "plt.bar(1 + width/2, ynr_str, color = 'blue', yerr = ynr_str_err, width = width)\n",
    "plt.ylim(0, 0.4)\n",
    "plt.xticks([0, 1], ['Unstructured', 'Structured'], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Switch rate', fontsize = 'x-large')\n",
    "plt.yticks([0, 0.2, 0.4], ['0.0', 0.2, 0.4], fontsize = 'large', color = 'grey')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55b82b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dms_an = an_dict['dms']\n",
    "yr_unstr = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 1) & (tempdf.sess_bin>=4) & tempdf.animal.isin(dms_an)].groupby('animal').shift_t0.mean().mean()\n",
    "ynr_unstr = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 0) & (tempdf.sess_bin>=4) & tempdf.animal.isin(dms_an)].groupby('animal').shift_t0.mean().mean()\n",
    "\n",
    "yr_unstr_err = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 1) & (tempdf.sess_bin>=4) & tempdf.animal.isin(dms_an)].groupby('animal').shift_t0.mean().sem()\n",
    "ynr_unstr_err = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 0) & (tempdf.sess_bin>=4)& tempdf.animal.isin(dms_an)].groupby('animal').shift_t0.mean().sem()\n",
    "\n",
    "yr_str = tempdf[(tempdf.task == 'dms') & (tempdf.reward == 1) & tempdf.animal.isin(dms_an)].groupby('animal').shift_t0.mean().mean()\n",
    "ynr_str = tempdf[(tempdf.task == 'dms') & (tempdf.reward == 0) & tempdf.animal.isin(dms_an)].groupby('animal').shift_t0.mean().mean()\n",
    "\n",
    "yr_str_err = tempdf[(tempdf.task == 'dms') & (tempdf.reward == 1) & tempdf.animal.isin(dms_an)].groupby('animal').shift_t0.mean().sem()\n",
    "ynr_str_err = tempdf[(tempdf.task == 'dms') & (tempdf.reward == 0) & tempdf.animal.isin(dms_an)].groupby('animal').shift_t0.mean().sem()\n",
    "\n",
    "plt.figure(figsize=(3.5,4))\n",
    "width = 0.4\n",
    "plt.bar(0 - width/2, yr_unstr, color = 'red', yerr = yr_unstr_err, width = width)\n",
    "plt.bar(0 + width/2, ynr_unstr, color = 'blue', yerr = yr_unstr_err, width = width)\n",
    "\n",
    "plt.bar(1 - width/2, yr_str, color = 'red', yerr = yr_str_err, width = width)\n",
    "plt.bar(1 + width/2, ynr_str, color = 'blue', yerr = ynr_str_err, width = width)\n",
    "plt.ylim(0, 0.45)\n",
    "plt.xticks([0, 1], ['Pre-lesion', 'Post-lesion'], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Switch rate', fontsize = 'x-large')\n",
    "plt.yticks([0, 0.2, 0.4], ['0.0', 0.2, 0.4], fontsize = 'large', color = 'grey')\n",
    "sns.despine()\n",
    "\n",
    "# Statistical annotations\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Rewarded pre vs post\n",
    "rewarded_pre = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 1) & (tempdf.sess_bin>=4) & tempdf.animal.isin(dms_an)].groupby('animal').shift_t0.mean()\n",
    "rewarded_post = tempdf[(tempdf.task == 'dms') & (tempdf.reward == 1) & tempdf.animal.isin(dms_an)].groupby('animal').shift_t0.mean()\n",
    "t_stat, p_val = ttest_rel(rewarded_pre, rewarded_post)\n",
    "\n",
    "# Unrewarded pre vs post\n",
    "unrewarded_pre = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 0) & (tempdf.sess_bin>=4) & tempdf.animal.isin(dms_an)].groupby('animal').shift_t0.mean()\n",
    "unrewarded_post = tempdf[(tempdf.task == 'dms') & (tempdf.reward == 0) & tempdf.animal.isin(dms_an)].groupby('animal').shift_t0.mean()\n",
    "t_stat2, p_val2 = ttest_rel(unrewarded_pre, unrewarded_post)\n",
    "\n",
    "# Add annotations\n",
    "max_nr = max(ynr_unstr + ynr_unstr_err, ynr_str + ynr_str_err)\n",
    "\n",
    "if p_val < 0.05:\n",
    "    plt.plot([0 - width/2, 1 - width/2], [max_nr + 0.05, max_nr + 0.05], color='black', linewidth=1)\n",
    "    plt.text(0.5, max_nr + 0.055, f'p={p_val:.3f}', ha='center', fontsize=10)\n",
    "else:\n",
    "    plt.plot([0 - width/2, 1 - width/2], [max_nr + 0.05, max_nr + 0.05], color='black', linewidth=1)\n",
    "    plt.text(0.5, max_nr + 0.055, 'ns', ha='center', fontsize=10)\n",
    "\n",
    "if p_val2 < 0.05:\n",
    "    plt.plot([0 + width/2, 1 + width/2], [max_nr + 0.1, max_nr + 0.1], color='black', linewidth=1)\n",
    "    plt.text(0.5, max_nr + 0.105, f'p={p_val2:.3f}', ha='center', fontsize=10)\n",
    "else:\n",
    "    plt.plot([0 + width/2, 1 + width/2], [max_nr + 0.1, max_nr + 0.1], color='black', linewidth=1)\n",
    "    plt.text(0.5, max_nr + 0.105, 'ns', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dada93d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_an = an_dict['dls']\n",
    "yr_unstr = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 1) & (tempdf.sess_bin>=4) & tempdf.animal.isin(dls_an)].groupby('animal').shift_t0.mean().mean()\n",
    "ynr_unstr = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 0) & (tempdf.sess_bin>=4) & tempdf.animal.isin(dls_an)].groupby('animal').shift_t0.mean().mean()\n",
    "\n",
    "yr_unstr_err = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 1) & (tempdf.sess_bin>=4) & tempdf.animal.isin(dls_an)].groupby('animal').shift_t0.mean().sem()\n",
    "ynr_unstr_err = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 0) & (tempdf.sess_bin>=4)& tempdf.animal.isin(dls_an)].groupby('animal').shift_t0.mean().sem()\n",
    "\n",
    "yr_str = tempdf[(tempdf.task == 'dls') & (tempdf.reward == 1) & tempdf.animal.isin(dls_an)].groupby('animal').shift_t0.mean().mean()\n",
    "ynr_str = tempdf[(tempdf.task == 'dls') & (tempdf.reward == 0) & tempdf.animal.isin(dls_an)].groupby('animal').shift_t0.mean().mean()\n",
    "\n",
    "yr_str_err = tempdf[(tempdf.task == 'dls') & (tempdf.reward == 1) & tempdf.animal.isin(dls_an)].groupby('animal').shift_t0.mean().sem()\n",
    "ynr_str_err = tempdf[(tempdf.task == 'dls') & (tempdf.reward == 0) & tempdf.animal.isin(dls_an)].groupby('animal').shift_t0.mean().sem()\n",
    "\n",
    "plt.figure(figsize=(3.5,4))\n",
    "width = 0.4\n",
    "plt.bar(0 - width/2, yr_unstr, color = 'red', yerr = yr_unstr_err, width = width)\n",
    "plt.bar(0 + width/2, ynr_unstr, color = 'blue', yerr = yr_unstr_err, width = width)\n",
    "\n",
    "plt.bar(1 - width/2, yr_str, color = 'red', yerr = yr_str_err, width = width)\n",
    "plt.bar(1 + width/2, ynr_str, color = 'blue', yerr = ynr_str_err, width = width)\n",
    "plt.ylim(0, 0.45)\n",
    "plt.xticks([0, 1], ['Pre-lesion', 'Post-lesion'], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Switch rate', fontsize = 'x-large')\n",
    "plt.yticks([0, 0.2, 0.4], ['0.0', 0.2, 0.4], fontsize = 'large', color = 'grey')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# Statistical annotations\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Rewarded pre vs post\n",
    "rewarded_pre = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 1) & (tempdf.sess_bin>=4) & tempdf.animal.isin(dls_an)].groupby('animal').shift_t0.mean()\n",
    "rewarded_post = tempdf[(tempdf.task == 'dls') & (tempdf.reward == 1) & tempdf.animal.isin(dls_an)].groupby('animal').shift_t0.mean()\n",
    "t_stat, p_val = ttest_rel(rewarded_pre, rewarded_post)\n",
    "\n",
    "# Unrewarded pre vs post\n",
    "unrewarded_pre = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 0) & (tempdf.sess_bin>=4) & tempdf.animal.isin(dls_an)].groupby('animal').shift_t0.mean()\n",
    "unrewarded_post = tempdf[(tempdf.task == 'dls') & (tempdf.reward == 0) & tempdf.animal.isin(dls_an)].groupby('animal').shift_t0.mean()\n",
    "t_stat2, p_val2 = ttest_rel(unrewarded_pre, unrewarded_post)\n",
    "\n",
    "# Add annotations\n",
    "max_nr = max(ynr_unstr + ynr_unstr_err, ynr_str + ynr_str_err)\n",
    "\n",
    "if p_val < 0.05:\n",
    "    plt.plot([0 - width/2, 1 - width/2], [max_nr + 0.05, max_nr + 0.05], color='black', linewidth=1)\n",
    "    plt.text(0.5, max_nr + 0.055, f'p={p_val:.3f}', ha='center', fontsize=10)\n",
    "else:\n",
    "    plt.plot([0 - width/2, 1 - width/2], [max_nr + 0.05, max_nr + 0.05], color='black', linewidth=1)\n",
    "    plt.text(0.5, max_nr + 0.055, 'ns', ha='center', fontsize=10)\n",
    "\n",
    "if p_val2 < 0.05:\n",
    "    plt.plot([0 + width/2, 1 + width/2], [max_nr + 0.1, max_nr + 0.1], color='black', linewidth=1)\n",
    "    plt.text(0.5, max_nr + 0.105, f'p={p_val2:.3f}', ha='center', fontsize=10)\n",
    "else:\n",
    "    plt.plot([0 + width/2, 1 + width/2], [max_nr + 0.1, max_nr + 0.1], color='black', linewidth=1)\n",
    "    plt.text(0.5, max_nr + 0.105, 'ns', ha='center', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f26c187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sham_an = an_dict['sham']\n",
    "yr_unstr = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 1) & (tempdf.sess_bin>=4) & tempdf.animal.isin(sham_an)].groupby('animal').shift_t0.mean().mean()\n",
    "ynr_unstr = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 0) & (tempdf.sess_bin>=4) & tempdf.animal.isin(sham_an)].groupby('animal').shift_t0.mean().mean()\n",
    "\n",
    "yr_unstr_err = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 1) & (tempdf.sess_bin>=4) & tempdf.animal.isin(sham_an)].groupby('animal').shift_t0.mean().sem()\n",
    "ynr_unstr_err = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 0) & (tempdf.sess_bin>=4)& tempdf.animal.isin(sham_an)].groupby('animal').shift_t0.mean().sem()\n",
    "\n",
    "yr_str = tempdf[(tempdf.task == 'sham') & (tempdf.reward == 1) & tempdf.animal.isin(sham_an)].groupby('animal').shift_t0.mean().mean()\n",
    "ynr_str = tempdf[(tempdf.task == 'sham') & (tempdf.reward == 0) & tempdf.animal.isin(sham_an)].groupby('animal').shift_t0.mean().mean()\n",
    "\n",
    "yr_str_err = tempdf[(tempdf.task == 'sham') & (tempdf.reward == 1) & tempdf.animal.isin(sham_an)].groupby('animal').shift_t0.mean().sem()\n",
    "ynr_str_err = tempdf[(tempdf.task == 'sham') & (tempdf.reward == 0) & tempdf.animal.isin(sham_an)].groupby('animal').shift_t0.mean().sem()\n",
    "\n",
    "plt.figure(figsize=(3.5,4))\n",
    "width = 0.4\n",
    "plt.bar(0 - width/2, yr_unstr, color = 'red', yerr = yr_unstr_err, width = width)\n",
    "plt.bar(0 + width/2, ynr_unstr, color = 'blue', yerr = yr_unstr_err, width = width)\n",
    "\n",
    "plt.bar(1 - width/2, yr_str, color = 'red', yerr = yr_str_err, width = width)\n",
    "plt.bar(1 + width/2, ynr_str, color = 'blue', yerr = ynr_str_err, width = width)\n",
    "plt.ylim(0, 0.45)\n",
    "plt.xticks([0, 1], ['Pre-lesion', 'Post-lesion'], fontsize = 'large', color = 'grey')\n",
    "plt.ylabel('Switch rate', fontsize = 'x-large')\n",
    "plt.yticks([0, 0.2, 0.4], ['0.0', 0.2, 0.4], fontsize = 'large', color = 'grey')\n",
    "sns.despine()\n",
    "\n",
    "# Statistical annotations\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Rewarded pre vs post\n",
    "rewarded_pre = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 1) & (tempdf.sess_bin>=4) & tempdf.animal.isin(sham_an)].groupby('animal').shift_t0.mean()\n",
    "rewarded_post = tempdf[(tempdf.task == 'sham') & (tempdf.reward == 1) & tempdf.animal.isin(sham_an)].groupby('animal').shift_t0.mean()\n",
    "t_stat, p_val = ttest_rel(rewarded_pre, rewarded_post)\n",
    "\n",
    "# Unrewarded pre vs post\n",
    "unrewarded_pre = tempdf[(tempdf.task == 'unstr') & (tempdf.reward == 0) & (tempdf.sess_bin>=4) & tempdf.animal.isin(sham_an)].groupby('animal').shift_t0.mean()\n",
    "unrewarded_post = tempdf[(tempdf.task == 'sham') & (tempdf.reward == 0) & tempdf.animal.isin(sham_an)].groupby('animal').shift_t0.mean()\n",
    "t_stat2, p_val2 = ttest_rel(unrewarded_pre, unrewarded_post)\n",
    "\n",
    "# Add annotations\n",
    "max_nr = max(ynr_unstr + ynr_unstr_err, ynr_str + ynr_str_err)-0.02\n",
    "\n",
    "if p_val < 0.05:\n",
    "    plt.plot([0 - width/2, 1 - width/2], [max_nr + 0.05, max_nr + 0.05], color='black', linewidth=1)\n",
    "    plt.text(0.5, max_nr + 0.055, f'p={p_val:.3f}', ha='center', fontsize=10)\n",
    "else:\n",
    "    plt.plot([0 - width/2, 1 - width/2], [max_nr + 0.05, max_nr + 0.05], color='black', linewidth=1)\n",
    "    plt.text(0.5, max_nr + 0.055, 'ns', ha='center', fontsize=10)\n",
    "\n",
    "if p_val2 < 0.05:\n",
    "    plt.plot([0 + width/2, 1 + width/2], [max_nr + 0.1, max_nr + 0.1], color='black', linewidth=1)\n",
    "    plt.text(0.5, max_nr + 0.105, f'p={p_val2:.3f}', ha='center', fontsize=10)\n",
    "else:\n",
    "    plt.plot([0 + width/2, 1 + width/2], [max_nr + 0.1, max_nr + 0.1], color='black', linewidth=1)\n",
    "    plt.text(0.5, max_nr + 0.105, 'ns', ha='center', fontsize=10)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff260a02",
   "metadata": {},
   "source": [
    "# metric vs/ metric correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "32814639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot perf index for each animal vs bias\n",
    "trialsinsess = 100\n",
    "tempdf = sessdf.groupby(['animal','session']).filter(lambda x: x.reward.size >= trialsinsess).groupby(['animal','session']).head(trialsinsess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "af6152ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018206987697983328 -1.7331756284868047 1.734430831227499\n",
      "[-1.73317563] 1.734430831227499\n"
     ]
    }
   ],
   "source": [
    "# calculate entropy per session\n",
    "# tempdf[(tempdf.task == 'unstr')&(tempdf.sess_bin>=4)].groupby(['animal', 'session']).entropy.mean().unstack().mean(axis = 1)\n",
    "\n",
    "# convert to numpy array\n",
    "# g = tempdf.groupby(['animal', 'session']).cumcount()\n",
    "# L = np.array(tempdf.set_index(['session',g])\n",
    "#         .unstack(fill_value=0)\n",
    "#         .stack().groupby(level=0)\n",
    "#         .apply(lambda x: x.port.values.tolist())\n",
    "#         .tolist())\n",
    "# # mean\n",
    "# entropy_trial = [entropy(calc_prob(L[:, col]), base = 2) for col in range(L.shape[1])]\n",
    "\n",
    "y = tempdf[(tempdf.task == 'unstr')&(tempdf.sess_bin>=4)].groupby(['animal', 'session']).port.apply(lambda x: entropy(calc_prob(x[:10]), base = 2)).unstack().mean(axis = 1)\n",
    "\n",
    "x = tempdf[(tempdf.task == 'unstr')&(tempdf.sess_bin>=4)].groupby(['animal', 'session']).rr.mean().unstack().mean(axis = 1)\n",
    "# sns.regplot(x =x, y=y, ci = None)\n",
    "# regress x against y and draw a line with coefficient and intercept from model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import linregress\n",
    "model = LinearRegression()\n",
    "model.fit(x.values.reshape(-1, 1), y.values)\n",
    "r_sq = model.score(x.values.reshape(-1, 1), y.values)\n",
    "plt.figure()\n",
    "plt.scatter(x, y, color = 'grey')\n",
    "plt.plot(x, model.predict(x.values.reshape(-1, 1)), color = 'red')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x,y)\n",
    "print(p_value, slope, intercept)\n",
    "print(model.coef_, model.intercept_)\n",
    "plt.title(fr'$R^2$ = {round(r_sq, 4)}, p = {round(p_value, 4)}', fontsize = 'large')\n",
    "plt.xlabel('Reward rate', fontsize = 'x-large')\n",
    "\n",
    "plt.ylabel('Entropy', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "\n",
    "# sns.regplot(x = x, y = y, ci = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5615859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tempdf[(tempdf.task == 'unstr')&(tempdf.sess_bin>=4)].groupby(['animal', 'session']).shift_t0.mean().unstack().mean(axis = 1)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import linregress\n",
    "model = LinearRegression()\n",
    "model.fit(x.values.reshape(-1, 1), y.values)\n",
    "r_sq = model.score(x.values.reshape(-1, 1), y.values)\n",
    "plt.figure()\n",
    "plt.scatter(x, y, color = 'grey')\n",
    "plt.plot(x, model.predict(x.values.reshape(-1, 1)), color = 'red')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x,y)\n",
    "print(p_value, slope, intercept)\n",
    "print(model.coef_, model.intercept_)\n",
    "plt.title(fr'$R^2$ = {round(r_sq, 4)}, p = {round(p_value, 4)}', fontsize = 'large')\n",
    "plt.xlabel('Performance index', fontsize = 'x-large')\n",
    "plt.ylabel('Average switch probability', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "f0e38c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12515671710251056 -2.634573790691113 3.363466412685049\n",
      "[-2.63457379] 3.363466412685049\n"
     ]
    }
   ],
   "source": [
    "y = tempdf[(tempdf.task == 'unstr')&(tempdf.sess_bin>=4)&(tempdf.shift_t0 == 1)].groupby(['animal', 'session']).disp.apply(lambda x: np.mean(abs(x))).unstack().mean(axis = 1)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import linregress\n",
    "model = LinearRegression()\n",
    "model.fit(x.values.reshape(-1, 1), y.values)\n",
    "r_sq = model.score(x.values.reshape(-1, 1), y.values)\n",
    "plt.figure()\n",
    "plt.scatter(x, y, color = 'grey')\n",
    "plt.plot(x, model.predict(x.values.reshape(-1, 1)), color = 'red')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x,y)\n",
    "print(p_value, slope, intercept)\n",
    "print(model.coef_, model.intercept_)\n",
    "plt.title(fr'$R^2$ = {round(r_sq, 4)}, p = {round(p_value, 4)}', fontsize = 'large')\n",
    "plt.xlabel('Performance index', fontsize = 'x-large')\n",
    "plt.ylabel('Average switch distance', fontsize = 'x-large')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rishika",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
