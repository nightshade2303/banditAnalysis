{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aaeec80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.ndimage import uniform_filter, gaussian_filter1d\n",
    "from scipy.stats import sem, pearsonr, entropy\n",
    "\n",
    "import seaborn as sns\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "sns.set_theme()\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a3ad68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# PROBABILITY FUNCTIONS ################\n",
    "def fxn(mean, arms):\n",
    "    x = np.linspace(1, arms, arms)\n",
    "    sig = 1.75/2\n",
    "#     amp = 1/(sig*np.sqrt(2*np.pi))\n",
    "    amp = 0.7\n",
    "    vo = 0.1\n",
    "    gx = (amp*np.exp(-0.5*((x-mean)**2)/(sig**2)))+vo\n",
    "#     gx = np.random.permutation(gx)\n",
    "    return gx\n",
    "\n",
    "def cauchy(median, arms):\n",
    "#     cauchy = @(x, s, t)(1./(s*pi*(1+(((x-t)./s).^2))))\n",
    "    x = np.linspace(1, arms, arms)\n",
    "    s = 1.5\n",
    "    cauchy = ((1/(s*np.pi*(1+(((x-median)/s)**2))))*3.5)+0.1;\n",
    "    return cauchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1a769872-ad1d-4657-ac6c-6c34c7115546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.8       , 0.46431508, 0.15135876, 0.10196115]), array([0.46431508, 0.8       , 0.46431508, 0.15135876]), array([0.15135876, 0.46431508, 0.8       , 0.46431508]), array([0.10196115, 0.15135876, 0.46431508, 0.8       ])] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fxn(mean, arms, permute = False):\n",
    "    x = np.linspace(1, arms, arms)\n",
    "    sig = 1.75/2\n",
    "#     amp = 1/(sig*np.sqrt(2*np.pi))\n",
    "    amp = 0.7\n",
    "    vo = 0.1\n",
    "    gx = (amp*np.exp(-0.5*((x-mean)**2)/(sig**2)))+vo\n",
    "    if permute:\n",
    "        gx = np.random.permutation(gx)\n",
    "    return gx\n",
    "    \n",
    "# fig = plt.figure(figsize = (4,6))\n",
    "plt.figure()\n",
    "arms = 4\n",
    "\n",
    "l = [fxn(i, arms, False) for i in range(1,arms+1)]\n",
    "for ind in range(arms):\n",
    "    ax = plt.subplot(4, 1, ind+1)\n",
    "    ax.bar(np.arange(1, arms+1), l[ind], color = 'xkcd:emerald green')\n",
    "    \n",
    "    sns.despine()\n",
    "    ax.set_xticks(np.arange(1,arms+1), np.arange(1,arms+1))\n",
    "print(l,'\\n')\n",
    "    # ax.set_yticks(np.arange(4)*0.25, np.arange(4)*0.25)\n",
    "#     if ind == 3:\n",
    "#         break\n",
    "# fig.supxlabel('Ports')\n",
    "# fig.supylabel('Reward probability')\n",
    "# plt.tight_layout()\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "cm_data = [[0.2081, 0.1663, 0.5292], [0.2116238095, 0.1897809524, 0.5776761905], \n",
    " [0.212252381, 0.2137714286, 0.6269714286], [0.2081, 0.2386, 0.6770857143], \n",
    " [0.1959047619, 0.2644571429, 0.7279], [0.1707285714, 0.2919380952, \n",
    "  0.779247619], [0.1252714286, 0.3242428571, 0.8302714286], \n",
    " [0.0591333333, 0.3598333333, 0.8683333333], [0.0116952381, 0.3875095238, \n",
    "  0.8819571429], [0.0059571429, 0.4086142857, 0.8828428571], \n",
    " [0.0165142857, 0.4266, 0.8786333333], [0.032852381, 0.4430428571, \n",
    "  0.8719571429], [0.0498142857, 0.4585714286, 0.8640571429], \n",
    " [0.0629333333, 0.4736904762, 0.8554380952], [0.0722666667, 0.4886666667, \n",
    "  0.8467], [0.0779428571, 0.5039857143, 0.8383714286], \n",
    " [0.079347619, 0.5200238095, 0.8311809524], [0.0749428571, 0.5375428571, \n",
    "  0.8262714286], [0.0640571429, 0.5569857143, 0.8239571429], \n",
    " [0.0487714286, 0.5772238095, 0.8228285714], [0.0343428571, 0.5965809524, \n",
    "  0.819852381], [0.0265, 0.6137, 0.8135], [0.0238904762, 0.6286619048, \n",
    "  0.8037619048], [0.0230904762, 0.6417857143, 0.7912666667], \n",
    " [0.0227714286, 0.6534857143, 0.7767571429], [0.0266619048, 0.6641952381, \n",
    "  0.7607190476], [0.0383714286, 0.6742714286, 0.743552381], \n",
    " [0.0589714286, 0.6837571429, 0.7253857143], \n",
    " [0.0843, 0.6928333333, 0.7061666667], [0.1132952381, 0.7015, 0.6858571429], \n",
    " [0.1452714286, 0.7097571429, 0.6646285714], [0.1801333333, 0.7176571429, \n",
    "  0.6424333333], [0.2178285714, 0.7250428571, 0.6192619048], \n",
    " [0.2586428571, 0.7317142857, 0.5954285714], [0.3021714286, 0.7376047619, \n",
    "  0.5711857143], [0.3481666667, 0.7424333333, 0.5472666667], \n",
    " [0.3952571429, 0.7459, 0.5244428571], [0.4420095238, 0.7480809524, \n",
    "  0.5033142857], [0.4871238095, 0.7490619048, 0.4839761905], \n",
    " [0.5300285714, 0.7491142857, 0.4661142857], [0.5708571429, 0.7485190476, \n",
    "  0.4493904762], [0.609852381, 0.7473142857, 0.4336857143], \n",
    " [0.6473, 0.7456, 0.4188], [0.6834190476, 0.7434761905, 0.4044333333], \n",
    " [0.7184095238, 0.7411333333, 0.3904761905], \n",
    " [0.7524857143, 0.7384, 0.3768142857], [0.7858428571, 0.7355666667, \n",
    "  0.3632714286], [0.8185047619, 0.7327333333, 0.3497904762], \n",
    " [0.8506571429, 0.7299, 0.3360285714], [0.8824333333, 0.7274333333, 0.3217], \n",
    " [0.9139333333, 0.7257857143, 0.3062761905], [0.9449571429, 0.7261142857, \n",
    "  0.2886428571], [0.9738952381, 0.7313952381, 0.266647619], \n",
    " [0.9937714286, 0.7454571429, 0.240347619], [0.9990428571, 0.7653142857, \n",
    "  0.2164142857], [0.9955333333, 0.7860571429, 0.196652381], \n",
    " [0.988, 0.8066, 0.1793666667], [0.9788571429, 0.8271428571, 0.1633142857], \n",
    " [0.9697, 0.8481380952, 0.147452381], [0.9625857143, 0.8705142857, 0.1309], \n",
    " [0.9588714286, 0.8949, 0.1132428571], [0.9598238095, 0.9218333333, \n",
    "  0.0948380952], [0.9661, 0.9514428571, 0.0755333333], \n",
    " [0.9763, 0.9831, 0.0538]]\n",
    "\n",
    "# parula_map = LinearSegmentedColormap.from_list('parula', cm_data)\n",
    "# For use of \"viscm view\"\n",
    "# test_cm = parula_map\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import numpy as np\n",
    "\n",
    "    # try:\n",
    "    #     from viscm import viscm\n",
    "    #     viscm(parula_map)\n",
    "    # except ImportError:\n",
    "    #     print(\"viscm not found, falling back on simple display\")\n",
    "    #     plt.imshow(np.linspace(0, 100, 256)[None, :], aspect='auto',\n",
    "    #                cmap=parula_map)\n",
    "    # plt.show()\n",
    "\n",
    "# l = [fxn(np.random.randint(1, arms+1), arms, True) for i in range(10000)]\n",
    "# sns.heatmap(np.corrcoef(np.array(l).T),\n",
    "#             cmap = parula_map, vmin = -1, vmax = 1, square = True,\n",
    "#             xticklabels = np.arange(1, arms+1), yticklabels = np.arange(1, arms+1))\n",
    "# plt.title('Unstructured')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84382c7a-5c90-49f1-9c52-7de2bcbf1e5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functions for value-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6281c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ ACTION SELECTION #######################\n",
    "# epsilon greedy action selection\n",
    "def epsilon_greedy(eps, actions, n_arms, value): \n",
    "    randn = np.random.uniform(0,1)\n",
    "    if randn <= eps:\n",
    "        action = np.random.randint(1, n_arms+1)\n",
    "    else:\n",
    "        action = np.random.choice((np.where(value == np.amax(value))[0])+1)\n",
    "    return action, 1\n",
    "\n",
    "\n",
    "# softmax action selection\n",
    "def softmax(inv_temp, actions, arms, value):\n",
    "    prob_choosing_action = np.zeros(len(arms))\n",
    "\n",
    "    for arm in range(len(arms)):\n",
    "        prob_choosing_action[arm] = (np.exp(value[arm]*inv_temp)) / np.sum(np.exp(value*inv_temp))\n",
    "\n",
    "#     actions = np.random.choice(arms, p = prob_choosing_action) ###### DO NOT USE THIS ######\n",
    "#     print(prob_choosing_action)\n",
    "    actions = np.random.multinomial(1, prob_choosing_action)\n",
    "    a = arms[actions.nonzero()[0][0]]\n",
    "    return a, prob_choosing_action\n",
    "\n",
    "# softmax biased action selection\n",
    "def softmax_biased(inv_temp, actions, arms, value, bias):\n",
    "    prob_choosing_action_biased = np.zeros(len(arms))\n",
    "\n",
    "    for arm in range(len(arms)):\n",
    "        prob_choosing_action_biased[arm] = (np.exp((value[arm]+bias[arm])*inv_temp))/(np.sum(np.exp((value+bias)*inv_temp)))\n",
    "    \n",
    "#     actions = np.random.choice(arms, p = prob_choosing_action) ###### DO NOT USE THIS ######\n",
    "#         print(prob_choosing_action_biased, arm)\n",
    "\n",
    "    actions = np.random.multinomial(1, prob_choosing_action_biased)\n",
    "    a = arms[actions.nonzero()[0][0]]\n",
    "#     print(prob_choosing_action_biased)\n",
    "    return a, prob_choosing_action_biased\n",
    "\n",
    "# softmax weighted bias action selection\n",
    "def softmax_wbias(inv_temp, actions, arms, value, wbias, w):\n",
    "    prob_choosing_action_wbias = np.zeros(len(arms))\n",
    "    \n",
    "    for arm in range(len(arms)):\n",
    "        softmax = (np.exp(value[arm]*inv_temp)) / np.sum(np.exp(value*inv_temp))\n",
    "        prob_choosing_action_wbias[arm] = (w*softmax) + ((1-w)*wbias[arm])\n",
    "    actions = np.random.multinomial(1, prob_choosing_action_wbias)\n",
    "    a = arms[actions.nonzero()[0][0]]\n",
    "\n",
    "    return a, prob_choosing_action_wbias    \n",
    "\n",
    "# Win-stay lose-shift \n",
    "def wsls(actions, reward, n_arms, shift_prob):\n",
    "    if len(actions) == 0:\n",
    "        actions = [np.random.randint(1,n_arms+1)]\n",
    "    av_actions = list(1,range(n_arms+1))\n",
    "    if reward==1:\n",
    "        action = actions[-1]\n",
    "    else:\n",
    "        shift = np.random.uniform(0,1)\n",
    "        if shift<=shift_prob:\n",
    "            av_actions.pop(actions[-1])\n",
    "            action = np.random.choice(av_actions)\n",
    "        else:\n",
    "            action = actions[-1]\n",
    "    return action, 1\n",
    "\n",
    "\n",
    "# upper confidence bound\n",
    "def ucb(c, actions, arms, value):\n",
    "    prob_choosing_action = np.zeros(len(arms))\n",
    "    nt = np.zeros(n_arms)\n",
    "    \n",
    "    for arm in range(len(arms)):\n",
    "        nt[arm] = actions.count(arm)\n",
    "        if nt[arm]!=0:\n",
    "            prob_choosing_action[arm] = value[arm] + (c*np.sqrt(np.log(len(actions)/nt[arm])))\n",
    "        else:\n",
    "            prob_choosing_action[arm] = 1\n",
    "        \n",
    "    action = np.random.choice(np.where((prob_choosing_action == np.amax(prob_choosing_action))[0]))\n",
    "    return action, prob_choosing_action\n",
    "\n",
    "\n",
    "#################### REGRET #######################\n",
    "# regret at each timestep for minimization?\n",
    "def regret(action, prob_arms):\n",
    "    reg = max(prob_arms) - prob_arms[action-1] \n",
    "    return reg\n",
    "\n",
    "################ GIVING REWARD #####################\n",
    "def rewarding(prob, reward_val):\n",
    "    temp = reward_val\n",
    "    rand = np.random.uniform(0, 1)\n",
    "    return temp if rand <= prob else 0\n",
    "\n",
    "################# VANILLA VALUE UPDATION #############\n",
    "def qlearn(value, action, alpha, reward):\n",
    "    value[int(action)-1] = value[int(action)-1] + alpha * (reward - value[int(action)-1])\n",
    "    return value \n",
    "\n",
    "################# DEVALUE OTHER ARMS #################\n",
    "def qlearnAllArms(value, action, alpha, reward, gamma):\n",
    "    value[int(action)] = value[int(action)] + alpha * (reward - value[int(action)])\n",
    "    value[:int(action)] = gamma*value[:int(action)]\n",
    "    value[int(action)+1:] = gamma*value[int(action)+1:]\n",
    "    return value\n",
    "\n",
    "############### BAYESIAN(?) VALUE UPDATION ###########\n",
    "def bayesQlearn(value, action, alpha, reward):\n",
    "    value[int(action)] = value[int(action)] + alpha * (reward - value[int(action)])\n",
    "    return value\n",
    "\n",
    "\n",
    "############# side-weighted softmax values - gaussian transformation? ##############\n",
    "def convSoftmax(inv_temp, actions, arms, value, sd):\n",
    "    prob_choosing_action = np.zeros(len(arms))\n",
    "    value = gaussian_filter1d(value, sigma = sd)\n",
    "    \n",
    "    for arm in range(len(arms)):\n",
    "        prob_choosing_action[arm] = (np.exp(value[arm]*inv_temp)) / np.sum(np.exp(value*inv_temp))\n",
    "\n",
    "    # prob_choosing_action = gaussian_filter1d(prob_choosing_action, sigma = sd)\n",
    "    actions = np.random.multinomial(1, prob_choosing_action)\n",
    "    a = arms[actions.nonzero()[0][0]]\n",
    "    return a, prob_choosing_action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "335d2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob(pk):\n",
    "    # calc prob of actions\n",
    "    unique, counts = np.unique(np.array(pk), return_counts =True)\n",
    "    outcomes = len(pk)\n",
    "    return counts/outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dd808271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphas = np.linspace(0,1, num=5)\n",
    "# taus = np.logspace(-2,2, num=5)\n",
    "# cs = np.linspace(0,0.5, num=5)\n",
    "# fig = plt.figure(figsize = (15, 10))\n",
    "# ind=1\n",
    "\n",
    "# for i, alpha in enumerate(alphas):\n",
    "#     for j, temperature in enumerate(taus):\n",
    "\n",
    "############### ENVIRONMENT #######################\n",
    "np.random.seed(4231)\n",
    "n_arms = 4\n",
    "arms = list(range(1,n_arms+1))\n",
    "\n",
    "prob_arms = np.ones(n_arms)\n",
    "rew_val = np.ones(n_arms)\n",
    "eps = 0.2\n",
    "alpha = 0.1\n",
    "gamma = 0.2\n",
    "c = 0.1\n",
    "shift_prob = 1\n",
    "temperature = 0.1\n",
    "inv_temp = 1/temperature\n",
    "sd = 0.8\n",
    "# bias = [0., 0, 0.1, 0]\n",
    "# wbias = np.array([0.1, 0.5, 0.3, 0.1])\n",
    "# sum(wbias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a37788dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w=0.5\n",
    "\n",
    "trials = 150\n",
    "sessions = 200\n",
    "window = 5\n",
    "\n",
    "sess_mean_list = []\n",
    "reward_hist = {}\n",
    "rew_prob = {}\n",
    "value_hist = {}\n",
    "action_hist = {}\n",
    "corrcoef_hist = {}\n",
    "regret_hist = {}\n",
    "lls= []\n",
    "df = pd.DataFrame()\n",
    "df['trial'] = \" \"\n",
    "df['action'] = \" \"\n",
    "df['reward'] = \" \"\n",
    "df['session'] = \" \"\n",
    "df['rewprob'] = \" \"\n",
    "df['regret'] = \" \"\n",
    "\n",
    "\n",
    "################## run here ##############\n",
    "chance_level_sess = []\n",
    "\n",
    "\n",
    "for sess in range(sessions):\n",
    "\n",
    "    actions = []\n",
    "\n",
    "    q0 = 0.25*np.ones(n_arms)\n",
    "\n",
    "    value=np.copy(q0)\n",
    "    \n",
    "    sess_mean = np.random.randint(1,n_arms+1) # check randint docs for details - returns number between 1 and 8\n",
    "    sess_mean_list.append(sess_mean)\n",
    "    gx = fxn(sess_mean, n_arms)\n",
    "    \n",
    "#     median = np.random.randint(1,n_arms+1)\n",
    "#      gx = cauchy(median, n_arms)\n",
    "\n",
    "    prob_arms = np.random.permutation(np.copy(gx))\n",
    "    rew_prob[sess] = prob_arms\n",
    "#     rew_val = np.copy(gx)\n",
    "\n",
    "    chance_level_sess.append(np.mean(prob_arms, axis = 0))\n",
    "    rew_temp = []\n",
    "    value_temp = []\n",
    "    corrcoef = []\n",
    "    regrets=[]\n",
    "        \n",
    "    reward = 0\n",
    "    \n",
    "    for trial in range(trials):\n",
    "#         action, p = epsilon_greedy(eps, actions, n_arms, value)\n",
    "#         action, p = wsls(actions, reward, n_arms, shift_prob)\n",
    "#         action, p = ucb(c, actions, arms, value)\n",
    "        action, p = convSoftmax(inv_temp, actions, arms, value, sd)\n",
    "#         action, p = softmax_biased(inv_temp, actions, arms, value, bias)\n",
    "#         action, p = softmax_wbias(inv_temp, actions, arms, value, wbias, w)\n",
    "        \n",
    "        actions.append(action)\n",
    "        reg = regret(action, prob_arms)\n",
    "        regrets.append(reg)\n",
    "        reward = rewarding(prob_arms[int(action)-1], rew_val[int(action)-1])\n",
    "        rew_temp.append(reward)\n",
    "        df.loc[len(df.index)] = [trial, action, reward, sess, prob_arms[int(action)-1], reg]\n",
    "        value = qlearn(value, action, alpha, reward)\n",
    "#         print(action, value, reward)\n",
    "#         value = qlearnAllArms(value, action, alpha, reward, gamma)\n",
    "    value_temp.append(value)\n",
    "    value_hist[sess] = value_temp\n",
    "    regret_hist[sess] = regrets\n",
    "    \n",
    "plt.plot(df.groupby('session')['action'].get_group(0), 'o')\n",
    "df['choice_t1'] = df.groupby('session').action.shift(-1)\n",
    "df['choice_t2'] = df.groupby('session').action.shift(-2)\n",
    "df['shift_t0'] = (df['choice_t1']==df['action']).replace({True: 0, False: 1})\n",
    "df['shift_t1'] = (df['choice_t2']==df['action']).replace({True: 0, False: 1})\n",
    "df['rr'] = (df.groupby('session', as_index = False)\n",
    "            .reward\n",
    "            .rolling(window, center=True)\n",
    "            .mean()\n",
    "            .reward)\n",
    "df['entropy'] = (df.groupby('session', as_index = False)\n",
    "                     .action\n",
    "                     .rolling(window, center=True)\n",
    "                     .apply(lambda x: entropy(calc_prob(x), base = 2))\n",
    "                     .action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "62b9faa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Transition matrix')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# potentially plot everything for this model, rr, entropy, tm, regret, distance, bias analysis, variability \n",
    "fig = plt.figure(figsize = (10, 7))\n",
    "\n",
    "def avg_mat(df, col):\n",
    "    g = df.groupby('session').cumcount()\n",
    "    L = np.array(df.set_index(['session',g])\n",
    "           .unstack(fill_value=0)\n",
    "           .stack().groupby(level=0)\n",
    "           .apply(lambda x: x[col].values.tolist())\n",
    "           .tolist())\n",
    "    return L\n",
    "\n",
    "\n",
    "# figure 1 - regret across all sessions\n",
    "ax = plt.subplot(221)\n",
    "reg_mat = avg_mat(df, 'regret')\n",
    "reg_mean = np.mean(reg_mat, axis = 0)\n",
    "reg_sem = sem(reg_mat, nan_policy = 'omit')\n",
    "ax.plot(reg_mean, color = 'xkcd:azure')\n",
    "ax.fill_between(np.arange(reg_mat.shape[1]), reg_mean - reg_sem, reg_mean + reg_sem,  color = 'xkcd:azure', alpha = 0.2)\n",
    "ax.set_title('Regret')\n",
    "\n",
    "# figure 2 - performance plot across all sessions\n",
    "ax = plt.subplot(222)\n",
    "rr_mat = avg_mat(df, 'rr')\n",
    "rr_mean = np.mean(rr_mat, axis = 0)\n",
    "rr_sem = sem(rr_mat, nan_policy = 'omit')\n",
    "ax.plot(rr_mean, color = 'xkcd:azure')\n",
    "ax.fill_between(np.arange(rr_mat.shape[1]), rr_mean - rr_sem, rr_mean + rr_sem,  color = 'xkcd:azure', alpha = 0.2)\n",
    "ax.set_title('Performance')\n",
    "\n",
    "# figure 3 - entropy plot across all sessions\n",
    "ax = plt.subplot(223)\n",
    "entropy_mat = avg_mat(df, 'entropy')\n",
    "entropy_mean = np.mean(entropy_mat, axis = 0)\n",
    "entropy_sem = sem(entropy_mat, nan_policy = 'omit')\n",
    "ax.plot(entropy_mean, color = 'xkcd:azure')\n",
    "ax.fill_between(np.arange(entropy_mat.shape[1]), entropy_mean - entropy_sem,\n",
    "                 entropy_mean + entropy_sem,  color = 'xkcd:azure', alpha = 0.2)\n",
    "ax.set_title('Entropy')\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "# figure 4 - transition matrix\n",
    "ax = plt.subplot(224)\n",
    "sns.heatmap(pd.crosstab(df[df.shift_t0==1].action, df[df.shift_t0==1].choice_t1, normalize = 'index'),\n",
    "            cmap = 'YlGnBu', annot = True, fmt = '.2f', vmin = 0.0, vmax = 0.7, mask = np.eye(4),\n",
    "            xticklabels = np.arange(1,5), yticklabels = np.arange(1,5), ax = ax)\n",
    "ax.patch.set_facecolor('white')\n",
    "ax.set_title('Transition matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ad0b8-fd7c-4971-a995-1e230108506a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# This will probably not work but might be worth a try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8d0e4-2cab-4807-8a6c-1e94ba52ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct df with rolling windows for -20, +20 trial history (choices), rewards (outcomes)\n",
    "from warnings import simplefilter \n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "hist = 21\n",
    "rolling_df = df.copy(deep = True)\n",
    "for i in range(1, hist):\n",
    "    \n",
    "    # shift i tells which port was taken on the prev trial i.e., 1st trial is NaN\n",
    "    rolling_df['backchoice_t'+str(i)] = df.groupby('session').action.shift(i)\n",
    "    \n",
    "#     shift -i tells which port was taken on the next trial i.e., last trial is NaN\n",
    "    rolling_df['fwdchoice_t'+str(i)] = df.groupby('session').action.shift(-i)\n",
    "    \n",
    "    # shift i tells outcome on the prev trial i.e., 1st trial is NaN\n",
    "    rolling_df['backreward_t'+str(i)] = df.groupby('session').reward.shift(i)\n",
    "\n",
    "    # shift -i tells outcome on the next trial i.e., last trial is NaN\n",
    "    rolling_df['fwdreward_t'+str(i)] = df.groupby('session').reward.shift(-i)\n",
    "\n",
    "    # shift i tells entropy on the next trial i.e 1st trial is NaN\n",
    "    rolling_df['backentropy_t'+str(i)] = df.groupby('session').entropy.shift(i)\n",
    "\n",
    "    # shift i tells entropy on the next trial i.e 1st trial is NaN\n",
    "    rolling_df['fwdentropy_t'+str(i)] = df.groupby('session').entropy.shift(-i)\n",
    "\n",
    "rolling_df.dropna(inplace = True)\n",
    "rolling_df['shift_t0'] = (rolling_df['fwdchoice_t1']==rolling_df['action']).replace({True: 0, False: 1})\n",
    "\n",
    "collist = ['backreward_t'+str(i) for i in range(hist-1, 0, -1)]+['fwdreward_t'+str(i) for i in range(1, hist)]\n",
    "\n",
    "# make formula for logreg\n",
    "formula = ''.join([i+' +'for i in collist])\n",
    "formula = 'reward ~' + formula.rstrip('+')\n",
    "print(formula)\n",
    "\n",
    "# define percentiles for binning\n",
    "from scipy.stats import scoreatpercentile as satp\n",
    "percentiles = np.linspace(0,1,21)*100\n",
    "rolling_df.dropna(inplace = True)\n",
    "rolling_df.prop_score, rolling_df.binnum, rolling_df['nan'] = 0, 0, 0\n",
    "\n",
    "# calculate prop score using these columns\n",
    "# so first, make a logreg\n",
    "model = smf.glm(formula = formula, data = rolling_df, family = sm.families.Binomial()).fit()\n",
    "\n",
    "# make predictions on dataset - this is the prop score (probability of reward given history/future)\n",
    "rolling_df['prop_score'] = model.predict(rolling_df)\n",
    "\n",
    "# bin the scores acc to some logic - use 10 equal prop bins, for eg - assign bin number to group\n",
    "binedges = satp(rolling_df['prop_score'], percentiles)\n",
    "rolling_df['binnum'] = np.digitize(rolling_df['prop_score'], binedges)\n",
    "    \n",
    "# get whether probability corresponds to reward or no reward\n",
    "# print(np.column_stack((model.model.endog, group.reward.to_numpy())))\n",
    "\n",
    "# add a column to convert prop score to prediction\n",
    "rolling_df['pred'] = [1 if x < 0.5 else 0 for x in rolling_df['prop_score']]\n",
    "\n",
    "# take entropy of trials with equal binnumbers and average? i think\n",
    "# split before average! into reward and no reward\n",
    "df['prop_score'] = rolling_df['prop_score']\n",
    "df['binnum'] = rolling_df['binnum']\n",
    "\n",
    "collist = ['backentropy_t'+str(i) for i in range(hist-1, 0, -1)]+['nan']+['fwdentropy_t'+str(i) for i in range(1, hist)]\n",
    "\n",
    "# across animals average in each bin\n",
    "# remove last bin of both R and NR\n",
    "lastbin = len(percentiles)\n",
    "propscored = rolling_df.groupby(['reward', 'binnum'])[collist].mean().drop(index = lastbin, level = 1).reset_index()\n",
    "\n",
    "# test whether any of the bins are empty\n",
    "# print((choice_df.groupby(['reward', 'binnum'])[collist].count()==0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3c4e5a66-0ac4-413a-816d-17c63bef015f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ca015ae050>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif = propscored[propscored.reward==0][collist].to_numpy() - propscored[propscored.reward==1][collist].to_numpy()\n",
    "mat = np.mean(dif, axis = 0)\n",
    "mat[hist-3:hist+2]= np.nan\n",
    "plt.plot(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f5e6d5-b67a-4259-beca-994ed0adefdb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Gradient bandit algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a43618d8-67a5-49ff-9c0c-9be6c4e0e119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 3 0.07500003055594018\n",
      "1 1 2 0.04950087381270531\n",
      "2 1 2 0.12350130633538219\n",
      "3 0 1 -0.07588467320223645\n",
      "4 1 2 0.19750172716825698\n",
      "5 1 3 0.0745001501315194\n",
      "6 1 3 0.14700017966892823\n",
      "7 1 3 0.21900020900263079\n",
      "8 0 0 -0.1747678657495343\n",
      "9 0 1 -0.17507047135284523\n",
      "10 0 0 -0.1770975188861125\n",
      "11 0 1 -0.17740744111673867\n",
      "12 1 3 0.29516689909551824\n",
      "13 1 2 0.17683708283734983\n",
      "14 0 0 -0.22800156457138374\n",
      "15 0 1 -0.22783808919105653\n",
      "16 0 2 0.17533700393118581\n",
      "17 0 1 -0.23084276460177666\n",
      "18 1 1 -0.1603061405511355\n",
      "19 0 1 -0.1653087380015356\n",
      "20 0 0 -0.25035960779721583\n",
      "21 0 0 -0.2553569790852479\n",
      "22 0 0 -0.26035435037328\n",
      "23 1 3 0.3306669697815931\n",
      "24 0 0 -0.2892215940909999\n",
      "25 1 2 0.20800472268003947\n",
      "26 1 2 0.27700512597821114\n",
      "27 0 3 0.27983368798594555\n",
      "28 1 3 0.3483337158937042\n",
      "29 1 3 0.41633374359775666\n",
      "30 0 0 -0.38635881285572704\n",
      "31 0 2 0.2286724648084973\n",
      "32 0 2 0.2211724209717395\n",
      "33 0 0 -0.38884698365187126\n",
      "34 1 1 -0.19362405927809004\n",
      "35 1 2 0.26817316327417146\n",
      "36 1 2 0.3346735519600905\n",
      "37 0 3 0.3503338095985875\n",
      "38 0 0 -0.4619431945098983\n",
      "39 0 0 -0.470938462828356\n",
      "40 0 3 0.34733379859844904\n",
      "41 1 2 0.4126737273071217\n",
      "42 1 2 0.47817411014813976\n",
      "43 0 3 0.2935005147657388\n",
      "44 0 0 -0.518492351423699\n",
      "45 1 0 -0.45352652467928234\n",
      "46 1 3 0.33966723011820343\n",
      "47 1 3 0.4036672561926057\n",
      "48 1 1 -0.26404864356746927\n",
      "49 1 1 -0.20101591569242827\n",
      "50 0 3 0.3490006359709681\n",
      "51 0 0 -0.5469807787631414\n",
      "52 1 2 0.44900941613557377\n",
      "53 0 1 -0.22650318818546789\n",
      "54 1 2 0.5153430358690579\n",
      "55 1 2 0.5768433953304718\n",
      "56 1 1 -0.2065740089323716\n",
      "57 1 1 -0.14604257978253063\n",
      "58 0 0 -0.6602943904288167\n",
      "59 0 0 -0.6752865042929128\n",
      "60 1 2 0.6063442808329792\n",
      "61 1 3 0.3045007873247251\n",
      "62 1 1 -0.11679876883898158\n",
      "63 1 2 0.6253453153804631\n",
      "64 0 0 -0.7714021676195028\n",
      "65 1 3 0.329000851899612\n",
      "66 1 1 -0.09238387556308575\n",
      "67 0 0 -0.8279534275028779\n",
      "68 1 2 0.6555127857210227\n",
      "69 0 1 -0.12387322601644543\n",
      "70 0 0 -0.8592972756840831\n",
      "71 1 2 0.7243462330299263\n",
      "72 1 2 0.7803465603443844\n",
      "73 1 1 -0.09962889558281637\n",
      "74 0 0 -0.9353750855583346\n",
      "75 0 2 0.7485133176070172\n",
      "76 1 2 0.8035136390765744\n",
      "77 1 1 -0.05009279102225527\n",
      "78 0 0 -0.9862444322456289\n",
      "79 0 3 0.2160009557898085\n",
      "80 1 1 0.01791344285870492\n",
      "81 0 0 -1.0187504782831551\n",
      "82 1 1 0.0785967332079321\n",
      "83 1 2 0.8236811912457482\n",
      "84 0 0 -1.0767946406442168\n",
      "85 0 1 0.04593422246190556\n",
      "86 1 0 -1.0168104129160245\n",
      "87 1 3 0.21916770332786348\n",
      "88 0 0 -1.0576587299075753\n",
      "89 1 1 0.07050305489750769\n",
      "90 0 2 0.7705148957302973\n",
      "91 1 0 -1.0158666673521388\n",
      "92 1 2 0.8040154889877527\n",
      "93 0 3 0.15900106945790599\n",
      "94 0 1 0.028017340874708134\n",
      "95 0 1 0.003004353622707734\n",
      "96 0 0 -1.0326739764369894\n",
      "97 0 2 0.812348091708456\n",
      "98 1 2 0.862348383953508\n",
      "99 1 3 0.22516773592086634\n",
      "100 0 0 -1.083532808276412\n",
      "101 1 3 0.28283441195802134\n",
      "102 0 2 0.8116819861522891\n",
      "103 0 3 0.26516772369849023\n",
      "104 0 1 -0.02999928280785238\n",
      "105 0 1 -0.056513049294972806\n",
      "106 0 2 0.8116813665927789\n",
      "107 1 0 -1.0071810739593028\n",
      "108 1 2 0.8435152639590625\n",
      "109 0 0 -1.0506918516783714\n",
      "110 1 1 -0.02313296185443804\n",
      "111 0 1 -0.05114750757667849\n",
      "112 1 1 -0.004123091542917734\n",
      "113 0 1 -0.03263789701019819\n",
      "114 1 2 0.8865155971184216\n",
      "115 0 0 -1.107887697047882\n",
      "116 0 3 0.22116773021709085\n",
      "117 0 3 0.19216771840212732\n",
      "118 0 0 -1.1175086241263061\n",
      "119 0 3 0.1728343614388669\n",
      "120 0 0 -1.1368114644008112\n",
      "121 1 1 0.0558197645482805\n",
      "122 0 0 -1.1816534724836387\n",
      "123 0 0 -1.211137963083028\n",
      "124 0 1 0.045940456342865754\n",
      "125 0 1 0.01642513138550528\n",
      "126 1 3 0.2520010054941378\n",
      "127 0 3 0.2220009932717617\n",
      "128 0 0 -1.226599321017099\n",
      "129 0 3 0.20200096882700955\n",
      "130 1 3 0.24700098716057364\n",
      "131 0 1 -0.01425711998356187\n",
      "132 0 0 -1.251908470200327\n",
      "133 1 3 0.31183431377160015\n",
      "134 1 3 0.3558343316977517\n",
      "135 1 0 -1.2379778681962808\n",
      "136 1 0 -1.1950004751192052\n",
      "137 0 3 0.2945010203646953\n",
      "138 0 0 -1.2166329685302884\n",
      "139 1 1 0.0018062578062000914\n",
      "140 0 0 -1.263804629749694\n",
      "141 1 2 0.9908480829411044\n",
      "142 1 2 1.0323483255044974\n",
      "143 0 1 -0.049018503940812974\n",
      "144 0 3 0.2516676839757679\n",
      "145 0 0 -1.3029615701820791\n",
      "146 0 3 0.22900098960504878\n",
      "147 0 0 -1.3255924863659816\n",
      "148 1 1 0.037265477834918834\n",
      "149 0 3 0.1921676450678707\n"
     ]
    }
   ],
   "source": [
    "# setup env \n",
    "arms = 4\n",
    "alpha = 0.1\n",
    "trials = 150\n",
    "sessions = 1\n",
    "rew_val = 1\n",
    "# prob_arms = fxn(2, 4)\n",
    "\n",
    "\n",
    "\n",
    "# parameterized policy \n",
    "def policy(a, theta_arm = theta_arm):\n",
    "    return (np.exp(theta_arm[a])/ np.sum(np.exp(theta_arm)))\n",
    "\n",
    "# update policy\n",
    "for session in range(sessions):\n",
    "    # initialize\n",
    "    rr = np.zeros(trials)\n",
    "    theta_arm = np.zeros(arms)\n",
    "    del_theta = np.zeros(arms)\n",
    "    R_hist = np.zeros(trials)\n",
    "    mean_p = np.random.randint(1, 5)\n",
    "    prob_arms = fxn(mean_p, arms)\n",
    "    \n",
    "    for trial in range(trials):\n",
    "        chosen = np.random.multinomial(1, [policy(a) for a in range(arms)]).nonzero()[0][0]\n",
    "    \n",
    "        R = rewarding(prob_arms[chosen], rew_val)\n",
    "        \n",
    "        # R_hist[trial] = R\n",
    "    \n",
    "        rr[trial] = np.nanmean(R_hist)\n",
    "    \n",
    "        del_theta = [(alpha*(1-policy(a))*(R - rr[trial])) \n",
    "                     if (chosen == a) \n",
    "                     else (-alpha*(policy(a))*(R - rr[trial])) for a in range(arms)]\n",
    "            \n",
    "        theta_arm = [(theta_arm[a] + del_theta[a]) for a in range(arms)]\n",
    "        \n",
    "        print(trial, R, chosen, theta_arm[chosen])\n",
    "\n",
    "        R_hist[trial] = R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4c7564ea-099e-474f-8392-1652811bff30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00666667, 0.01333333, 0.02      , 0.02      ,\n",
       "       0.02666667, 0.03333333, 0.04      , 0.04666667, 0.04666667,\n",
       "       0.04666667, 0.04666667, 0.04666667, 0.05333333, 0.06      ,\n",
       "       0.06      , 0.06      , 0.06      , 0.06      , 0.06666667,\n",
       "       0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.07333333,\n",
       "       0.07333333, 0.08      , 0.08666667, 0.08666667, 0.09333333,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.10666667, 0.11333333, 0.12      , 0.12      , 0.12      ,\n",
       "       0.12      , 0.12      , 0.12666667, 0.13333333, 0.13333333,\n",
       "       0.13333333, 0.14      , 0.14666667, 0.15333333, 0.16      ,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.17333333, 0.17333333,\n",
       "       0.18      , 0.18666667, 0.19333333, 0.2       , 0.2       ,\n",
       "       0.2       , 0.20666667, 0.21333333, 0.22      , 0.22666667,\n",
       "       0.22666667, 0.23333333, 0.24      , 0.24      , 0.24666667,\n",
       "       0.24666667, 0.24666667, 0.25333333, 0.26      , 0.26666667,\n",
       "       0.26666667, 0.26666667, 0.27333333, 0.28      , 0.28      ,\n",
       "       0.28      , 0.28666667, 0.28666667, 0.29333333, 0.3       ,\n",
       "       0.3       , 0.3       , 0.30666667, 0.31333333, 0.31333333,\n",
       "       0.32      , 0.32      , 0.32666667, 0.33333333, 0.33333333,\n",
       "       0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.34      ,\n",
       "       0.34666667, 0.34666667, 0.35333333, 0.35333333, 0.35333333,\n",
       "       0.35333333, 0.35333333, 0.35333333, 0.36      , 0.36666667,\n",
       "       0.36666667, 0.37333333, 0.37333333, 0.38      , 0.38      ,\n",
       "       0.38666667, 0.38666667, 0.38666667, 0.38666667, 0.38666667,\n",
       "       0.38666667, 0.38666667, 0.39333333, 0.39333333, 0.39333333,\n",
       "       0.39333333, 0.39333333, 0.4       , 0.4       , 0.4       ,\n",
       "       0.4       , 0.40666667, 0.40666667, 0.40666667, 0.41333333,\n",
       "       0.42      , 0.42666667, 0.43333333, 0.43333333, 0.43333333,\n",
       "       0.44      , 0.44      , 0.44666667, 0.45333333, 0.45333333,\n",
       "       0.45333333, 0.45333333, 0.45333333, 0.45333333, 0.46      ])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
